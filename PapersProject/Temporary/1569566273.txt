Title:          SVB-ISIT12-final.dvi
Creator:        www.freepdfconvert.com         
Producer:       Appligent StampPDF Batch, version 5.1
CreationDate:   Fri May 18 07:10:31 2012
ModDate:        Tue Jun 19 12:55:59 2012
Tagged:         no
Pages:          5
Encrypted:      no
Page size:      612 x 792 pts (letter)
File size:      286471 bytes
Optimized:      no
PDF version:    1.7
ISIT'2012 1569566273

Properties and encoding aspects of direct product
convolutional codes
Vladimir Sidorenko,
Martin Bossert

Francesca Vatta

Department of Telecommunications and Applied Information Theory
University of Ulm
Albert-Einstein-Allee, 43
D-89081 Ulm, Germany
Email: {vladimir.sidorenko, martin.bossert}@uni-ulm.de

DI3
University of Trieste
Via A. Valerio, 10
I-34127 Trieste, Italy
Email: vatta@units.it

applied for convolutional codes combination as well, as done
in [3] where a more general work on this subject was started.
For convolutional codes only a few combining methods have
been suggested. Besides the well-known parallel [4] and serial
[5] concatenation of convolutional codes, perhaps one of the
most versatile and interesting methods, woven convolutional
codes, was considered in [6]. In our work, we have taken a
different approach to construct a new class of convolutional
codes, called product convolutional codes, which has been
deﬁned and investigated in [7]. The new codes have been
constructed using the well-known method of the direct product
for combining block codes. Convolutional codes were considered as block codes over the ﬁeld of rational functions F (D)
([8]) and, thus, the new concept of block weight and block
distance of a convolutional code was deﬁned in [3]. There, it
was shown that the free distance of the product code equals
the product of component codes free distances if at least one
of the component codes block distance equals its free distance.
Afterwards, some algorithms for the termination and tailbiting of direct product convolutional codes were proposed and
investigated in [9] for the rate 1/n case and in [10] for the
rate-k/n case, assuming to encode these codes by feedback
convolutional encoders realized in controller canonical form.
In [9] and [10], however, the relationship between the
canonicality of the constituent encoders generator matrices
and the canonicality of the direct product encoder generator
matrix was not investigated. Moreover, in [7] were given some
theorems, with no proof, stating the relationship between the
properties of the constituent encoders and the direct product
encoder polynomial generator matrices. Thus, purpose of this
paper is to give proof of theorems in [7] and to investigate
on the relationship between the canonicality of the constituent
encoders generator matrices and the canonicality of the direct
product encoder generator matrix.
The paper is organized as follows. In Section II, we give
some deﬁnitions, showing how a direct product convolutional
code can be obtained from its vertical and horizontal constituent encoders. In Section III, we recall some properties
of the generator matrices. In Section IV, we investigate on
the properties of the direct product encoder generator matrix

Abstract—In this paper we investigate the properties of the
generator matrices of a new class of convolutional codes, called
product convolutional codes, which were previously deﬁned and
investigated by the authors. The new codes are constructed using
the well-known method of the direct product for combining block
codes. Convolutional codes are considered as block codes over the
ﬁeld of rational functions F(D). The description of convolutional
codes as block codes allows the successful application of the direct
product method to convolutional codes, and, in addition, leads to
a general method to construct new convolutional codes based on
already known combining methods for block codes. Expressions
for the generator matrices of the product convolutional codes are
given and several of their properties, which were not addressed
before, are determined. The relationship between the properties
of the direct product encoder generator matrix and the properties
of the vertical and horizontal constituent encoders generator
matrices is derived. Rational generator matrices, as well as
polynomial generator matrices, are addressed.

I. I NTRODUCTION
Powerful codes can be designed by combining already
known codes. The new codes can have several advantageous
features such as large distance, capability of burst and random
error correction, large blocklength and low-density parity
check matrices. In order to be useful, these new codes must
have a structure suitable for decoding using techniques with
low complexity such as iterative decoding.
For block codes many combining methods are suggested
and analyzed [1]. One of the earliest methods, product or
iterated codes, was proposed by Elias [2] in 1954. Product
of block codes gives a block code which has not the best
distance. However, in this way long codes with large distance
can be constructed and efﬁciently decoded. The algebraic
structure of these codes was investigated in the literature so
that their performance can be analytically determined without
simulations. This is important for optical transmission and
other similar applications, where the block error rate might be
so small that it is not possible to estimate it by simulations.
The same advantages still hold for the product of convolutional codes if the methods of combining block codes can be
This work was partly supported by the Vigoni Program 2008/2010 of
scientiﬁc cooperation between Italy and Germany.

1

and the relationship between the properties of the constituent
encoders and those of the direct product encoders obtained
from their concatenation. Finally, Section V summarizes and
concludes the paper.



G (D) = 


−

II. D EFINITIONS




|
G (D) = 



|

|

q1 (D)

···

.
.
.

g

|

(D)

k| ,1
|
q | (D)
k

|

(D)

1,n|
|
q1 (D)

.
.
.

···

g

|

(D)
|

k| ,n
|
q | (D)
k

g− (D)
−
k

,1

q− (D)
−

(D)

1,n−
−
q1 (D)

.
.
.

···

k

g−
−

(D)

k ,n−
q− (D)
k−









u1,k− (D)

.
.

.
uk| ,k− (D)

T

C ⊗ (D) = G| (D) U (D) G− (D)

(3)

(4)

(5)

We can also apply Column-Row encoding and get the same
matrix by matrix multiplication in another order:
T

C ⊗ (D) = G| (D) U (D) G− (D)

(6)

From (5) it follows that every column of C ⊗ (D) belongs
to C | , and, from (6), that every row of C(D) belongs to C − .
Hence, by Deﬁnition 3, we obtain a codeword C ⊗ (D) ∈
C | ⊗ C − . Denote by C ⊗ the set of matrices C ⊗ (D) obtained
by encoding all matrices U (D) using (5). In the following,
we show that C ⊗ is an (n| n− , k | k − ) convolutional code, and
C ⊗ = C | ⊗ C − , by verifying that every C ⊗ (D) ∈ C ⊗ satisﬁes
Deﬁnition 1, and all matrices C ⊗ (D) that satisfy Deﬁnition 3
are included in C ⊗ .
First, let us introduce the operator row and consider the
Kronecker or direct product of two matrices.
Deﬁnition 5: The matrix operation of ordering the rows of
a matrix one next to the other to form a single row vector is
called row and the notation is row(A), where A is a matrix.
Deﬁnition 6: Let A be an m × n matrix and let B be a
p × q matrix. Then the Kronecker product of A and B is that
(mp) × (nq) deﬁned by


a1,1 B a1,2 B · · · a1,n B
 a2,1 B a2,2 B · · · a2,n B 


(7)
A⊗B = .

.
.
.
.
.

 .
.
.
am,1 B am,2 B · · · am,n B
The following property of the Kronecker product can be
derived from [11]:









.
.
.

g−

be the matrix which describes the information sequences to be
encoded.
We can perform a Row-Column encoding, ﬁrst using the
horizontal encoder to encode the rows of U (D), obtaining
V (D) = U (D) G− (D). Then the vertical encoder is used to
encode the columns of V (D), obtaining the code sequence [7]

(1)

g

···

u1,1 (D) · · ·

.
.
U (D) = 
.
uk| ,1 (D) · · ·

Deﬁnition 3: Let C | and C − be convolutional (n| , k | ) and
(n , k − ) codes. Then, the direct product convolutional code
C | ⊗ C − is deﬁned to be the code whose codewords consist of
all n| × n− arrays in which the columns belong to C | and the
rows to C − .
Deﬁnition 4: Let C ⊗ be a direct product convolutional
code generated from the concatenation of two component
convolutional codes C − of rate R− = k − /n− (horizontal
code) and C | of rate R| = k | /n| (vertical code). The rate
k| k−
R⊗ of this direct product code is then R⊗ = n| n− = R| R− .
The generator matrix G| (D) of the vertical component
encoder and the generator matrix G− (D) of the horizontal
component encoder are described by:
g1,1 (D)

−
q1 (D)



−



−
g1,1 (D)

Let

Using Forney’s algebraic theory of convolutional codes [8]
we consider convolutional codes as block codes over a ﬁeld
of rational functions. Let F be a ﬁeld, and F (D) denote the
ﬁeld of rational functions over F in the indeterminate D. Each
non-zero element a(D) of F (D) can be represented as a ratio
of polynomials over F , a(D) = p(D)/q(D), where p(D) and
q(D) are relatively prime.
Similar to linear block codes, we consider the following
deﬁnition of a convolutional code [8] and of its generator
matrix.
Deﬁnition 1: An (n, k) convolutional code C over a ﬁeld F
n
is a k-dimensional subspace of F (D) , i.e., a subspace of the
vector space of n-tuples over the rational ﬁeld F (D).
The rate R of the (n, k) convolutional code C is deﬁned to
be R = k/n.
Deﬁnition 2: A k × n matrix G(D) over F (D) whose rows
form a basis of an (n, k) convolutional code C is called a
generator matrix of the code.
In our work, we consider only binary convolutional codes,
i.e., F = GF (2).
Let v(D) = {v1 (D), · · · , vn (D)} be a codeword
of an (n, k) convolutional code and let u(D) =
{u1 (D), · · · , uk (D)} be the information word. Then, the
encoding rule, similar to block codes, is
v(D) = u(D)G(D)



(2)

row(ABC) = row(B)(AT ⊗ C)

(8)
⊗

|

Let us return to the product convolutional code C = C ⊗
C − and consider replacing every matrix C ⊗ (D) ∈ C ⊗ by a
vector c⊗ (D) = row(C ⊗ (D)) to obtain a code C ⊗ of vectors.

and

2

Take the encoding procedure (5) for the product code and
apply the operator row. Then, using the notation u(D) =
row(U (D)), the encoding procedure (5) for the product code
can be rewritten in traditional vector form
c(D) = u(D)G⊗ (D)






⊗
G (D) = 



(9)

where the generator matrix G⊗ (D) is the generator matrix of
the product convolutional code C ⊗ . G⊗ (D) is given by the
following theorem.
Theorem 1: The generator matrix G⊗ (D) of a product
convolutional code C ⊗ = C | ⊗ C − is given by the Kronecker
product of the generator matrices of the constituent codes
G⊗ (D) = G| (D) ⊗ G− (D)

T




G (D) = 


⊗

(10)

(11)

We call the code C ⊗ a product convolutional code.
Following Theorem 1, G⊗ (D) is given by:
|

G− (D),

|
 q1 (D)
 |
 g2,1 (D)
 |
G− (D),
G⊗ (D) =  q2 (D)

 · · ·,
 |
 gk| ,1 (D)
G− (D),
|

q

k|

(D)

|


G− (D) 


−
· · ·,
G (D) 
|

q2 (D)


· · ·, · · ·

|
g | | (D)

k ,n
−
· · ·,
G (D)
|
· · ·,

g

(D)

1,n|
|
q1 (D)
|
g | (D)
2,n

q

k|

.
.
.

···

g⊗
|

(D)

k k− ,n| n−
|
q | (D)q− (D)
k−
k

⊗
q1 (D)

···

.
.
.

g⊗ − (D)
k| k ,1
q⊗ − (D)
k| k

g

(D)

1,n| n−
⊗
q1 (D)

.
.
.

···

g⊗ − | − (D)
k| k ,n n
q⊗ − (D)
k| k




 (14)










(15)

OF THE GENERATOR MATRICES

be a generator matrix for an (n, k) convolutional code
C where gi,j (D) and qi (D) are polynomials with
gcd(gi,1 (D), · · · , gi,n (D), qi (D) = 1. The following
properties hold:
1) G(D) is a rational generator matrix if at least one qi (D)
has degree larger than 1.
2) If qi (D) is delay free, i.e., qi (0) = 0, ∀i, then the
generator matrix is called realizable, i.e., it is realizable
in controller or observer canonical form.
3) If all the entries of G(D) are polynomials, then G(D)
is called a polynomial generator matrix for C.
4) A generator matrix G(D) for an (n, k) convolutional
code C is said to be systematic if the information
sequence u(D) is an unchanged part of the encoded
sequence v(D) = u(D)G(D).
5) Two generator matrices G(D) and G (D) are equivalent
if they encode the same code. Two generator matrices
are equivalent iff G (D) = T (D)G(D), where T (D) is
a rational and invertible k × k matrix.
6) A generator matrix G(D) is called encoding matrix if
G(0) has full rank. An encoding matrix is realizable and
delay free. In addition, it has a realizable right inverse
G−1 (D).
7) A convolutional generator encoding matrix is called
basic if it is polynomial and it has a polynomial right
inverse. A convolutional encoder is called basic if its
generator matrix is basic.

the direct product of convolutional codes C | and C − ;
an (n| n− , k | k − ) convolutional code.

g1,1 (D)

···



The properties of the generator matrix G⊗ (D) of a product
convolutional code (10) can be derived from the structural
properties of the generator matrices of the constituent codes. In
the following, we recall some deﬁnitions and properties from
[12] of the generator matrix G(D) of an (n, k) convolutional
code and determine the properties of G⊗ (D).
Let
 g1,1 (D)

g1,n (D)
···
q1 (D)
q1 (D)


.
.

.
.
G(D) = 
(16)
.
.


gk,1 (D)
gk,n (D)
···
qk (D)
qk (D)

By Deﬁnition 2, the generator matrices G| (D) and G− (D)
of the constituent codes have full rank. Since G| (D) and
G− (D) have elements from F (D), i.e., they are rational
matrices, from (10) it follows that G⊗ (D) is also a rational
k | k − × n| n− matrix of full rank. Therefore, the code C ⊗
generated by G⊗ (D) is a k | k − -dimensional linear subspace of
| −
{F (D)}n n . This means that all matrices C ⊗ (D) that satisfy
Deﬁnition 3 are included in C ⊗ .
Finally, we conclude that the code C ⊗ generated by (5) or
(9) is



(D)

k k− ,1
|
q | (D)q− (D)
k−
k

III. P ROPERTIES

c(D) = row(U (D))[G| (D) ⊗ G− (D)] = u(D)G⊗ (D)
(12)

•

g⊗
|

(D)

1,n| n−
|
−
q1 (D)q1 (D)

.
.
.

⊗
g1,1 (D)

Applying the property (8) we have:

•

|

−
q1 (D)q1 (D)

g⊗

The matrix (14) can also be rewritten as:

⊗

G| (D) and G− (D) are the generator matrices of the
constituent codes C | and C − , respectively.
Proof: Let C ⊗ (D) be a codeword of a product convolutional code C ⊗ = C | ⊗ C − . Using (5), C ⊗ (D) may be written
as a vector c(D) using the operator row. Thus:
row(C ⊗ (D)) = row(G| (D) U (D) G− (D) )

⊗
g1,1 (D)

(D)

(13)

or also by:

3

8) A minimal basic encoding matrix is a basic encoding
matrix whose overall constraint length ν is minimal over
all equivalent basic encoding matrices.
9) A canonical generator matrix is a rational encoding
matrix whose overall constraint length ν is minimal over
all equivalent rational generator matrices.

and the overall constraint length results in
ν⊗

k| k−

=

⊗
{νi }

i=1
k| k−

=

Some well known parameters of a k × n generator matrix
G(D), using the notation in [12], are:

=

|

−
(νp + νq )

p=1 q=1
k|
|
νp
p=1
− |

k− +

(23)

ν−
|
νp

= k ν + k| ν −

1) The constraint length νi of the i-th row of G(D) is the
maximum degree of all the numerator and denominator
polynomials of this row:

Theorem 3: If G| (D) and G− (D) are rational delay free
generator matrices, the generator matrix of the product conνi ≡ max{deg(gi,1 (D)), · · · , deg(gi,n (D), deg(qi (D))}. volutional code G⊗ (D) is delay free.
(17)
Proof: By deﬁnition of the direct product of two matrices
2) The overall constraint length ν is the sum over all (10), every entry q ⊗ (D) of G⊗ (D) (15) is the product of
i
constraint lengths
the corresponding entries of G| (D) and G− (D) (14), i.e.,
|
⊗
−
qi (D) = qp (D) qr (D). If G| (D) and G− (D) are rational
n
|
ν≡
νi .
(18) delay free generator matrices, then qp (0) = 0, ∀p, and
⊗
−
qr (0) = 0, ∀r. Thus, ∀i qi (0) = 0, i.e., G⊗ (D) is delay
i=1
free.
3) The memory m is the maximum of all constraint lengths
Theorem 4: If G| (D) and G− (D) are systematic generator
matrices, the generator matrix of the product convolutional
m ≡ max νi .
(19) code G⊗ (D) is systematic.
i
Proof: Let G| (D) = (Ik| , R| (D) and G− (D) =
(Ik− , R− (D), where Ik| and Ik− are k | × k | and k − × k −
IV. P ROPERTIES OF THE DIRECT PRODUCT CODE
identity matrices, and R| (D) and R− (D) are k | × (n| − k | )
GENERATOR MATRIX
and k − × (n− − k − ) matrices with rational elements.
Using these deﬁnitions we can state the following properties
Following the encoding procedure given by (5), it is clear
of the generator matrices of product convolutional codes.
that for any information k | × k − matrix U (D) (4) over F (D),
Theorem 2: Let G| (D) and G− (D) be polynomial generator the resulting codeword n| × n− matrix C(D) (5) includes
matrices with memory m| and m− and overall constraint a k | × k − submatrix in the ﬁrst position which corresponds
length ν | and ν − , respectively. The memory m⊗ and overall exactly to U (D). Then, it is obvious that the generator matrix
constraint length ν ⊗ of the generator matrix G⊗ (D) of the G⊗ (D) of the product code is a systematic generator matrix.
product convolutional code are
|
Theorem 5: Let G⊗ (D) = G1 (D) ⊗ G− (D) and
1
1
|
G⊗ (D) = G2 (D) ⊗ G− (D) be rational generator matrices.
⊗
|
−
2
2
m =m +m ,
(20)
|
|
If G1 (D) is equivalent to G2 (D) and G− (D) is equivalent
1
−
⊗
to G2 (D), then G1 (D) and G⊗ (D) are equivalent.
2
and
|
|
Proof: G1 (D) = T | (D) G2 (D) and G− (D) =
1
⊗
− |
| −
−
−
|
ν =k ν +k ν .
(21) T (D) G2 (D) where T (D) and T − (D) are nonsingular
matrices of size k | × k | and k − × k − , respectively. Thus,
Proof: Since the resulting matrix G⊗ (D) is the direct
product of the component matrices (10), the constraint length
|
G⊗ (D) = G1 (D) ⊗ G− (D)
|
⊗
−
1
1
of the i-th row of G⊗ (D) is νi = νp +νq , for the correspond|
= (T | (D) G2 (D)) ⊗ (T − (D) G− (D))
|
−
2
ing rows p and q of G (D) and G (D), respectively. Thus,
|
⊗
= (T | (D) ⊗ T − (D))(G2 (D) ⊗ G− (D))
2
the memory m of the product convolutional code generator
= T ⊗ (D)G⊗ (D)
2
matrix G⊗ (D) is given by:
(24)
T | (D) and T − (D) are nonsingular. Then, T ⊗ (D) =
⊗
m⊗ = max{νi }
T | (D) ⊗ T − (D) is nonsingular. In fact, |T ⊗ (D)| =
i
|
−
|
−
|T | (D) |k |T − (D) |k = 0. Thus, (T ⊗ (D))−1 exists and
= max{(νp + νq )}
p,q
⊗
(22) T (D) is nonsingular.
|
−
= max{νp } + max{νq }
Since T ⊗ (D) is a k | k − ×k | k − nonsingular matrix, G⊗ (D)
p
q
1
is equivalent to G⊗ (D).
= m| + m−
2

4

Theorem 6: If G| (D) and G− (D) are basic encoding
matrices, the generator matrix of the product convolutional
code G⊗ (D) is a basic encoding matrix.
Proof: If G| (D) and G− (D) are polynomial, then
⊗
G (D) is polynomial. If G| (D) and G− (D) are polynomial
and have polynomial inverses (basic), then G⊗ (D) has a
polynomial inverse. In fact, being G⊗ (D) = G| (D)⊗G− (D),
it follows that G⊗ (D)−1 = G| (D)−1 ⊗ G− (D)−1 .
Theorem 7: If G| (D) and G− (D) are minimal basic encoding matrices, the generator matrix of the product convolutional
code G⊗ (D) is a minimal basic encoding matrix.
Proof: Let G(D) be a basic encoding matrix, and
[G(D)]h be a (0, 1)-matrix with 1 in the position (i, j) where
deg(gi,j (D)) = νi (see (17)) and 0 otherwise.
If G| (D) and G− (D) are minimal basic, [G| (D)]h and
[G− (D)]h have full rank [12]. By the deﬁnition of the Kronecker product [7], the maximum degree in every row of the
resulting matrix G⊗ (D) will appear in the elements that are
the product of the elements of highest degree in each row
corresponding to G| (D) and G− (D). Then,
[G⊗ (D)]h = [G| (D)]h ⊗ [G− (D)]h

their equivalent rational generator matrices. Thus, being the
overall constraint length ν ⊗ of G⊗ (D) = G| (D) ⊗ G− (D)
given by (21) in Theorem 2, and given that, if the constituent
encoders are equivalent, also the corresponding direct product
encoders are equivalent (Theorem 5), it follows that if G| (D)
and G− (D) are canonical generator matrices also G⊗ (D) is
canonical.
A canonical generator matrix has the following important
properties [12]:
• A canonical generator matrix is minimal.
• A canonical generator matrix is a canonical encoding
matrix.
• A rational matrix G(D) is canonical if it is minimal and
has the global predictable valuation property (GPVP).
V. C ONCLUSIONS
The algebraic description of convolutional codes allows us
to apply the various methods for combining block codes to
convolutional codes. In this work, one of these combining
methods, the direct product, has been considered. We have
given a formal and simple deﬁnition of a product convolutional
code. In addition, it was possible to determine expressions for
the generator matrices in a simple form. The encoder properties were derived based on the properties of the horizontal
and vertical constituent codes.

(25)

Considering the rank of the resulting matrix,
rank[G⊗ (D)]h = rank[G| (D)]h rank[G− (D)]h = k | k −
(26)
Thus, [G⊗ (D)]h has full rank. Therefore, G⊗ (D) is minimal basic.
A minimal basic encoding matrix has the following important properties [12]:
1) A minimal-basic encoding matrix is canonical.
2) A minimal encoding matrix is noncatastrophic.
3) Every minimal basic encoding matrix is a minimal
encoding matrix.
4) The controller canonical form of a minimal basic encoding matrix is a minimal encoder.
Thus, if we construct a product convolutional code from
two codes, encoded with minimal basic encoding matrices,
the resulting generator matrix is a non-catastrophic encoding
matrix, the controller canonical form of the encoding matrix
is a minimal encoder and the corresponding Forney trellis of
the code is a minimal trellis.
Since the position of minimal basic encoding matrices
within the class of polynomial generator matrices corresponds
to that of canonical encoding matrices within the class of rational generator matrices [12], we state and prove the following
theorem, too.
Theorem 8: If G| (D) and G− (D) are canonical generator
matrices, the generator matrix of the product convolutional
code G⊗ (D) is a canonical generator matrix.
Proof: A canonical generator matrix G(D) is a rational
generator matrix whose overall constraint length ν is minimal
over all equivalent rational generator matrices.
If G| (D) and G− (D) are canonical generator matrices, their
overall constraint lengths ν | and ν − are minimal over all

R EFERENCES
[1] F. J. MacWilliams and N. J. Sloane, “The theory of Error Correcting
Codes”, North-Holland, Amsterdam, 1992.
[2] P. Elias, “Error Free Coding”, IRE Transactions on Information Theory,
Vol. PGIT-4, September 1954, pp. 29-37.
[3] V. Sidorenko, C. Medina, and M. Bossert, “From Block to Convolutional
Codes using Block Distances”, Proc. of the IEEE 2007 International
Symposium on Information Theory, ISIT ’07, Nice, France, June 24-29,
2007, pp. 2331-2335.
[4] C. Berrou, A. Glavieux, and P. Thitimajshima, “Near Shannon limit error
correcting coding and decoding: Turbo codes,” in Proceedings of the IEEE
International Conference on Communications, Geneva, Switzerland, May
1993, pp. 1064–1070.
[5] S. Benedetto, D. Divsalar, G. Montorsi and F. Pollara, “Serial concatenation of interleaved codes: performance analysis, design and iterative
decoding”, IEEE Transactions on Information Theory, Vol. 44, n. 3, May
1998, pp. 909-926.
[6] S. H¨ st, R. Johannesson, and V. Zyablov, “Woven Convolutional Codes
o
I: Encoder Properties”, IEEE Transactions on Information Theory, Vol.
48, No. 1, January 2002, pp. 149-161.
[7] M. Bossert, C. Medina, and V. Sidorenko, “Encoding and distance
estimation of product convolutional codes”, Proc. of the IEEE 2005
International Symposium on Information Theory, ISIT ’05, Adelaide,
Australia, September 4-9, 2005, pp. 1063-1067.
[8] G. D. Forney, Jr., “Convolutional codes 1: Algebraic structure”, IEEE
Trans. Inf. Theory, Vol. 16, November 1970, pp. 720-738.
[9] F. Vatta, A. Schiavi, V. Sidorenko, and M. Bossert, “Termination and
tailbiting of direct product convolutional codes”, Proc. of the IEEE 2009
Information Theory Workshop, ITW ’09, Taormina, Italy, October 11 16, 2009, pp. 213-217.
[10] F. Vatta, V. Sidorenko, and M. Bossert, “Termination and tailbiting of
rate-k/n direct product convolutional codes”, Proc. of the 2010 IEEE
International Symposium on Information Theory, ISIT’10, Austin, Texas,
U.S.A., June 13 - 18, 2010, pp. 2023-2027.
[11] W.-H. Steeb, Kronecker Product of Matrices and Applications, BIWissenschaftverlag, Mannheim, Wien, Zurich, 1991.
[12] R. Johannesson and K. Sh. Zigangirov, Fundamentals of Convolutional
Coding, IEEE Press, Piscataway, New Jersey, 1999.

5

