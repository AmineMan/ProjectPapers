Title:          C:/Users/Owner/Dropbox/FabianManabu/LPBOUND/isit/final/isit.dvi
Creator:        dvips(k) 5.96dev Copyright 2007 Radical Eye Software
Producer:       Appligent StampPDF Batch, version 5.1
CreationDate:   Sat May 19 00:57:23 2012
ModDate:        Tue Jun 19 12:56:37 2012
Tagged:         no
Pages:          5
Encrypted:      no
Page size:      612 x 792 pts (letter)
File size:      322573 bytes
Optimized:      no
PDF version:    1.6
ISIT'2012 1569561713

Linear Programming Upper Bounds on Permutation
Code Sizes From Coherent Conﬁgurations Related
to the Kendall-Tau Distance Metric
1 Research

Fabian Lim1 and Manabu Hagiwara2
Laboratory of Electronics, Massachusetts Institute of Technology, Cambridge, MA 02139
2 National Institute of Advanced Industrial Science and Technology
Central 2, 1-1-1 Umezono, Tsukuba City, Ibaraki, 305-8568, JAPAN
Email: ﬂim@mit.edu, hagiwara.hagiwara@aist.go.jp

Abstract—Recent interest on permutation rank modulation
shows the Kendall-tau metric as an important distance metric.
This note documents our ﬁrst efforts to obtain upper bounds on
optimal code sizes (for said metric) ala Delsarte’s approach. For
the Hamming metric, Delsarte’s seminal work on powerful linear
programming (LP) bounds have been extended to permutation
codes, via association scheme theory. For the Kendall-tau metric,
the same extension needs the more general theory of coherent
conﬁgurations, whereby the optimal code size problem can be
formulated as an extremely huge semideﬁnite programming
(SDP) problem. Inspired by recent algebraic techniques for
solving SDP’s, we consider the dual problem, and propose an
LP to search over a subset of dual feasible solutions. We obtain
modest improvement over a recent Singleton bound due to Barg
and Mazumdar. We regard this work as a starting point, towards
fully exploiting the power of Delsarte’s method, which are known
to give some of the best bounds in the context of binary codes.

theory of coherent conﬁgurations (CC), which instead deliver
semideﬁnite programming (SDP) formulations. The matrices
in these SDP’s turn out to be of unwieldy size, but recent
work [12], [13], [14] suggest possible approaches. One may
exploit the algebraic structure of the CC’s, to only work with
block-diagonalized (and possibly much smaller) versions of
these matrices. To our knowledge, such recent techniques are
new in the area of permutation codes. However, the solution
is not straight-forward. As code lengths increase, the CC’s
(related to the Kendall-tau metric) become huge quickly,
motivating the techniques presented in this preliminary report.
While we believe to be presently unable to fully exploit
the power of SDP bounds, we show some initial success. We
consider the dual problem (also a SDP), and use an LP to
search over a subset of feasible solutions. We obtained modest improvement over a recently published Singleton bound
in [6]. The reduced complexity allows us to compute up to
permutation codes of length 11 (where the matrices were
previously of order 11 factorial). Certain bottlenecks, if solved,
could allow computation for longer codes. As it stands, our
proposed LP bounds perform poorer than known Hamming
bounds [6], and it remains to see how far sophisticated SDPbased approaches can ultimately bring us. This note aims to
motivate new research to resolve this open question.

Index Terms—association schemes, coherent conﬁgurations,
permutations, linear programming, semideﬁnite programming

I. I NTRODUCTION
A permutation code is designed to only allow certain
pairwise distances between any two codewords. These codes
have been studied in various contexts, e.g., group codes [1],
signal modulation [2], [3], vector quantization [4], rank modulation [5], [6], cost-constrained transpositions [7], etc. This
work is motivated by a recent study on a fundamental coding
problem. In [6] they looked at optimal code sizes with respect
to the Kendall-tau distance metric. This metric is important to
rank modulation and its applications, e.g., ﬂash memories.
For binary codes, Delsarte’s optimization-based methods [8]
give some of the best known bounds [9]. For permutation
codes, we observe during initial experiments (for very small
lengths) that Delsarte-like methods outperform Hamming
(sphere packing) bounds [6], [10]. Our interest is to investigate,
if this improvement carries over for larger codes. Tarnanen
extended Delsarte’s work over to permutation codes [11],
however only for the Hamming metric (and other metrics
with similar symmetries). The novelty here is to consider the
Kendall-tau metric, and as pointed out in [6], lacks required
symmetry to straight-forwardly apply Tarnanen’s techniques.
Delsarte’s (and Tarnanen) techniques are based on association schemes, from which linear programming (LP) formulations (of the optimal code size problem) are obtained. For the
Kendall-tau metric, one needs to consider the more general

II. BACKGROUND
A. Optimal Code Size Problem and Two Metrics
Let Sn denote the symmetric group on a set {1, 2, . . . , n}
and dist(, ) be a distance metric on Sn . A subset V of Sn is
an (n, δmin ) permutation code (with respect to dist(,)), if for
any g, h ∈ V such that g = h, we have dist(g, h) ≥ δmin .
Deﬁnition 1 (Optimal code size problem). Let dist(, ) be a
distance metric on the symmetric group Sn . Let δmin ≥ 1. The
following problem is the optimal code size problem.
max #V

V⊆Sn

(1)

s.t. dist(g, h) ≥ δmin for all g, h ∈ V where g = h,
and #V denotes the cardinality of the set V. Denote µ(n, δmin )
to be the maximal cardinality achieved by (n, δmin ) codes, i.e.,
µ(n, δmin ) equals the optimal value of the above problem.
The image of i by g is denoted g(i). The inverse of g
is denoted g −1 . The product of permutations g and h is

F. Lim recieved support from NSF Grant ECCS-1128226.

1

d

denoted gh, whereby (gh)(i) = g(h(i)). Most literature (e.g.,
Tarnanen [11]) consider the Hamming metric
∆

dist(g, h) = #{1 ≤ x ≤ n : (g −1 h)(i) = i},

ii) the sum i=1 Ai equals the all ones matrix.
iii) for any Ai , there exists some Ai′ that satisﬁes AT = Ai′ .
i
iv) for any i, j ∈ {1, 2, · · · , d}, there exists numbers pk that
ij
satisfy Ai Aj = d pk Ak .
k=1 ij

(2)

i.e., the Hamming distance dist(g, h) equals the number of
moved points of g −1 h. For the direct product group Sn × Sn ,
∆
deﬁne its action on Sn , as (α, β) · g = αgβ −1 , where (α, β) ∈
Sn × Sn and g ∈ Sn . For any subgroup G of Sn × Sn , a metric
dist(, ) on Sn is G-invariant if for any g, h ∈ Sn , we have
dist(g, h) = dist((α, β) · g, (α, β) · h) for all (α, β) ∈ G. The
Hamming metric (2) can be veriﬁed to be (Sn × Sn )-invariant.
The length of a permutation g, denoted length(g), equals
the minimum integer r satisfying g = α1 α2 . . . αr whereby
αi are adjacent transpositions in Sn . For rank modulation [5],
[6] we consider the Kendall-tau metric, given as
∆

dist(g, h) = length(g −1 h).

A coherent conﬁguration (CC) denoted (G, Sn ), refers
to the set {A1 , A2 , · · · , Ad } of corresponding adjacency matrices. A CC with the additional property pk = pk is an
ij
ji
association scheme; in this special case, Delsarte showed how
combinatorial properties can deliver linear programming (LP)
bounds [8]. Construct two CC’s related to the G-invariances of
the Hamming and Kendall-tau metrics. For the former metric,
set G = Sn ×Sn and call (Sn ×Sn , Sn ) the conjugacy CC - the
name comes from [11]. For the latter metric, set G = Sn × Ψn
and term (Sn × Ψn , Sn ) the length CC. Let RSn ×Sn denote
the set of real matrices and index set Sn . Write ASn ,i and
AΨn ,i for adjacency matrices of conjugacy, and length CC.

(3)

There exists a unique element w0 , termed the longest element,
that satisﬁes length(w0 ) = n(n − 1)/2. Then w0 is an
−1
involution, i.e., w0 = w0 , and dist(g, h) = dist(gw0 , hw0 ),
see [15], p. 119. Denote a subgroup {e, w0 } of Sn by Ψn ,
where e is the identity element of Sn . In general, the Kendalltau metric is (Sn × Ψn )-invariant.
A permutation g written as g = (123) means g(1) = 2,
g(2) = 3 and g(3) = 1. Note (12), (23), (13) are transpositions, in particular the ﬁrst two are adjacent transpositions.

Example 2. The matrices in RS3 ×S3 corresponding to the
conjugacy and length CC (the indexing on S3 is done in the
same order that appears in Eg. 1), are written as follows. First
ASn ,1 = AΨn ,1 = I, where I is the identity matrix. Next




0 1 1 0 0 1
0 1 1 0 0 0
1 0 0 1 0 0
1 0 0 1 1 0






1 0 0 1 1 0
 , AΨn ,2 =  1 0 0 0 1 0  .
ASn ,2 = 
0 1 0 0 0 1
0 1 1 0 0 1




0 0 1 0 0 1
0 1 1 0 0 1
1 0 0 1 1 0
0 0 0 1 1 0
By Theorem 1, ASn ,3 = J − I − ASn ,2 , here J has all ones.
Finally, it so happens that we get AΨn ,3 = ASn ,3 and AΨn ,4 =
ASn ,2 − AΨn ,2 . Matrices ASn ,1 to ASn ,3 corresponding to
Hamming distances 0, 2, 3, and AΨn ,1 to AΨn ,4 to Kendalltau distances 0, 1, 2, 3.

Example 1. Consider S3 with elements e, (12), (23), (123),
(132), (13), and the Hamming metric. The minimum distance
between any two non-equal permutations is 2. For δmin = 1
and 2 we have µ(n, δmin ) = #S3 . For δmin = 3 the code V
with the optimal size satisﬁes V = {e, (123), (132)}. Check
dist(e, (123)) = dist(e, (132)) = 3, and dist((123), (132)) =
dist(e, (123)−1 (132)) = dist(e, (123)) = 3.
The minimum possible non-zero Kendall-tau pairwise distance is 1. For δmin = 1, we have µ(n, δmin ) = #S3
as before. For δmin = 2 the optimal code satisﬁes V =
{e, (123), (132)}. Check dist(e, (123)) = length((123)) = 2,
where (123) = (12)(23). For δmin = 3 the optimal code
satisﬁes V = {e, (13)}, where (13) is the longest element w0
in S3 and length((13)) = 3 (here (13) = (12)(23)(12)).

The focus here is on the length CC, related to the Kendalltau metric. The conjugacy CC (related to the Hamming metric)
is actually an association scheme, and is treated in [11]; the
recollection is because of connections exploited later.
III. S EMIDEFINITE P ROGRAMMING (SDP) B OUNDS
A symmetric matrix M in RSn ×Sn is positive semideﬁnite,
if all its eigenvalues are non-negative. We now use CC’s to
formulate the relaxation of the optimal code size problem.
˜ ˜
˜˜
By iii), Theorem 1, a set {A1 , A2 , · · · , Ad } of symmetrized
˜
adjacency matrices are obtained, whereby d ≤ d. If Ai is
T
not symmetric, then ﬁnd Ai′ such that Ai = Ai′ , and set
˜
˜
Aj = Ai + Ai′ . Similarly the symmetrized orbitals ∆i are
˜ j = ∆i ∪ ∆i′ if Aj = Ai + Ai′ . Note
˜
obtained by setting ∆
˜
both (g, h) and (h, g) belong to the same ∆j , and dist(g, h) =
dist(h, g). Thus by G-invariance of dist(, ) set δj = dist(g, h)
˜
for any (g, h) ∈ ∆j , since dist(g, h) = dist(g ′ , h′ ) for any
′
′
˜ j . The values δj are called orbit-distances
(g, h), (g , h ) ∈ ∆
(with respect to a G-invariant metric dist(, )). If G acts
˜
transitively on Sn , then by convention ∆1 = {(g, g) : g ∈ Sn },
thus δj ≥ 1 for all j ≥ 2. The properties of the CC’s can
simplify the following optimizations.

B. Coherent Conﬁgurations (CC)
We now describe objects used to formulate relaxations of
(1). For a subgroup G of Sn × Sn , deﬁne an induced action
∆
of G on Sn × Sn , as g · (x, y) = (g(x), g(y)) where g ∈ G
and x, y ∈ Sn . An orbit of this induced action is termed an
orbital. These orbitals ∆1 , ∆2 , · · · , ∆d of the induced action
partition {(x, y) : x, y ∈ Sn } = ∪d ∆i . If the action of G on
i=1
Sn is transitive, we use the convention ∆1 = {(x, x) : x ∈
Sn }. For each orbital ∆i , we correspond an adjacency matrix
Ai as follows. Here Ai is a 0-1 matrix, whose rows/columns
are indexed by Sn , and we have (Ai )x,y = 1 if and only if
(x, y) ∈ ∆i . Let AT denote the transposed matrix of Ai .
i
Theorem 1 (c.f. [16], p. 52). Let G be a group which acts
on Sn transitively. For the induced action of G on Sn × Sn ,
the adjacency matrices Ai corresponding to the d orbitals ∆i ,
satisfy
i) A1 equals the identity matrix.

Deﬁnition 2 (Primal SDP, (G, Sn ) and δmin ). Let G be a
group which acts on Sn transitively and dist(, ) a G-invariant
distance metric on Sn . Let δj be the orbit-distances w.r.t.

2

TABLE I
[I NITIAL E XPERIMENTS ] SDP B OUNDS FOR 3 ≤ n ≤ 5
n=3
δmin
1
2
3

b∗
1
6
3
2

δmin
1
2
3
4
5
6

b∗
1
24
12
5
3
2
2

†
‡

TABLE II
N UMBER d OF ADJACENCY MATRICES

n=5

SB HB
6
6
6
6
2
2
n=4
SB HB
24 24
24 24
24
6
6
6
6
2
2
2

Search
6
3
2
Search
24
12
5
3
2
2

b∗
1
120
60
22
14
7
5
3
2
2
2

δmin
1
2
3
4
5
6
7
8
9
10

SB
120
120
120
120
24
24
24
6
6
2

HB
120
120
24
24
8
8
4
4
2
2

n

(G, Sn ) and dist(, ). Deﬁne the semideﬁnite programming
(SDP) problem correp. to (G, Sn ) and some δmin ≥ 1, as
max

Tr(JM )

(4)

s.t. M is positive semideﬁnite, and Tr(M ) = 1,
˜
˜
Tr(Aj M ) ≥ 0, for 2 ≤ j ≤ d,
˜
˜j M ) = 0, for 2 ≤ j ≤ d with δj < δmin ,
Tr(A
˜
where Aj is a corresponding symmetrized adjacency matrix,
J is the all-one matrix, and Tr is the trace function.
Proposition 1. Let G be a group which acts on Sn transitively
and dist(, ) a G-invariant distance metric on Sn . Let δmin ≥
1. Then, the optimal objective value of (4) upper bounds the
optimal objective value of (1) for dist(, ) and δmin .
The SDP (4) is a relaxation of the optimal code size problem
(1), see [17] for the proof. The optimal value of the SDP (4)
is at most #Sn , as for any feasible M , we have Tr(JM ) ≤
Tr(J) = #Sn . Software like SeDuMi [18] can solve SDP’s.
Example 3. Consider G = S3 × Ψ3 , whereby the Kendall˜
˜
tau metric is G-invariant. Let ∆1 to ∆4 correspond to AΨn ,1
to AΨn ,4 (all symmetric). Using SeDuMi we solve for δmin = 1,
2 and 3, and get the optimal solutions
1
1
1
· J,
· (AΨn ,1 + AΨn ,3 ),
· (AΨn ,1 + AΨn ,4 ).
6
6
6
which correspond to optimal objective values 6, 3 and 2.

b1

(5)

˜
s.t. bj ≤ 0 for 2 ≤ j ≤ d with δj ≥ δmin ,

Len.

Conj.

˜
dΘn

8
9
10
11

10558
92126
912908
9998008

22
30
42
56

171
860
1052
7578

i=1

˜
d

Recall that the all-ones matrix J is also in AG,Sn .
To build an intuition on how such a strategy is possible,
we ﬁrst connect with the LP bound of the conjugacy CC
(Sn × Sn , Sn ) described in [11]. To clarify between conjugacy
and length CC’s, we respectively denote ASn ,i and AΨn ,i for
adjacency matrices, and dSn and dΨn for their numbers.

˜
bj Aj − J is positive semideﬁnite,
j=1

to be the dual problem of the SDP in Deﬁnition 4.
˜

Any feasible solution b in Rd to the dual program (5),
provides an upper bound to the optimal objective value of the
SDP (4), see [14]; we have the following chain of inequalities
Tr(JM ∗ ) ≤ b∗ ≤ b1 ,
1

n

8
21
34
122

Using “duality” we consider the feasible solutions b to (5)
(for some G-invariant dist(, ) and δmin ≥ 1) that furnish upper
estimates b1 to µ(n, δmin ), see (6) and Proposition 1. While
“duality” ideas are not new, the novelty here is to “guess
a good subset” of feasible solutions (in the dual program)
described by a manageable number of linear equations, and
use an LP to optimize over them. For a CC (G, Sn ), a feasible
solution b corresponds to a positive semideﬁnite matrix in the
following set1


˜
 d

∆
˜
˜
AG,Sn =
bj Aj : bj ∈ R, for all 1 ≤ j ≤ d . (7)



Deﬁnition 3 (Dual problem, (G, Sn ) and δmin ). Let G be a
group which acts on Sn transitively and dist(, ) a G-invariant
distance metric on Sn . Let δj be the orbit-distances w.r.t.
˜
(G, Sn ) and dist(, ). Let Aj be a corresponding symmetrized
adjacency matrix to (G, Sn ). Let δmin ≥ 1. Deﬁne the following
min

˜
dΘn

5
7
11
15

IV. L ENGTH CC: L INEAR P ROGRAMMING (LP) B OUNDS

We need to work with the dual problem to (4).

˜
(b1 ,b2 ,...,bd )∈Rd
˜

Conj.

13
45
230
1388

where M ∗ and b∗ are optimal solns. of (4) and (5), resp.
Our interest in SDP bounds is motivated by initial experimentation. Table I shows optimal objective values of (5)
obtained using SeDuMi, for (small) n = 3 to 5. We compare
with two other bounds, i) a Singleton bound (SB) recently
published in [6], and ii) a Hamming bound (HB) obtained
by sphere packing, see [6]. Ball-sizes for HB were obtained
from exact numbers of permutations with k inversions [10].
For cases shown, SDP bounds always perform the best, with
some tightness veriﬁed by limited exhaustive searches. Given
that optimization-based bounds are (some of) the best-known
for binary codes, e.g. see discussion in [9], it is not unusual to
ask: for permutation codes, are SDP bounds always better
for all n?
To seek an answer we should compute for larger n, thus
motivating the proposed method in the next section. When Sn
gets large, problems (4) and (5) become increasingly difﬁcult
˜
to solve, as the matrices Aj have order #Sn . Our method is
˜
inspired by recent work [12], [13], [14], which show that if Aj
˜
come from a CC, then the Aj can be replaced (in (4) and (5))
by block-diagonalized versions - exact details omitted here.
This may result in huge complexity reduction, e.g., [14] shows
how SDP’s related to the conjugacy CC reduces to simpler LP
problems. The caveat is that number of matrix blocks (obtained
from diagonalization) is at least d, the number of adjacency
matrices Ai , see [12]. Unfortunately for the length CC, this
number quickly becomes large for increasing n, see Table II.
Thus in our case it becomes difﬁcult to directly apply the
techniques in [12], and modiﬁcations of the ideas are needed.

Singleton bound (SB), published in [6], equation (5).
Hamming bound (HB) from ball-size estimates, see [10], [6].
Note: Above table created by taking numerical ﬂoor.

M∈RSn ×Sn

Len.

4
5
6
7

Search
120
3
2
2
2
2

1 The set A
Sn ×Ψn ,Sn is usually known as the adjacency algebra (over R)
of the CC (G, Sn ), which has the properties of a matrix-∗ algebra [16].

(6)

3

˜
computed using the action of Sn ×Sn on Sn . Let AΘn ,ℓ denote
the symmetrized adjacency matrices belonging to the CC
˜
˜
(Sn ×Θn , Sn ), where there are dΘn of them. Note dΘn ≤ dΨn .
˜
Lemma 1. Let ASn ,i and AΘn ,ℓ be the symmetrized adjacency
matrices belonging to the conjugacy CC and (Sn × Θn , Sn ),
˜
respectively. Let W be deﬁned as before. For 1 ≤ ℓ ≤ dΘn
and 1 ≤ i ≤ 2dSn there exists 0-1 coefﬁcients tℓ,i that satisfy

We claim that the set ASn ×Sn ,Sn is a subset of ASn ×Ψn ,Sn ,
seen by showing each Ai to lie in ASn ×Ψn ,Sn . Observe that
Sn × Ψn is a subgroup of Sn × Sn , hence the orbitals of
the length CC, lie within those of the conjugacy CC. In other
dSn
words, there exists index subsets ISn ,i , where ∪i=1 ISn ,i =
{1, 2, · · · , dΨn }, such that ASn ,i = j∈ISn ,i AΨn ,j hold (for
all i). The claim ASn ,i ∈ ASn ×Ψn ,Sn follows if ASn ,i is a
symmetric matrix, see property i) of the following theorem
from [11].

˜
dΘn

ℓ=1

˜
tℓ,dSn +i AΘn ,ℓ . (9)
ℓ=1

See [17] for proof. The coefﬁcients tℓ,i satisfying (9) are
used to state the following main theorem. For Θn ⊆ Sn ,
˜
˜
˜
let index subsets IΘn ,ℓ satisfy AΘn ,ℓ =
˜
j∈IΘn ,ℓ AΨn ,i .
Using orbit-distances δj w.r.t. (Sn × Ψn , Sn ) and the Kendalltau metric dist(, ), deﬁne constants γℓ that satisfy γℓ =
˜
max{δj : j ∈ IΘn ,ℓ }.

The numbers dSn , tabulated in Table II, equal the partition
dΨn
˜
number of n, see [11]. Consider a matrix
j=1 bj AΨn ,j
in ASn ×Ψn ,Sn , that for some a ∈ RdSn , can be exd
pressed as
i=1 ai ASn ,i . Theorem 2 allows us to further
dΨn
dSn
T
˜
express
j=1 bj AΨn ,j =
j=1 zj · (U Ij U ) where zj =
dSn
dΨn
˜
i=1 pi,j ai . Then
j=1 bj AΨn ,j − J is positive semideﬁnite
dSn
(see (5)) if the linear constraints i=1 pi,j ai ≥ cj hold for all
j, for constants cj in iii). Intuitively, Theorem 2 is an explicit
“diagonalization” of all matrices in the subset ASn ×Sn ,Sn of
ASn ×Ψn ,Sn , and facilitates checking of positive semidef.
A simple extension of the “diagonalization” idea to the
following larger subset of matrices, works reasonably well.
Property ii) of Theorem 2 implies iii), as symmetric matrices that commute share common eigenspaces. As such, we
desire2 a subset B of ASn ×Ψn ,Sn , with the property that any
M ∈ B, commutes with any M ′ ∈ ASn ×Ψn ,Sn . Thus any two
matrices in B commute. Such a subset B may be obtained


dSn

dSn
B=
(ai ASn ,i ) +
(adSn +i ASn ,i W ) : a ∈ R2dSn ,(8)


i=1

˜
tℓ,i AΘn ,ℓ , ASn ,i W =

ASn ,i =

Theorem 2 (c.f. [11]). Let (Sn ×Sn , Sn ) denote the conjugacy
CC, where (Sn × Sn , Sn ) = {ASn ,i : 1 ≤ i ≤ dSn }, and
ASn ,1 = I. Then all of the following hold for ASn ,i :
˜
i) symmetry, i.e., ATn ,i = ASn ,i (or ASn ,i = ASn ,i ).
S
ii) commutativity, i.e., ASn ,i ASn ,j = ASn ,j ASn ,i for all i, j.
iii) diagonalization by an orthonormal matrix U in RSn ×Sn ,
dSn
i.e., U T ASn ,i U = j=1 pi,j · Ij for some pi,j ∈ R and
0-1 diagonal matrix Ij .
dSn
dSn
• I = ASn ,1 = j=1 U Ij U T , therefore j=1 Ij = I.
dSn
d
T
•
i=1 ASn ,i = J, so U JU =
j=1 cj · Ij where
d
cj = i=1 pi,j . By convention c1 = #Sn (the only
non-zero eigenvalue of J) and cj = 0 for j ≥ 2.

˜
dΘn

i=1

where W is an orthonormal, 0-1 matrix in RSn ×Sn , that sat−1
isﬁes (W )x,y = 1 if and only if yw0 = x for any x, y ∈ Sn .
From (8) we see B contains the set ASn ×Sn ,Sn considered in
Theorem 2. Also by the previous corresponding between Bj
and the orbital ∆j (see [17]), one can check W commutes
with all of ASn ×Ψn ,Sn (and each ASn ,i ). Because the longest
−1
element satisﬁes w0 = w0 , thus W T = W −1 = W . So
ASn ,i W are symmetric, and B is a set of symmetric matrices.
One technical lemma, that connects (8) with the dual
problem (5), stands in way of ﬁnally describing our LP
bound. This lemma involves a special subgroup Θn of Sn ,
where Θn is also involved in a few ﬁnal deﬁnitions. Let
Θn = {α ∈ Sn : (α, α) · w0 = w0 }, where (α, α) · w0 is

Theorem 3 (LP Bound on (Sn × Ψn , Sn ) and δmin ). Let W
be the 0-1 orthornormal matrix deﬁned as before.
For 1 ≤ i, j ≤ dSn , let constants pi,j , cj and matrices
U, Ij be obtained from Theorem 2. Let matrices M1,j and
M2,j satisfy M1,j = 1 (U Ij U T )(I + W ) and M2,j =
2
1
T
2 (U Ij U )(I − W ).
˜
For 1 ≤ ℓ ≤ dΘn , let the constants γℓ be deﬁned as above.
For 1 ≤ i ≤ 2dSn , let the coefﬁcients tℓ,i satisfy (9). Let a∗
in R2dSn solve the following LP problem
2dSn

min

2dSn

tℓ,i · ai ≤ 0

s.t.
dSn

(a1 ,a2 ,...,a2dS )∈R2dSn i=1
n

t1,i · ai

(10)

˜
for 2 ≤ ℓ ≤ dΘn with γℓ ≥ δmin ,

i=1

(ai + adSn +i ) · pi,j ≥ cj for 1 ≤ j ≤ dSn with M1,j = 0
i=1
dSn

(ai − adSn +i ) · pi,j ≥ cj for 1 ≤ j ≤ dSn with M2,j = 0
i=1

Let b∗ and µ(n, δmin ) respectively denote the optimal objective
1
values of the dual problem (5), and the optimal code size
problem (1), for G = Sn × Ψn and the Kendall-tau metric
dist(, ) and δmin . Then we have the following inequalities
2dSn

µ(n, δmin ) ≤ b∗ ≤
1

t1,i · a∗ .
i
i=1

As promised our main result Theorem 3 furnishes an LP
bound on the optimal code size µ(n, δmin ). See [17] for proof.
˜
˜
The number dΘn of matrices AΘn ,ℓ is given in the previous
˜Θ > dS , but dΘ is much reduced
˜
Table II, where observe d n
n
n
from dΨn . Table III shows our computed LP bounds whereby
n is between 3 and 11. Our proposed LP bound fails to
completely answer the question posed (at the end) of Section
III, but some initial success is obtained. Observe that our LP
bound is at least as tight as the SB in the places highlighted
in bold font. Improvements are mainly obtained when δmin is
close to n(n − 1)/2. Interestingly, these two bounds are useful
for similar ranges of δmin (the SB is known to be non-trivial
only when δmin ≥ n, see [6]). For the case n = 3 the LP and
SDP bounds are equal, though unfortunately for n > 4, our LP

2 Try to show, see [16], pp. 50-51., that A
Sn ,i and ASn ,i W are conjugacysums, and B in (8) is the center of the adjacency algebra (7) for G = Sn ×Ψn .

4

TABLE III
B OUNDS COMPUTED FOR VARIOUS 3 ≤ n ≤ 11.
n=3

n=7

SB†

HB‡

6
6
2

6
6
2

δmin
1
2
3

LP
6
3
2

δmin
3
4
5
6

n=4
LP
SB
24
24
12
6
4
6
2
2

HB
6
6
2
2

δmin
6
7
8
9
10

n=5
LP
SB
120
24
10
24
5
6
2
6
2
2

HB
8
4
4
2
2

δmin
8
9
11
12
13
14
15

n=6
LP
SB
720
120
120
120
27
24
13
24
6
6
4
6
2
2

HB
14
7
4
4
2
2
2

† ‡

,

n=9

δmin
10
11
12
15
16
17
18
19
20
21

LP
5040
630
543
140
75
14
7
3
2
2

SB
720
720
120
120
24
24
24
6
6
2

HB
28
14
14
5
5
3
3
2
2
2

δmin
12
13
14
19
21
22
23
24
25
26
27
28

n=8
LP
SB
40320
5040
5040
5040
4135
720
896
120
384
120
192
120
41
24
21
24
8
24
5
6
2
6
2
2

HB
64
32
32
7
5
5
3
3
2
2
2
2

n = 10

δmin
14
15
16
23
25
27
29
30
31
32
33
34
35
36

LP
362880
45360
32989
7560
2016
1008
186
93
15
9
4
3
2
2

SB
40320
40320
5040
720
720
120
120
120
24
24
24
6
6
2

δmin
16
17
18
27
29
31
35
36
37
38
39
40
41

n = 10
LP
3628800
329891
302400
49371
21098
9735
4995
3900
446
230
55
30
11

SB
362880
362880
40320
5040
5040
720
720
120
120
120
120
24
24

δmin
42
43
44
45

LP
6
3
3
2

SB
24
6
6
2

δmin
18
19
31
33
34
35
37
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55

n = 11
LP
39916800
3326400
359611
193458
177678
94924
66176
33662
26050
11152
8700
6349
3541
222
111
17
11
5
4
3
2
2

SB
3628800
3628800
40320
40320
40320
5040
5040
720
720
720
720
720
120
120
120
120
24
24
24
6
6
2

See footnotes on previous Table I.

bound does worse than the HB, and the performance gap gets
bigger for smaller δmin . Inspired by [6] (which points out three
regions with different asymptotics), it is tempting to conjecture
that different strategies work for cases δmin < n and δmin ≥ n.
The subset searched here works reasonably well for the latter
case, for the former what are the “good” dual-feasible subsets?
One issue: no known efﬁcient method to compute “max.
˜
distances” γℓ , where γℓ = max{δj : j ∈ IΘn ,ℓ }. If one
replaces Θn by Sn in the expression for γℓ , (where ASn ,i =
˜
j∈ISn ,i AΨn ,j ), then [19] has closed-forms for γℓ . Also its
˜
is unclear how large the number #{1 ≤ δℓ ≤ dΘn : δℓ ≥ δmin }
of non-positive constraints could be. No rigorous analysis is
done here, but see [20] for a characterization of Θn .

[4] V. K. Goyal, S. A. Savari, and W. Wang, “On optimal permutation
codes,” IEEE Trans. Inform. Theory, vol. 47, no. 7, pp. 2961–2971,
2001.
[5] A. A. Jiang, R. Mateescu, M. Schwartz, and J. Bruck, “Rank modulation
for ﬂash memories,” IEEE Trans. Inform. Theory, vol. 55, no. 6, pp.
2659–2673, 2009.
[6] A. Barg and A. Mazumdar, “Codes in permutations and error correction
for rank modulation,” IEEE Trans. Inform. Theory, vol. 56, no. 7, pp.
854–858, 2009.
[7] F. Farnoud and O. Milenkovic, “Sorting of permutations by costconstrained transpositions” IEEE Trans. Inform. Theory, vol. 58, no. 1,
pp. 3–23, 2012.
[8] P. Delserte, An algebraic approach to the association schemes of coding
theory, 1st ed. Philips Research Reports, Supplement No. 10, 1973.
[9] M. Navon and A. Samorodnitsky, “Linear programming bounds for
codes via a covering argument,” Discrete Computational Geometry,
vol. 41, no. 2, pp. 199–207, 2007.
[10] B. H. Margolius, “Permutations with inversions,” J Integer Seq, vol. 2,
no. 4, pp. 1–13, 2001.
[11] H. Tarnanen, “Upper bounds on permutation codes via linear programming,” Europ. J. Combinatorics, vol. 20, pp. 101–114, 1999.
[12] C. Bachoc, D. C. Gijswijt, A. Schrijver, and F. Vallentin, Invariant
semideﬁnite programs. Online: http://arxiv.org/abs/1007.2905, 2010.
[13] A. Schrijver, “New code upper bounds from the Terwilliger algebra and
SDP,” IEEE Trans. Inform. Theory, vol. 51, no. 8, pp. 2859–2866, 2005.
[14] M. X. Goemans and F. Rendl, “Semideﬁnite programs and association
schemes,” Computing, vol. 63, pp. 331–340, 1999.
[15] J. E. Humphreys, Reﬂection Groups and Coxeter Groups, 4th ed.
Cambridge University Press, 1990.
[16] E. Bannai and T. Ito, Algebraic Combinatorics I, 1st ed.
Benjamin/Cummings Publishing Co., 1984.
[17] F. Lim and M. Hagiwara, Linear Programming Upper Bounds (extended
version). Online: http://arxiv.org/abs/1202.0241v1, 2012.
[18] J. F. Sturm, “Using SeDuMi 1.02, a MATLAB toolbox for optimization
over symmetric cones,” Opt. Meth. and Soft., vol. 11, no. 1, pp.
625–653, 1999.
[19] M. Geck, S. Kim, and G. Pfeiffer, “Minimal length elements in twisted
conjugacy classes of ﬁnite Coxeter groups,” Journal of Algebra, vol.
229, no. 2, pp. 570–600, Jul. 2000.
[20] B. Brink and R. B. Howlett, “Normalizers of parabolic subgroups
in Coxeter groups,” Inventiones Mathematicae, vol. 136, no. 2, pp.
323–351, Apr. 1999.

V. C ONCLUSION & F UTURE D IRECTIONS
Motivated by recent work on solving SDP’s with algebraic
structure, we formulated the optimal code size problem w.r.t.
Kendall-tau metric as a SDP, and propose using LP to search
for solutions. The problem seems difﬁcult, but we report
modest improvement over a recent Singleton bound.
The interest is to progress toward (possibly) beating known
Hamming bounds, for the cases n ≥ 6 (other than those
shown here). We offer some future directions. As previously
mentioned, it would be nice to analyze the subsets that should
be searched (for δmin < n). Next, one might generalize to
larger subsets where a manageable SDP (not a LP as here) is
used for searching. Finally, one might seek a similar Fouriertype analysis as [9], using representation-theoretic techniques.
R EFERENCES
[1] D. Slepian, “Group codes for the Gaussian channel (Abstr.),” IEEE
Trans. Inform. Theory, vol. 14, no. 2, p. 242, 1968.
[2] ——, “Permutation modulation,” Proc. IEEE, vol. 53, no. 3, pp. 228–
236, 1965.
[3] T. Mittelholzer and J. Lahtonen, “Group codes generated by ﬁnite
reﬂection groups,” IEEE Trans. Inform. Theory, vol. 42, no. 2, pp.
519–528, Mar. 1996.

5

