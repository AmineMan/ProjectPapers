Creator:        TeX
Producer:       Appligent StampPDF Batch, version 5.1
CreationDate:   Fri May 18 11:14:11 2012
ModDate:        Tue Jun 19 12:55:53 2012
Tagged:         no
Pages:          5
Encrypted:      no
Page size:      612 x 792 pts (letter)
File size:      652635 bytes
Optimized:      no
PDF version:    1.6
ISIT'2012 1569566575

Index Coding: An Interference Alignment
Perspective
Hamed Maleki, Viveck Cadambe and Syed Jafar†

S

Abstract—The index coding problem is a multiple unicast wireline communication network where the network is represented by
a directed graph having exactly one link with ﬁnite capacity (also
known as the bottleneck link). There are K independent sources
which share the ingress of this bottleneck link. Correspondingly
there are K destinations which are on the receiving end of the
bottleneck link, with each destination intending to decode the
message of one (unique) corresponding source. Each destination
can have apriori side-information of a (different) subset of the
original source messages. In this paper, we study the capacity of
such a network from the perspective of interference alignment,
and derive information theoretically optimal schemes for a class
of networks. In our ﬁrst main result, we identify the set of
graphs where each user can achieve half rate in the index coding
problem. In a second result, we derive the capacity for a class
of symmetric index coding networks.

Bottleneck

W2

A Wired Two-Unicast Network

Fig. 2. The Butterﬂy Network - A two user index coding problem analogous
to the deterministic broadcast channel depicted in Fig 1. A rate 1 is well known
to be achievable by choosing S = W1 ⊕ W2 .

In the index coding problem (See Fig. 2 for an example
which is analogous to the deterministic broadcast channel
depicted in Fig 1), there are K independent discrete source
messages W1 , W2 , . . . WK . There are K destinations, with
destination i intending to decode source Wi for i ∈ K, where
K = {1, 2, . . . , K}. We assume that each destination has side
information of a certain set of messages apriori. The set of
side information present at receiver i, also referred to as the
set of antidotes, is denoted by Ai ⊂ K − {i}. We denote the
set of messages present as side information at receiver i as
WAi = {Wi : i ∈ Ai }. Each destination receives a common
(broadcast) symbol S ∈ S from a ﬁnite alphabet S that can
be chosen arbitrarily. The goal of the index coding problem is
to design the broadcast alphabet S and the broadcast symbol
S using the messages as S = f (W1 , W2 , . . . , WK ), where the
function f is often referred to as the (index) code. An index
coding scheme is said to be achievable1 if each destination is
able to decode its intended message successfully, i.e., if

Much progress in network information theory can be attributed to the pursuit of capacity of simple-to-describe canonical network communication models. Simplicity in the network
communication models often affords a clear formulation of
techniques involved in the communication system. The focus
of this paper is the index coding problem, which is, arguably,
the simplest open multi-source (non-multicast) wireline network capacity problem, because it has only one link with ﬁnite
capacity. We begin by describing the index coding problem.
Side information
(Antidote)

ˆ
W1

S, W1

W 1 , W2

ˆ
W2
Antidotes

I. I NTRODUCTION

S , W2

ˆ
W1

W1

ˆ
W2

S

H (Wi |S, WAi ) = 0
Side information
(Antidote)

(1)

where H(.) is the entropy function. For a given achievable
coding scheme, rate of transmission for message i is deﬁned
as Ri = H(Wi ) . The capacity region of the index coding
H(S)
problem is deﬁned as the set of all achievable rate tuples
(R1 , R2 , . . . , RK ) and is denoted by C. In this paper, we are
speciﬁcally interested in the highest symmetric achievable rate
in this system, i.e.,
max R

Deterministic Broadcast Channel with Side information

Fig. 1.
A deterministic broadcast channel with cognitive receivers. A
representative two user index coding problem.
† Hamed Maleki and Prof. Syed A. Jafar are with the Center for Pervasive
Communications and Computing (CPCC) at the University of California,
Irvine, CA 92617, USA. Dr. Viveck R. Cadambe is a joint postdoctoral fellow
with the Research Lab of Electronics at Massachusetts Institute of Technology,
and the Electrical & Computer Engineering Department at Boston University.
This work is supported in part by ONR N00014-12-1-0067 and by NSF
CCF-1143982. The authors can respectively be contacted at hmaleki@uci.edu,
viveck@mit.edu and syed@uci.edu

1 Note here that we are restricting our encoding schemes to zero-error
achievable schemes. However, all the results of the paper including the
converses are applicable even under the conventional information theoretic
assumption asymptotically vanishing rate.

1

S = x1 V1 + (x2 + x3 )V2

R = R1 = R2 = . . . RK , and (R1 , R2 , . . . , RK ) ∈ C

x1

Importantly, it is worth noting that the index coding problem
can be described in terms of multi-source network capacity of
a directed graph as shown in Figure 2. In this network, there
is exactly one (directed) link of ﬁnite capacity, since all the
antidotes links can be thought of links with inﬁnite capacities.
Remark: Note that a trivial achievable scheme in the index
coding problem - routing - achieves a symmetric rate of 1/K.
However, as demonstrated by the butterﬂy network (which is a
2 user index coding problem), the antidotes can indeed enable
a higher achievable rate.
Linear Schemes: For a given antidote set, an achievable
coding scheme is said to be linear if S = FT , and

x2

x3

W1

ˆ
W1

W2

ˆ
W2

W3

ˆ
W3

Fig. 3. A simple example where interference alignment is useful in the index
coding problem. In the example, the alignment is realized with V2 = V3 .
The alignment enables transmission of 3 scalars to the 3 corresponding users
in a 2 dimensional vector space, ensuring that a rate of 1/2 is achievable.
Also note that random linear network coding achieves a rate of 1/3 in this
problem.

K

S=

Vi Xi ,

holds even for the specialized context of the index coding
problem2
In the context of the index coding problem, there remain two
important unanswered questions. The ﬁrst is a characterization
of the best possible rate achievable using a vector linear index
code. The second question of interest is an identiﬁcation of
the index coding scenarios where vector linear coding is optimal. Reference [10] made progress in addressing these open
questions by obtaining information theoretic outer bounds for
the index coding rate through a linear programming approach.
The formulation of the outer bounds enabled the authors to
identify certain scenarios where (vector) linear coding is tight,
in an information theoretic sense. In this paper, we make
further progress in this direction by studying the problem from
perspective of interference alignment.
Interference alignment is an important tool that has recently
emerged out of the pursuit of capacity of wireless interference networks. The representative example is the wireless
interference channel with K transmitter-receiver pairs where,
because of interference alignment, each user is simultaneously
able to send at a data rate equal to half of his interferencefree channel capacity to his desired receiver [11]. Interference
alignment is useful, not only to wireless communications, but
also for wireline communication networks [12], [13], [14].
In this paper, we study the index coding problem from the
perspective of interference alignment. In particular, we present
two main results in the paper.
1) In a result that has parallels to [11], we will identify scenarios in the index coding problem where each user gets
half the “interference-free” channel capacity, i.e., each
user can send a (symmetric) rate of 1/2. In particular,
we uniquely identify the side-information graphs where
a rate of 1/2 is feasible in the index coding problem.
2) We solve the index coding problem for a class of
cyclically symmetric side information graphs.
To show these results, we will develop new information

(2)

i=1

where
•
•
•

F is a ﬁnite ﬁeld, and FT represents the T -time Cartesian
product of the ﬁeld,
Xi ∈ FL is a L × 1 vector representing Wi such that
H(Wi ) = L|F|.
Vi is a T × L linear pre-coding vector over F, chosen
independent of the messages.

A coding scheme is said to be a scalar linear encoding scheme
if L = 1. The index code is said to be a binary scalar
linear encoding scheme if S = F2 and L = 1. A rate tuple
(R1 , R2 , . . . , RK ) is said to be achievable using (scalar/binary
scalar) linear coding if there exists some (scalar/binary scalar)
linear coding scheme that achieves the rate tuple.
Remark: As is common in network coding and wireline
network capacity literature, note that the index coding problem
can be deﬁned without explicit mention of the alphabet set
S, since we are only interested in the H(S). However, we
explicitly identify this set because the deﬁnition of a linear
index code is closely connected to this alphabet.
II. BACKGROUND AND S UMMARY OF C ONTRIBUTIONS
The index coding problem was introduced by Birk and
Kol in [1]. Since then, the index coding problem has been
studied from different perspectives [2], [3], [4], [5] . A primary
theme in the pursuit of the index coding problem has been
the applicability of linear coding. References [2], [3] have
characterized the best possible rate achievable with scalar
linear network coding. In particular, they have shown that the
best achievable rate is related to a functional on the network
communication graph known as the minrank. An important
observation was made in [6], where it was shown that this
quantity is sub-optimal because of the possibilty of vector
linear coding. Further, it has been shown in [7] that even vector
linear coding is not sufﬁcient for the index coding problem.
This means that the insufﬁciency of linear network coding
shown previously in [8] in the context of general networks,

2 It is worth noting that in [9], it has been shown that a generalization of the
index coding problem studied here is indeed equivalent to a general network
coding capacity problem. However, the class of index coding problems studied
here is only a special subclass of the general network capacity problem.

2

1

For the example of Fig. 3 the alignment relations are W2 ↔
W3 and the alignment subsets are {W2 , W3 }, {W1 }. We are
now ready to present our main result.
Theorem 1: The rate tuple R with R1 = R2 = ... = RK =
0.5 is not achievable in a single bottleneck network if and
only if there exist distinct indices i, j ∈ K such that Wi , Wj
belong to the same alignment subset and Wi ∈ Aj .
/
Remark: The statement of Theorem 1 is intuitively interpreted as follows. If messages Wi , Wj belong to the same
alignment set then they should overlap almost perfectly in
half the dimensions of the bottleneck link so as to leave the
remaining half of the dimensions for the desired message
Wk . Because of their overlap, it is not possible to recover
one message unless the other message is removed by using
an antidote. If such an antidote is not available then the
achievability of half rate for every user becomes infeasible.
Note that the converse bounds all possible coding schemes
and not just linear schemes.

theoretic outer bounds for the index coding set up which are
of interest in and of themselves. Achievability is shown by
intuitive interference alignment schemes. (See Fig. 3.)
A. Index Coding as an Interference Alignment Problem
To begin, it is worth examining the role of interference
alignment in the index coding problem. Consider a linear index
coding achievable scheme, i.e., we assume that the transmitted
broadcast symbol S has a form as in (2). We use the following
notation here.
V = {v ∈ FT : ∃i ∈ K, s.t. v is a column vector of Vi }
VA = {v ∈ FT : ∃i ∈ A s.t. v is a column vector of Vi },
i.e., V is the set of all column vectors of [V1 V2 . . . VK ] .
Similarly, VA is the set of all column vectors which belong to
at least one matrix Vi : i ∈ A.
Now, note that receiver i has, as antidotes, messages WAi
and can cancel the effect of these messages from S. The
interference that remains at receiver i after this cancellation
lies in the span of VAc . For receiver i to resolve the message
i
from Wi from this the resolvability of message Wi at receiver
i can be expressed as
span(V{i} ) ∩ span(VAc −{i} ) = {0}
i

B. A Class of Cyclically Symmetric Graphs
A second main result of this paper is a characterization of
(symmetric) rate of index coding problems where the antidote
sets have a cyclically symmetric property.
Deﬁnition 1: Consider an arbirary set ∆
⊆
{±1, ±2, . . . , ±K/2 }. A cyclically symmetric index
coding problem deﬁned on ∆ is characterized by its antidotes
as
Ai = {((i − 1 + d) mod K) + 1 : ∀d ∈ ∆}

(3)

Since we operate in a T dimensional space and we want
resolvability of an L dimensional vector Vi , this means that
the dimension of span(VAc −{i} ) should be smaller than T − L
i
(because the vectors are all observed in an T dimensional
space). Clearly, if T < |Ac |L, then, these interfering vectors
i
need to align in an T − L dimensional space. This scenario
is demonstrated in Figure 3, where K = 3, T = 2 and each
user sends L = 1 vector. Because of alignment of V2 and
V3 , user 1 is able to resolve x1 . Indeed, our ﬁrst main result
generalizes this scenario by explicitly identifying the set of all
index coding problems where a rate of 1/2 is achievable.

We refer to ∆ as antidote generator set.
Theorem 2: The information theoretically optimal symmetric rate of a cyclically symmetric index coding problem
characterized by antidote generator set
∆ = {±1, ±2, . . . , ±U, U + 1, U + 2, . . . , D},
is

III. M AIN R ESULTS

Rsym =

A. Half-Rate Feasibility

•

U +1
K−D+U ,

(D + U ) = K − 1
(D + U ) ≤ K − 2

See Figure 4 for an example.

The ﬁrst issue we investigate is the achievability of a
symmetric rate of 1 for each user which we denote as the half2
rate-feasibility problem. The following terminology is useful
for an explicit description of the solution of this problem.
•

1,

IV. ACHIEVABLE S CHEMES
A. Half-Rate Feasibility

k

Alignment Relation: We deﬁne a relation Wi ↔ Wj as
k
follows. Wi ↔ Wj iff Wi ∈ Ak , Wj ∈ Ak for distinct
/
/
indices i, j, k ∈ K. We may occasionally use the notation
Wi ↔ Wj when the identity of the destination is not
important.
Alignment Subsets: The set of messages W is partitioned into alignment subsets, created as follows. If
Wi ↔ Wj , then both Wi , Wj belong to the same
alignment subset. Further, if Wi ↔ Wj and Wj ↔ Wm
then Wi , Wj , Wm all belong to the same alignment
subset.

We choose S = F2 , where q is chosen to be sufﬁciently
q
large. We partition {1, 2, . . . , K} into alignment subsets as per
Theorem 1. Let us denote the partitions by P1 , P2 , . . . , PM .
Then, we assign a 2 × 1 coding vector for each subset denoted
by VPi , such that the M vectors VP1 , VP2 , . . . , VPM are
pairwise linearly independent. The linear coding vectors are
chosen as Vi = VPm if i ∈ Pm . As per Theorem 1, we need
to show that the following conditions imply the resolvability
of message Wi at receiver i.
i, j ∈ Pm ⇒ i ∈ Aj , j ∈ Ai

3

(4)

U + 2, . . . , K, 2, 3, . . . , D + 1}. Cancelling the effect of these
messages above, the receiver can obtain

To see this, note that each receiver receives
K

S

=

K−U

U

xi V i

xi V i

= xr V r +

+

i∈Ar



Desired Signal

Aligned Interference

i∈Ac −{r}
r

Note that the above is the linear combination of K − (D −
U ) vectors z1 , z2 , . . . , zU +1 , zD+2 , zD+3 , . . . , zK . Since we
operate in a K − (D − U ) dimensional space, it is easy to
see these vectors are linearly independent and therefore the
desired scalars x1,j , j = 0, 1, . . . , U are resolvable at receiver
i. This completes the proof. See Figure 4 for an example.

Side information
at receiver r
where the ﬁnal equation follows because all elements of
{i : i ∈ Ar , i = r} belong to the same alignment subset
/
by deﬁnition; this subset is denoted by Pm . From the above
equations, it is clear that after cancelling the second term
above, receiver r can obtain


Sr = xr Vr + 

xi,j zi+j
i=D+2 j=0

j=0

xi  VPm

U

x1,j zj+1 +

S1 =

i=1

x1,0 z1
x5,0 z5

x5,1 z1

x4,1 z5
x3,1 z4

xi  VPm

Achievability via alignment

x3,0 z3

x4,0 z4

i∈Ac −{r}
r

x2,0 z2

x1,1 z2
x2,1 z3

(Note that the ﬁgure represents 5
linearly independent directions in a
5 dimensional space)

S

Further, r ∈ Pm , because if r ∈ Pm , then, the condition (4)
/
is violated. This is because j, r ∈ Pm → j ∈ Ar → j ∈
/
Pm which is a contradiction. This means that VPm and Vr
are linearly independent. Since we are operating in a T = 2
dimensional space, xr is linearly resolvable at receiver r as
required. This proves achievability.

W1

ˆ
W1

W2

ˆ
W2

W3

ˆ
W3

W4

ˆ
W4

W5

ˆ
W5

B. Cyclically Symmetric Graphs
First, note that if |∆| = U + D = K − 1, then it is obvious
that each source can achieve a rate of 1. If |∆| = K − 2, then,
1
it is easy to verify that a rate of 2 is achievable using Theorem
1. Here we are trying to show achievability for |∆| ≤ K − 3.
Using linear coding, we show that each user can send L =
(U + 1) symbols in a T = (K − (D − U )) dimensional space
FT . Let z1 , z2 , . . . , zK , be K vectors of size T × 1 where any
q
T of them are linearly independent over Fq . Note that over a
sufﬁciently large ﬁeld, the vectors zi , i = 1, 2, . . . , K can be
chosen to satisfy this property. Our construction for Vi - the
linear coding co-efﬁcients for user i - is as follows.

Fig. 4. A cyclically symmetric 5 user index coding problem with antidote
generator set ∆ = {1, −1}. As per Theorem 3 we have R1 + R2 + R3 +
R4 + R5 ≤ 2. Also, as per the achievability described in Section IV-B, a
rate of 2/5 is achievable using the scheme pictorially depicted.

V. O UTER B OUNDS
We (brieﬂy) describe the outerbound for networks which
are valid in general and are tight for the half rate feasibility
problem. Detailed outer bounds for Theorems 1 and 2 can be
found in [15].
Theorem 3: For any N +1 distinct indices i0 , i1 , ..., iN ∈ K
and N indices j1 , ..., jN ∈ K if there is the following
alignment chain

Vi = [zi zi⊕1 zi⊕2 . . . zi⊕U ]
where a ⊕ b denotes [((a − 1) + b) mod K] + 1. With this
construction, we intend to show that (3) is satisﬁed. First,
note that the U + 1 columns of Vi are linearly independent
since U + 1 < K − (D − U ). In particular, denoting
Xi = [xi,0 xi,1 . . . , xi,U ], we have
K

j1

j3

jN −1

jN

then
Ri0 + Rj1 + Ri1 + ... + RjN + RiN ≤ N

U

S=

j2

Wi0 ↔ Wi1 ↔ Wi2 ↔ ... ↔ WiN −1 ↔ WiN
Wi0 ∈ AiN
/
(5)

xi,j zi⊕j .

(6)

Remark: It worths mentioning the difference between the
above alignment chain and directed acyclic side information
graphs presented in [3]. In the the above alignment chain, all
the messages can be perfectly aligned except the ﬁrst and the
last messages in the chain, i.e., Wi0 and WiN , which leads to
the derived outerbound in Theorem 3. However, in a directed

i=1 j=0

Now, because of the symmetric nature of the problem, we
only need to show that W1 is linearly resolvable at X1 . This
ensures resolvability at all other receivers. Note that receiver
1 has side information of xi,j for all i ∈ {K − U + 1, K −

4

acyclic side information graph, none of the messages can be
aligned which leads to the sum rate outerbound of 1.
The converse for Theorem 1 follows as a corollary.
Corollary 1: The rate tuple R with R1 = R2 = ... =
RK = 0.5 is not achievable in a single bottleneck network if
there exist distinct indices i, j ∈ K such that Wi , Wj belong
to the same alignment subset and Wi ∈ Aj .
/
Proof of Corollary: If Wi , Wj belong to the same alignment subset, there must exist a chain of alignment relations
connecting Wi , Wj as
j1

j2

j3

jN1

jN

Wi ↔ Wi1 ↔ Wi2 ↔ ... ↔ WiN −1 ↔ Wj

Proof: Because of submodularity of the entropy function, for
two sets C, D we have
H(C) + H(D) ≥ H(C ∪ D) + H(C ∩ D)

(20)

Choosing C = {S, W −{Wi , Wj }}, D = {S, W −{Wi , Wk }}
we have
H(S, W − {Wi , Wj }) + H(S, W − {Wi , Wk }) ≥
H(S, W − {Wi }) + H(S, W − {Wi , Wj , Wk })

(21)

which is equivalent to

(7)

H(S | W − {Wi , Wj }) + H(S | W − {Wi , Wk }) ≥

where N is the length of the chain. If Wi ∈ Aj then from
/
the result of Theorem 3 shown later in this paper we have an
explicit rate bound

H(S | W − {Wi }) + H(S | W − {Wi , Wj , Wk }) ≥

Ri + Rj1 + Ri1 + Rj2 + ... + RiN −1 + RjN + Rj ≤ N

H(S | W − {Wi }) + H(S | W − {Wj , Wk })

where (22) is true because conditioning reduces the entropy.

(8)

Clearly, Ri = Ri1 = Ri2 = . . . = RiN = Rj1 = Rjn = 0.5
does not satisfy the above bound. This proves the corollary.
Proof of Theorem 3: Theorem 3 affords a simple proof for
N = 1 which can be found in [15]. Here, we consider the
case where N = 2, since it captures all the ideas required
for proving the theorem for an arbitrary value of N . In what
follows we show that for any 3 distinct indices i, j, k ∈ K and
l
m
indices l, m ∈ K if Wi ↔ Wj ↔ Wk and Wi ∈ Ak then
/
Ri + Rj + Rk + Rl + Rm ≤ 2 (see Fig. 4). Below, we denote
H(S) = n.
H(Wl ) = nRl

= I(Wl ; S, WAl ) + o(n)

R EFERENCES
[1] Y. Birk and T. Kol, “Informed-source coding-on-demand (ISCOD) over
broadcast channels,” in Proceedings of the Seventeenth Annual Joint
Conference of the IEEE Computer and Communications Societies, IEEE
INFOCOM’98, vol. 3, pp. 1257–1264, 1998.
[2] Y. Birk and T. Kol, “Coding on demand by an informed source (ISCOD)
for efﬁcient broadcast of different supplemental data to caching clients,”
IEEE Trans. on Information Theory, vol. 52, pp. 2825–2830, June 2006.
[3] Z. Bar-Yossef and Y. Birk and T. S. Jayram and T. Kol, “Index Coding
With Side Information,” IEEE Trans. on Information Theory, vol. 57,
pp. 1479 – 1494, March 2011.
[4] I. Haviv and M. Langberg, “On linear index coding for random graphs,”
CoRR, vol. abs/1107.0390v1, July 2011.
[5] Y. Berliner and M. Langberg, “Index coding with outerplanar side
information,” in Proceedings of IEEE International Symposium on
Information Theory, pp. 806 – 810, 2011.
[6] N. Alon, A. Hasidim, E. Lubetzky, U. Stav, and A. Weinstein, “Broadcasting with side information,” CoRR, vol. abs/0806.3246v1, Jun. 2008.
[7] A. Blasiak, R. Kleinberg, and E. Lubetzky, “Lexicographic products and
the power of non-linear network coding,” CoRR, vol. abs/1108.2489v1,
Aug. 2011.
[8] R. Dougherty and C. Freiling and K. Zeger, “Insufﬁciency of linear
coding in network information ﬂow ,” IEEE Trans. on Information
Theory, vol. 51, pp. 2745 – 2759, Aug. 2005.
[9] S. Rouayheb, A. Sprintson, and C. Georghiades, “On the Index Coding
Problem and Its Relation to Network Coding and Matroid Theory,” IEEE
Trans. on Information Theory, vol. 56, pp. 3187–3195, July 2010.
[10] A. Blasiak, R. Kleinberg, and E. Lubetzky, “Index coding via linear
programming,” CoRR, vol. abs/1004.1379v2, April 2010.
[11] V. Cadambe and S. Jafar, “Interference alignment and the degrees of
freedom of the K user interference channel,” IEEE Trans. on Information
Theory, vol. 54, pp. 3425–3441, Aug. 2008.
[12] V. R. Cadambe, S. A. Jafar, and H. Maleki, “Distributed data storage
with minimum storage regenerating codes - exact and functional repair
are asymptotically equally efﬁcient,” CoRR, vol. abs/1004.4299, 2010.
[13] A. Das, S. Vishwanath, S. Jafar, and A. Markopoulou, “Network
coding for multiple unicasts: An interference alignment approach,” in
Proceedings of IEEE International Symposium on Information Theory,
pp. 1878 – 1882, 2010.
[14] A. Ramakrishnan, A. Das, H. Maleki, A. Markopoulou, S. Jafar,
and S. Vishwanath, “Network Coding for Three Unicast Sessions:
Interference Alignment Approaches,” Annual Allerton Conference on
Communications, Control and Computing, October 2010.
[15] H. Maleki, V. R. Cadambe, and S. A. Jafar, “Index coding - an
interference alignment perspective,” CoRR, vol. abs/1205.1483v1, May
2012.

(9)

≤ I(Wl ; S, W − {Wi , Wj , Wl }) + o(n)
=

H(S | W − {Wi , Wj , Wl })
−H(S | W − {Wi , Wj }) + o(n) (10)

≤ n − H(S | W − {Wi , Wj }) + o(n)
(11)
nRk

≤

I(Wk ; S, WAk ) + o(n)

(12)

≤

I(Wk ; S, W − {Wi , Wk }) + o(n)

(13)

≤

H(S | W − {Wi , Wk }) − nRi + o(n)

(14)

≤

H(S | W − {Wi , Wj }) + H(S | W − {Wj , Wk })
−H(S | W − {Wj }) − nRi + o(n)

=

(15)

H(S | W − {Wi , Wj }) + H(S | W − {Wj , Wk })
−nRj − nRi + o(n)

≤

(16)

n(1 − Rl ) + n(1 − Rm ) − nRi − nRj + o(n)
(17)

⇒ Rk ≤ 2 − Ri − Rj − Rl − Rm

(18)

where (14) follows from the fact that Ri ≤ H(S|W − {Wi })
because of (1), (15) follows from Lemma 1 which is proved
in the Appendix. (17) follows from (11).
A PPENDIX
Lemma 1:
H(S | W − {Wj , Wk }) ≤ H(S | W − {Wi , Wj })
+H(S | W − {Wi , Wk }) − H(S | W − {Wi })

(22)

(19)

5

