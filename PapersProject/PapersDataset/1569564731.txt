Creator:        TeX
Producer:       Appligent StampPDF Batch, version 5.1
CreationDate:   Mon May 14 07:41:45 2012
ModDate:        Tue Jun 19 12:54:53 2012
Tagged:         no
Pages:          5
Encrypted:      no
Page size:      612 x 792 pts (letter)
File size:      490407 bytes
Optimized:      no
PDF version:    1.6
ISIT'2012 1569564731

Entropy rate calculations of algebraic measures
Katy Marchand

Jaideep Mulherkar

Bruno Nachtergaele

Unafﬁliated

DA Institute of Information and
Communication Technology,Gandhinagar, India
Email: jaideep mulherkar@daiict.ac.in

Department of Mathematics
U.C. Davis, California, USA
Email: bxn@math.ucdavis.edu

with each wi ∈ K. Let FK be the sigma algebra generated
by all the cylinder sets. In [1] a special class of translationinvariant measures called algebraic measures was constructed
on FK in terms of a triplet (U, ρ, (Ea )a∈K ) where
• U is a real ordered algebra (the order determined by a
proper convex cone U + ).
• ρ is a positive linear functional on U .
+
• Ea ∈ U
satisfying ρ(AE) = ρ(EA) = ρ(A), ∀ A ∈ U ,
ρ(E) = 1 where E = a∈K Ea .
We state the following proposition from [1]
Proposition 2.1: Given the triplet (U, ρ, (Ea )a∈K ) there
exists a unique translation invariant probability measure µ on
FK such that

Abstract—Let K = {0, 1, ..., q − 1}. We use a special class of
translation invariant measures on K Z called algebraic measures
to study the entropy rate of a hidden Markov processes. We
derive exact formulas for the entropy rate of a q state hidden
Markov process derived from a speciﬁc noise model and show
that the formula converges exponentially fast to the entropy rate.
Index Terms—Entropy rate, Hidden Markov process, Algebraic measures

I. I NTRODUCTION
In this paper we study the entropy rate of a hidden Markov
process using a class of translation-invariant measures on the
chain K Z where K = {0, ...., q − 1}. These measures known
as manifestly positive algebraic measures and their properties
were ﬁrst studied in [1]. Algebraic measures are classical
analogues of ﬁnitely correlated states in quantum spin systems
[2]. We use the properties of the algebraic measures to give
formulas for the entropy rate of a hidden Markov process
derived from a certain noise model that we will describe later.
The entropy rate of an information source is deﬁned by

µ(ω[m,n] ) = ρ(Eωm Eωm+1 ...Eωn )
where ω[m,n] = (ωm , ωm+1 , ..., ωn ), ωi ∈ K.
+
Let Md be the positive cone in the algebra of d × d real
matrices Md consisting of matrices with positive entries and
+
(Rd ) be d × 1 column vectors with positive entries. An
algebraic measure µ is called manifestly positive if there exists
+
a d ∈ N, a positive τ and σ ∈ (Rd ) and for each a ∈ K, a
+
Ea ∈ Md such that

Sn (X1 , X2 , ..., Xn )
(1)
n
where µ is the measure associated with the sequence of random variables. This limit exits when {Xn } forms a stationary
stochastic process. There is a well known formula for the
entropy rate of a Markov source, however the problem of
deriving explicit expressions for the entropy rate of the is
still an open issue. The entropy rate of a hidden Markov
process was ﬁrst studied by Blackwell in 1957 [3] who showed
that the entropy rate is given by the integral with respect to
a function on a simplex with respect to a measure called
the Blackwell measure. Recently there has been a renewed
interest in problem of calculating the entropy rate of a hidden
Markov chain [4], [5], [6], [7], [8], [9]. The algebraic measure
approach to functions of Markov process can be compared
to previous work in [10], [11] and recently to [12]. In [3]
Blackwell derived a formula for a three state hidden Markov
process which has one unambiguous symbol. The hidden
Markov model we work with is a generalization of Blackwell,
moreover we also show that approximate formula we give
converges exponentially fast to the entropy rate.
H(µ) = lim

n→∞

µ((ωm , ωm+1 , ..., ωn )) = τ | Eωm Eωm+1 ...Eωn σ
where τ | σ = τ T σ is the usual inner product on Rd . In
[1] a one-one correspondence was shown between functions
of Markov processes (hidden Markov models) and the class
of manifestly positive algebraic measures. Let X = {Xi }i∈N
be a Markov chain that takes values on a ﬁnite alphabet L
with transition matrix E and stationary measure ν. Let Fa be
the matrix with the only non-vanishing row equal to the ath
row of E. Thus
Fa = E

(2)

a∈L

Let Y = {Yi }i∈N be a noisy observation of the Markov chain
with values in K = {0, 1, ..., q − 1}. Deﬁne the matrix R =
[rab ] with rab = P r[Yi = a|Xi = b] and let
Ea =

rab Fb

(3)

b∈L

It is easy to verify that the manifestly positive representation of
the stationary measure µ associated with Y is (τ, σ, (Ea )a∈K ).
So that

II. M ANIFESTLY POSITIVE ALGEBRAIC MEASURES
Let q ∈ N and K = {0, 1, ..., q − 1} and consider the chain
Ω = K Z consisting of conﬁgurations ω = (..., ωi , ωi+1 , ...)

µ((wm , ..., wn )) = τ | Ewm ...Ewn σ

1

(4)

1

ε-

2

1

1

1

ε

ha (w)φ(dw)

1

ε-

=

0

ε

H(µ)

1

0

where τa = µ(a) and σ is a vector with all components equal
to 1.
It was shown that under certain irreducibility conditions (see
Condition 1 in [1]) the entropy rate of a manifestly positive
algebraic measure can be computed as an integral with respect
to a measure on the simplex W = {w = (w1 , w2 , ..., wq ) :
wi ≥ 0, wi = 1} similar to the Blackwell measure. We
have the following theorem for the entropy rate of a function
of Markov process.
Theorem 2.2 ([1]): The entropy rate H(µ) of a manifestly
positive algebraic measure µ (satisfying Condition 1) is given
by

2

1

2

2

Fig. 1. The noise model for q = 3. If 0 is transmitted 0 is received with
probability 1. If 1 of 2 are transmitted there is an error probability of 1 and
2 respectively of the received symbol being 0.

(5)

W

a∈K

model we write the matrices {Ea } given by equation (3) as

where ha (w) = − w | Ea σ log w | Ea σ and φ(dw) is a
probability measure on the simplex W.
We deﬁne Γa : W0 → W0 with W0 = W ∪ {0} by

q−1

E0

=

F0 +

a Fa

(10)

a=1

Γa (ν) =

†
Ea ν
νEa |σ

0

if νEa | σ = 0
otherwise

Ea

=

(1 −

Ea

(6)

=

E

a )Fa

for a = 1, ..., q − 1

a∈K
†
where Ea is the adjoint of Ea . Let C0 (W0 ) be the set of
continuous real valued functions that vanish on 0, then Tµ :
C0 (W0 ) → C0 (W0 ) is deﬁned by

(Tµ f )(w)

w | Ea σ f (Γa w)

=

Let ei , i = 0, 1..., q − 1 denote the transpose of the (i + 1)st
row of E = [eij ]. Let p = minij eij and P = maxij eij . Our
only assumption will be

(7)

Assumption 1 :

a∈K

0 < p ≤ P < 1,

In [1] the measure φ(dw) was characterized as the unique
measure on C(W) that is invariant under Tµ ,i.e.,
φ(f )

= φ(Tµ f ) f ∈ C(W)

= 1,

a

>0

∀a ∈ {1, ..., q − 1}.

From equation (6) one can see that for each ν ∈ W

(8)

Γ0 ν

=

The support of φ(dw) is given by
supp(φ) = ∆ ≡ {Γ(ω) τ |ω ∈ K n , n ∈ N }
¯

0

q−1
a=0 a νa ea
q−1
a=0 a νa

q−1

=

αa ea

(11)

a=0

q−1
a=0

a
αa = 1 with αa = q−1νa ν .
a=0 a a
Because of Assumption 1 we get

(9)

where Γ(ω) = Γωn−1 · · · Γω0 and τ is the only non-trivial ﬁxed
¯
point of Γa0 .

p ≤ (Γ0 ν)a ≤ P

∀a ∈ K.

(12)

Also one gets from equation (6) for all a ∈ {1, ..., q − 1}.

III. N OISE MODEL AND SUPPORT OF THE MEASURE φ
In this section we describe the noise model and the support
of the measure φ(dw) given by equation (9) for this noise
model. If the symbol 0 is transmitted then it is always received
as 0 at the other end. On the other hand if any of the other
symbol is transmitted then it is either received without any
error or received as the symbol 0 with a small error probability.
That is P (Yi = 0|Xi = 0) = 1, P (Yi = 0|Xi = a) = a
and P (Yi = a|Xi = a) = 1 − a for a = 1, ..., q − 1 and
P (Yi = b|Xi = a) = 0 when 0 = b = a. Here we consider
the symbols 1, 2, ..., q − 1 to be unambiguous, since if any
one of them is received then that same symbol must have
been transmitted. See ﬁgure 1 for a description of the model
in the special case of q = 3.
Let the matrices {Fa } be the matrices that describe the
uncorrupted Markov source as in equation (2). For this noise

Γa ν =

ea
0

if νa = 0
otherwise

(13)

A key factor that simpliﬁes our analysis of the entropy rate
is that the support of φ(dw) given by equation (9) simpliﬁes
signiﬁcantly with this noise model. We have the following
proposition about the support of the measure φ.
Proposition 3.1: The support of the measure φ is given by
∆ = {Γm ej |j ∈ {1, .., q − 1}; m ∈ N0 }
0

(14)

Proof: Since by equation (12) τ ∈ (Rq )+ , it follows from
¯
equation (13) that Γa τ = ea and Γa ea = ea for a = 0.
¯
Therefore by (9)
∆ = {¯} ∪ {Γm ej |j ∈ {1, .., q − 1}; m ∈ N0 }
τ
0

2

One can show ([1] equation (28)) that for any ν ∈ W + there
exists constants C1 and ρ < 1 such that
Γk+1 ν − τ
¯
0

1

≤ C1 ρk

Let fm ∈ C(W) be deﬁned so that

This implies that all subsequences in ∆ converge to τ and
¯
hence τ is the only accumulation point in ∆. Therefore
¯
∆

So, φ(∆j,m )

{Γm ej |j ∈ {1, .., q − 1}; m ∈ N0 }
0

=

lim Γm ej
0

†
Therefore E0 (ν − Cη)

=

then

where C =

ν|E0 σ
η|E0 σ

. But

†
E0

=

Therefore, φ(∆j,m )

where we used (13) and the fact that Γ0 ν ∈ ∆m only if
ν ∈ ∆m−1 . We have
φ(∆j,m )

≤

From Assumption 1 we have ν | E0 σ < 1 and ∆j,m−1 being
a compact set we get

0

r=

ν | E0 σ < 1

sup
ν∈∆j,m−1

So, φ(∆j,m ) ≤ rφ(∆j,m−1 ) =⇒ φ(∆j,m ) ≤ rm−1 φ(∆1 )

Γm ei
0

=

Γn ej
0

Γm ei
0

=

Therefore,
φ(¯)
τ

τ
¯

lim φ(∆j,m ) ≤ lim rm−1 φ(∆1 ) = 0.

=

m→∞

(17)

m→∞

IV. E NTROPY RATE FORMULAS
In this section we apply the results on manifestly positive
algebraic measures in II to the case of the hidden Markov
model described in section III. Deﬁne

Assume Γm ei = Γn ej for some m, n ≥ 0 and for i, j ∈
0
0
{1, ..., q − 1}, If m and n are both zero then ei = ej but this
contradicts the fact that ej ’s form a linearly independent set.
Assume wlog that m > n. Since Γ0 is one-one we arrive at
Γk ei = ej for k = m−n. Again using equation (11) we arrive
0
at a contradiction that ej ’s form a linearly independent set.
From above, Γ0 ea = ea for any a ∈ K so ea = τ . If
¯
Γm ea = τ for some m ≥ 1 then Γ0 (Γm−1 ea ) = τ . Since τ
¯
¯
¯
0
0
is a ﬁxed point of Γ0 and Γ0 is one to one we conclude that
(Γm−1 )ea = τ . Repeating the argument we get ea = τ which
¯
¯
0
again is a contradiction.
Lemma 3.3: If ∆ is countably inﬁnite then φ(¯) = 0
τ
Proof: Since ∆ is countably inﬁnite there exists a j ∈
{1, ..., q − 1} such that limm→∞ Γm ej = τ . Consider the set
¯
0

m

Γm−i ej | E0 σ
0

cj,m =

(18)

i=1

Let A be the q × q − 1 matrix deﬁned by entries.
∞

Aij

Γm ej | Ei σ cj,m
0

= −δij +

if i = q, q = 2

m=0

Aij

=

0

if i = q, q = 2

∞

Aqj

=

cj,m

(19)

m=0

Φ = [φ(e1 ) · · · φ(eq−1 )]T ∈ Rq−1 , b = [0 0 · · · 1]T ∈ Rq

∆j,m = {Γk ej |k ≥ m}
0

ˆ
Let A = A + R

for m ∈ {1, 2, ...}. This is a decreasing sequence of sets with

=

ν | E0 σ ∆j,m−1

sup
ν∈∆j,m−1

and since ν, η ∈ W therefore C = 1 so ν = η. Observe
†
from equation (11) that if E0 is one-one then the vectors ea ∈
W, a ∈ K form a linearly independent set. We will show that
all the elements of ∆ are distinct ,i.e., for any m, n ≥ 0

Therefore φ(¯)
τ

ν | E0 σ dφ

=
∆m−1

ν = Cη

=

ν | E0 σ dφ

=
∆m−1

is one-one implies

∆j,m

ν | Ea σ fm (Γa ν)dφ

=

(16)

Γ0 η for ν, η ∈ W
†
E0 η
η | E0 σ

=

fm (ν)dφ

∆ a∈K

∆ can be countably inﬁnite as can be seen from the
following lemma.
†
Lemma 3.2: If E0 is one to one then ∆ is countably inﬁnite
set of distinct elements.
†
Proof: We will ﬁrst show that E0 is one-one =⇒ Γ0 :
W → W is one-one.
If Γ0 ν
†
E0 ν
ν | E0 σ

=

By (7) and (8) we get
φ(∆j,m )

= τ
¯

ν ∈ ∆j,m
otherwise

∆

Moreover for any j ∈ {1, ..., q − 1}
m→∞

1
0

fm (ν) =

(15)

(20)

where the entries of R are the tails ((N + 1)st term onwards)
ˆ
of the entries of A. Let Φ be the least square solution to

{¯}
τ

m∈N

lim φ(∆j,m )

ˆ
AΦ = b

m→∞

3

(21)

ˆ
ˆ
Therefore Φ = A† b

Now the measure of the whole set φ(∆) = 1 so

(22)

ˆ
where A† is the pseudo-inverse of A.

q−1 ∞

q−1

φ(Γm ej )

q−1
k
a [Γ0 ej ]a

Let γ := max sup
j

k

(23)

is one-one
Theorem 4.1: Under Assumption 1 and if
the entropy rate of the measure µ associated with the hidden
Markov process with the noise model described in section III
is given by
q−1 ∞ q−1

H(µ)

ha (Γm ej )φ(Γm ej )
0
0

=
j=1 m=0 a=0

Moreover the entropy rate can be approximated to O(γ N +1 )
by

From (25) we get
q−1 ∞ q−1

q−1

H(µ)

ˆ
ha (Γm ej )cj,m Φj
0

HN (µ) =

ha (Γm ej )cj,m φ(ej )
0

=
j=1 m=0 a=0

j=1 m=0 a=0

q−1 ∞ q−1

Proof: Let

H(µ)
if ν =
otherwise

j=1 m=0 a=0

err(N )

for m ∈ N and j = 1, ..., q − 1. We have
φ(Γm ej )
0

=

q−1

fj,m dφ

ˆ
ha (Γm ej )cj,m Φj +
0
q−1 ∞ q−1

ˆ
ha (Γm ej )cj,m (Φj − Φj )
0

ν | Ea σ fj,m (Γa ν)dφ

=

j=1 m=0 a=0

W a∈K

q−1

=

cj,m φ(ej )

(25)

m

cj,m

Γm−i ej | E0 σ
0

=

Therefore

i=1

Similarly we use
φ(e1 ),...,φ(eq−1 ).

the

functions

fj,0

to

solve

for

err(N ) ≤

ν | Ea σ fi,0 (Γa ν)dφ

=

q

ˆ
γ N +1
q A† 1
1+
= O(γ N +1 )
1−γ
1−γ

Lemma 4.2: For all j = 1, ..., q − 1 and m ∈ N0

W a∈K

cj,m

ν | Ei σ φ(ν)

=

ˆ
γ m |Φj − Φj |
j=1 m=0

j=1 m=N +1

and iterating we get
φ(Γm ej )
0

ˆ
γ m Φj + q

1
γ N +1 ˆ
ˆ
Φ 1+q
Φ − Φj 1
=q
1−γ
1−γ
By lemma 4.3
ˆ
γ N +1
1
q A† 1 N +1
≤q
+q
γ
1−γ
1−γ 1−γ

Γm−1 ej | E0 σ φ(Γm−1 ej )
0
0

=

q−1 ∞

∞

≤q

m−1
But Γa (ν) = ea and Γ0 ν = Γm ej only if ν = Γ0 ej
0
therefore

where

q−1

∞

j=1 m=N +1 a=0

By (7) and (8) we get

φ(Γm ej )
0

|H(µ) − HN (µ)|

=

err(N ) =

W

φ(Γm ej )
0

ha (Γm ej )cj,m Φj
0

=

Γm ej
0

1
0

fj,m (ν) =

φ(ei )

<

γm

<1
(28)

ν∈∆
q−1 ∞

Proof:

Γm ej | Ei σ φ(Γm ej )
0
0

=

m

j=1 m=0

cj,m

Using (25) we get
q−1

φ(ei )

(27)

q−1 ∞ q−1

(24)

j=1 m=0 a=0

q−1 N

cj,m = 1
m=0

j=1

Equations (26) and (27) form a system of q linear equations
AΦ = b with A ∈ Mq,q−1 , Φ ∈ Rq−1 and b ∈ Rq as given
∞
by (19),(20). By lemma (4.2) m=0 cj,m < ∞ which ensures
that each Aij is bounded. Now from the integral formula for
the entropy rate given by (5) and the support of the measure
given by proposition (3.1) we get that

a=0

ha (Γm ej )cj,m Φj
0

∞

φ(ej )

j=1 m=0

†
E0

H(µ) =

=

=

Γm−i ej | E0 σ
0
i=1
m q−1

∞

Γm ej | Ei σ cj,m
0

φ(ej )
j=1

=

(26)

m−i
ej ]a
a [Γ0

=

m=0

i=1 a=0

4

(29)

Now, by (12) and Assumption 1, a < 1 if a ∈ {1, .., q − 1}
q−1
and 0 = 1. So a=0 a [Γk ej ]a < 1 ∀k ∈ N0 Moreover by
(16)
lim Γk ej
0
k→∞
q−1

k
a [Γ0 ej ]a

<1

a=0
q−1

and γ = max sup
j

<1

k
a [Γ0 ej ]a

Therefore, sup
k

= τ ∈ W+
¯

k

a=0

Fig. 2.

Lemma 4.3:
ˆ
Φ−Φ

1

≤

V. C ONCLUSION AND FUTURE DIRECTION

ˆ
q A† 1
1−γ

In this paper we used algebraic measures to compute an
exact formula for a the entropy rate of hidden Markov model
and showed that the formula converges exponentially fast. The
noise model we studied was very speciﬁc and it would be
interesting to see if the techniques of algebraic measures can
be generalized to a larger class of noise models. Computing
the corresponding entropic entities like Von Neumann entropy
and capacities of correlated quantum channels described by
ﬁnitely correlated states in quantum spin systems would be
very important from the point of view of quantum information
theory.

Proof: From (21) and (20)
ˆ
AΦ = AΦ + RΦ = b
ˆ
ˆˆ
ˆˆ
Substituting (22), AΦ − AΦ = b − RΦ − AΦ
ˆ
ˆ
ˆˆ
A(Φ − Φ) = b − RΦ − AΦ =⇒
ˆ 1 = A† b − A† RΦ − Φ
ˆ
ˆ
ˆ
Φ−Φ
ˆ
Φ−Φ

ˆ
A†

≤

1

1

∞
m=N +1

Each entry in R is bounded by


1 ··· 1
N +1
γ


..
RΦ ≤

Φ
.
1−γ
1 ··· 1
ˆ
Φ−Φ

1

ˆ
≤ A†

1

RΦ

1

≤

RΦ

γm =

1
γ N +1
1−γ .

ACKNOWLEDGMENT
γ N +1 q
≤
1−γ

The authors would like to acknowledge the NSF grant
Award #1009502.

1

R EFERENCES

ˆ
q A† N +1
γ
1−γ

[1] M. Fannes, B. Nachtergaele, and L. Slegers, “Functions of Markov
processes and algebraic measure,” Reviews in Mathematical Physics,
vol. 4, p. 39, 1992.
[2] M. Fannes, B. Nachtergaele, and R. Werner, “Finitely correlated states
on quantum spin chains,” Commun. Math. Phys., vol. 144, pp. 443–490,
1992.
[3] D. Blackwell, “The entropy of functions of ﬁnite-state Markov chains,”
Trans. 1st Prague Conf. Information Theory, Statistical Decision Functions, Random Processes, pp. 13–20, 1957.
[4] P. Jacquet, G. Seroussi, and W. Szpankowski, “On the entropy of a
hidden Markov process,” Proceedings of Data Compression Conference,
Snowbird, UT, pp. 362–371, 2004.
[5] T. Holliday, A. Goldsmith, and P. Glynn, “On entropy and lyapunov
exponents for ﬁnite state channels,” IEEE Trans. Inf. Theory, vol. 52,
2006.
[6] E. Ordentlich and T. Weissman, “On the optimality of symbol by symbol
ﬁltering and denoising,” IEEE Trans. Inf. Theory, vol. 52, pp. 19–40,
2006.
[7] O. Zuk, E. Domany, I. Kanter, and M. Aizenmann, “From ﬁnite-system
entropy to entropy rate of a hidden Markov process,” IEEE Signal
Processing Letters, vol. 13, pp. 517–520, 2006.
[8] A. Schonhuth, “On analytic properties of entropy rate,” IEEE Trans. Inf.
Theory, vol. 55, pp. 2119–2127, 2009.
[9] G. Han and B. Marcus, “Asymptotics of entropy rate in special families
of hidden Markov chains,” IEEE Trans. Inf. Theory, vol. 56, pp. 1287–
1295, 2010.
[10] A. Heller, “On stochastic processes derived from Markov chains,” Ann.
Math. Statist., vol. 36, pp. 1286–1291, 2005.
[11] G. Picci, “On the internal structure of ﬁnite state stochastic processes,”
Lecture Notes in Econ. and Math. Systems, vol. 161, 1987.
[12] U. Fagile and A. Sch¨ nhuth, “Efﬁcient tests for equivalence of hidden
o
Markov processes and quantum random walks,” IEEE Trans. Inf. Theory,
vol. 57(3), pp. 1746–1753, 2011.

We present a numerical example for approximating the
entropy rate formulas given by theorem 4.1. Let q = 3,
1 = 0.01 and 2 = 0.02. The transition matrix we use is


0.4 0.25 0.35
E = 0.25 0.45 0.3 
0.2 0.55 0.25
N
10
20
30
40
50

HN (µ)
0.95961052113515
0.95961126155225
0.95961126164043
0.95961126164044
0.95961126164044

Plot of the error err(N ) versus N.

err(N) bound
0.3561
0.0030
2.6758 × 10−5
2.3193 × 10−7
2.0103 × 10−9

TABLE I
T HE ESTIMATED ENTROPY RATE HN (µ) USING THE FORMULA GIVEN BY
THEOREM 4.1.

We note that the computational complexity of the formula
is exponential in N , but since the error goes to zero exponentially fast we require only a small number of terms in the
computation which leads to a practically more useful formula
than other methods, for eg. using HN = limN →∞ SN −SN −1 .

5

