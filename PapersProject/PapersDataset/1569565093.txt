Creator:        TeX
Producer:       Appligent StampPDF Batch, version 5.1
CreationDate:   Thu May 10 07:56:54 2012
ModDate:        Tue Jun 19 12:55:58 2012
Tagged:         no
Pages:          5
Encrypted:      no
Page size:      612 x 792 pts (letter)
File size:      2874945 bytes
Optimized:      no
PDF version:    1.7
ISIT'2012 1569565093

Finite-length analysis of the TEP decoder for LDPC
ensembles over the BEC
Pablo M. Olmos, Fernando P´ rez-Cruz
e

Luis Salamanca, Juan Jos´ Murillo-Fuentes
e

Departamento de Teor´a de la Se˜ al y Comunicaciones.
ı
n
Universidad Carlos III in Madrid.
email: {olmos,fernando}@tsc.uc3m.es

Departamento de Teor´a de la Se˜ al y Comunicaciones.
ı
n
Universidad de Sevilla.
email:{salamanca,murillo}@us.es

In this contribution, we analyze the ﬁnite-length performance of the TEP decoder for the BEC from a theoretical
perspective. For a given LDPC ensemble, we are able to explain the gain in performance with respect to BP by comparing
the expected graph evolution for each decoder. In addition,
we derive a scaling law (SL) that accurately predicts the TEP
performance for any given LDPC ensemble in the waterfall
region. The TEP decoder SL can be used for TEP-oriented
ﬁnite-length LDPC optimization. These results can be also
applied to estimate the ﬁnite-length ML decoder performance
for Raptor codes.

Abstract—In this work, we analyze the ﬁnite-length performance of low-density parity check (LDPC) ensembles decoded
over the binary erasure channel (BEC) using the tree-expectation
propagation (TEP) algorithm. In a previous paper, we showed
that the TEP improves the BP performance for decoding regular
and irregular short LDPC codes, but the perspective was mainly
empirical. In this work, given the degree-distribution of an LDPC
ensemble, we explain and predict the range of code lengths for
which the TEP improves the BP solution. In addition, for LDPC
ensembles that present a single critical point, we propose a scaling
law to accurately predict the performance in the waterfall region.
These results are of critical importance to design practical LDPC
codes for the TEP decoder.

I. I NTRODUCTION

II. TEP DECODER

Tree-structured expectation propagation (TEP) was ﬁrst proposed in [1] to construct tractable approximations to graphical
models. Its application to low-density parity-check (LDPC)
decoding is introduced in [2], [3], [4] for the binary erasure
channel (BEC), where we show that it improves the performance of the belief propagation (BP) algorithm, thanks
to a better estimation of the posterior probability for each
coded bit. Contrary to alternative techniques to BP, such
as generalized-BP (GBP) [5], the TEP complexity for the
BEC is of the same order as BP, i.e., linear with the LDPC
code length [6]. For LDPC over the BEC, the TEP can be
explained as a Gaussian elimination algorithm where rows
with up to two ones can be processed. For properly designed
Raptor codes, extensively considered nowadays in broadcast
erasure networks, inactivation decoding [7], [8] achieves the
ML solution by GE of rows with no more than two ones, i.e.,
is equivalent to the TEP.
In [4], [3], we compute in detail the TEP decoder graph
evolution, which constitutes the basic tool to analyze the TEP
decoder properties over the BEC. In [4], we show the conditions that have to be fulﬁlled by an LDPC ensemble to improve
the BP limiting performance, i.e., the decoding threshold ✏BP .
These conditions are quite restrictive and no code satisfying
them have been found to date. On the contrary, the TEP
decoder signiﬁcantly improves the BP solution when decoding
ﬁnite-length LDPC codes [2], [3]. In [2], we illustrate this
result for regular and irregular LDPC ensembles. Based on
empirical evidence, we concluded that TEP either provides a
gain in word error rate (WER) for a given code length, or a
reduction of the code length needed to achieve a target WER.

The TEP decoder for the erasure channel can be formulated
as a peeling algorithm [6], which works over the Tanner graph
of the code [4], [2]. We assume, without loss of generality,
that the all zero codeword1 is transmitted through a BEC
with erasure parameter ✏. The Tanner graph is initialized by
removing all the non-erased variables, along with all their
links. Then, one of the two following steps is performed at
each iteration:
1) Variable identiﬁcation: Look for a degree-one check
node in the graph and remove it along with the variable
it is connected to. The parity of the check node indicates
the value of the variable, which is declared as revealed.
2) Graph reduction: Look for a degree-two check node in
the graph and remove it along with one of the variables
it is connected to. The removed variable will be revealed
once the remaining variable in the graph is revealed. This
process is sketched in Fig. 1. The variable V1 inherits the
connections of V2 (solid lines) in Fig. 1(b) and the check
P1 and the variable V2 are removed.
The BP decoder as a peeling-type algorithm, usually referred to as peeling decoder (PD), only implements the ﬁrst
step, i.e., variable identiﬁcation. Note the equivalence between
the graph reduction step and the triangularization procedure in
[9] for Gaussian elimination. During triangularization procedure, a variable is related to some “reference” variables or
pivots, as done during the graph reduction step. Accordingly,
the TEP decoder triangularizes the residual matrix by only
processing rows with up to two ones.
1 The

1

full algorithm is described in [4].

where i represents the fraction of edges connected to a
variable node of degree i, i.e., edges with left degree i, and ⇢j
is the fraction of edges connected to a check node of degree
j, i.e., edges of right degree j [10]. In [4], we compute the
expected graph evolution during the TEP decoding, also with a
set of non-linear differential equations. These equations track
down the expected progression of the fraction of edges with
left degree i, li (⌧ ) for i = 1, . . . , lmax , and right degree j,
rj (⌧ ) for j = 1, . . . , rmax , as the TEP decoder iterates. The
normalized time ⌧ is such that if ` is the TEP iteration index
and E / n is the total number of edges in the original graph
then ⌧ = `/E. The normalized P of the residual graph
size
P
along time is given by e(⌧ ) =
j rj (⌧ ) =
i li (⌧ ). The
initial conditions for the TEP differential equations depend on
both the DD in (1) and the erasure probability ✏.
Let us illustrate the accuracy of this model for the analysis
of the TEP decoder properties. In Fig. 3, we compare the
estimated TEP expected graph evolution (in solid lines) for
R1 (⌧ ) = r1 (⌧ )E and R2 (⌧ ) = r2 (⌧ )E for a regular (3, 6)
code with 20 particular decoding trajectories obtained through
simulation (thin lines). We choose a very large code length,
n = 217 , so that the deviation around the expected evolution is
small. Since the BP threshold is ✏BP = 0.4294, we consider
two cases: below the threshold, ✏ = 0.415 in (a), and above,
✏ = 0.43 in (b). We depict their evolution e(⌧ ). As we can see,
our model in [4] accurately estimates the average decoding
trajectories. Note that, below the threshold, all the curves
represent successful decoding.
To perform better than the BP decoder, the TEP decoder
needs to create a signiﬁcant amount of check nodes of degree
one. In other words, the probability of the scenario in Fig.
2(a) should be large. In [4] we computed the probability that
two variable nodes that share a check node of degree-two
also share at least another check node (of any degree). Let S
denote this scenario. For the graph at time ⌧ , if we randomly
choose a particular degree-two check node, the probability of
this scenario is lower bounded by

P1

V1

P2
V2

P2

V1

P3

P3

(a)

(b)

Fig. 1. In (a), V1 and V2 share a check node of degree two. In (b), V1
inherits the connections of V2 (solid lines) and P1 and V2 are removed.

P1

V1

P2
V2

P2

V1

P3

P3
V3

V3

(a)

(b)

Fig. 2. In (a) we show two variable nodes, V1 and V2 , that share a check
node of degree two and a check node of degree three. In (b), V1 inherits the
connections of V2 and P3 becomes degree one.

The TEP operates until all variable nodes have been removed, i.e., successful decoding, or until there are no degreeone and degree-two check nodes left. In the graph reduction
step, we eventually create check nodes of degree one. For
example, in Fig. 2(a), we create a check node of degree one
since V1 and V2 also share P3 , a check node of degree three.
Once P1 and V2 are removed, the check node P3 becomes
degree one, as illustrated in Fig. 2(b). V3 is now revealed.
The TEP decoder complexity is analyzed in [4], where we
show that the graph reduction step is performed by a basic
BP iteration followed by the addition of two columns of the
parity check matrix. Along the decoding process, the matrix
remains sparse and the resulting complexity is of order O(n),
where n is the code length.

PS (⌧ )

III. E XPECTED G RAPH E VOLUTION UNDER TEP
DECODING

imax
X
i=2

ix

i 1

,

⇢(x) =

jmax
X

⇢j x j

1

,

1)2 (ravg (⌧ )
e(⌧ )E

1)

,

(2)

where lavg (⌧ ) and ravg (⌧ ) are, respectively, the average left
and right edge degrees. The probability of the scenario in Fig.
2(a) is just a fraction of (2). For most codes of interest, in the
limit n ! 1, PS (⌧ ) ! 0 for any ⌧ , proving that the TEP
and BP present the same limiting performance and threshold
[4]. For ﬁnite-length codes, PS (⌧ ) is higher than zero and the
improvement with respect to the BP decoder is possible.

Both the PD and the TEP decoder sequentially reduce the
LDPC Tanner graph and, as a consequence, the decoding
process yields a random sequence of residual graphs. As
proved in [10], this random process follows a typical path
or expected evolution [6] that is computed as the solution of
a set of differential equations. In [11], the authors show that
individual sequences of residual graphs under BP decoding are
Gaussian distributed around such expected evolution, and that
the covariance decays as O(1/n).
Consider an LDPC ensemble of code length n and degree
distribution (DD) ( (x), ⇢(x)):
(x) =

(lavg (⌧ )

IV. TEP GAIN IN THE FINITE - LENGTH REGIME
In [11], the authors prove that the BP performance for ﬁnitelength LDPC codes can be predicted by analyzing the average
presence of degree-one check nodes at a ﬁnite set of time
instants during the BP decoding. These points are referred to
BP
as critical points. For a given ensemble with n ! 1, if r1 (⌧ )
is the expected evolution of the fraction of degree-one check

(1)

j=2

2

5

10

For the TEP decoder, we extend the notion of critical points:
given an LDPC ensemble with n ! 1, we say that ⌧ 0 is a
TEP-critical point of the LDPC ensemble if

4

lim r1 (⌧ 0 ) = 0,

3

10

where r1 (⌧ 0 ) is the evolution of degree-one check nodes under
TEP decoding, computed in [4]. The following lemma relates
the number of TEP and BP critical points for the same LDPC
ensemble. The complete proof of this lemma can be found in
the extended version of this paper in [4]:

4

10

2

10

3

10

0.06

0.08

0.1

0.12

0.14

0.16

Lemma 1: For a given LDPC[ (x), ⇢(x), n ! 1] ensemble used for transmission over the BEC, the number of TEP
critical points is equal to the number of BP critical points.

0.18

Resid u al grap h n ormalized size e (⌧ )

1

10

0

0.05

0.1

0.15

0.2

0.25

0.3

0.35

0.4

0.45

Resid u al grap h n ormalized size e (⌧ )

(a)

To estimate the TEP performance, we compute the cumulative probability distribution of decoding trajectories at the
critical points. For a given ﬁnite-length ensemble, the TEP
expected graph evolution provides the average presence of
degree-one check nodes at any time 2 ⌧ , i.e., r1 (⌧, n, ✏). Unlike
the BP case in (4), the average trajectory r1 (⌧, n, ✏) is strongly
dependent on the code length n. For instance, in Fig. 4, we
include the solution for r1 (⌧, n, ✏) for the (3, 6) regular code
and different code lengths n = 2i for i = 12, . . . , 17 at
✏ = ✏BP = ✏TEP . For n
217 , we locate the unique TEPcritical point at e(⌧ ) ⇡ 0.1, where r1 (⌧ 0 , n, ✏BP ) vanishes. For
lower code lengths, r1 (⌧ 0 , n, ✏TEP ) does not vanish since the
graph is small enough to make PS (⌧ ) in (2) signiﬁcant. The
fraction r1 (⌧ 0 , n, ✏TEP ) represents the number of degree-one
check nodes that the TEP decoder is able to create with respect
to the BP solution, which is zero at the critical point.
As we increase n, we observe that, above a certain length
threshold nth , r1 (⌧ 0 , n, ✏TEP ) becomes zero. On the one hand,
for n
nth , we do not expect signiﬁcant mismatch between
the BP and the TEP solutions. On the other hand, for n < nth ,
a closer look to the curves in Fig. 4 shows that r1 (⌧ 0 , n, ✏TEP )
decays approximately as O(1/n), which is consistent with
with probability PS (⌧ ) in (2):

5

10

4

R i (⌧ ), i = 1, 2

10

3

10

2

10

1

10

0

0.05

0.1

0.15

0.2

0.25

0.3

0.35

0.4

0.45

Resid u al grap h n ormalized size e(⌧ )

(b)
Fig. 3. We include the predicted evolution of R1 (⌧ ) (C) and R2 (⌧ ) (⇧) for a
regular (3, 6) code with n = 217 and an erasure probability ✏ = 0.415 < ✏BP
(a) and ✏ = 0.43 > ✏BP (b), where ✏BP = 0.4294. We include in thin lines
a set of 20 individual decoding trajectories chosen at random.

nodes under BP decoding, we say that ⌧ ⇤ is a BP-critical point
if
BP
lim r1 (⌧ ⇤ ) = 0,

(3)

✏!✏BP

where

and

(6)

✏!✏TEP

R i (⌧ ), i = 1, 2

R i (⌧ ), i = 1, 2

10

r1 (⌧ 0 , n, ✏TEP ) ⇡

BP
r1 (⌧ )

is computed analytically in [10]:
✓
◆
BP
r1 (u) = ✏ (u) u 1 + ⇢ (1 ✏ (u)) ,
@u
@⌧
=
) u = exp
u
e(⌧ )

✓ Z

⌧
0

ds
e(s)

◆

.

TEP n

1

,

(7)

where TEP depends on the ensemble. We obtain this value
by linearly interpolating r1 (⌧ 0 , n, ✏TEP ) 1 for different code
lengths. Indeed, we have observed that (7) is a general property, where the constant TEP depends on the ensemble. For
1
instance, for the (3, 6) regular code we obtain TEP = 0.3194
and for the following single-critical-point irregular LDPC
ensemble with BP threshold ✏BP = 0.4828 deﬁned by

(4)

(5)

Given the parameter u in (5), the decoding process starts at
u = 1 and ﬁnishes, if it succeeds, at u = 0. In [11], it is
shown that the BP decoder at ✏ = ✏BP
✏ succeed with
very high probability as long as there exists, on average,
degree-one check nodes at the critical points. The ﬁnitelength performance is estimated by computing the cumulative
probability distribution of individual trajectories at the critical
points. We show that the same idea extends to the TEP case.

(x) =
we computed

1
TEP

1
5
x + x3 ,
6
6

⇢(x) = x5 ,

(8)

= 0.2925.

2 To avoid any confusion, in the following, we explicitly include the
dependence with n and ✏.

3

−1

variable is less than zero:
⇥ BP
⇤
ELDPC[ (x),⇢(x),n] PW (C, ✏) ⇡
0
1
BP
@r1 (⌧ )
B @✏ ⌧ =⌧ ⇤ ✏ C
✓p
B
C
n(✏BP
✏=✏BP
C=Q
1 QB q
B
C
↵BP
BP (⌧ ⇤ )/n A
@
r1 ,r1

10

−2

r 1 (⌧ , n, ✏ T EP )

10

−3

10

where
n = 2 12
n = 2 13

−4

10

↵BP =

n = 2 14
n =

2 15

n = 2 17
0.05

0.1

0.15

0.2

0.25

0.3

Residual graph normalized size e(⌧ )

Fig. 4. We plot the solution for r1 (⌧ ) along with e(t) for a (3, 6) regular
code at ✏ = ✏BP = ✏TEP . The code lengths considered are n = 212 (+),
n = 213 ( ), n = 214 (⇤), n = 215 (⇧), n = 216 (⇥) and n = 217 (•).

⌘
) ,

(9)

r1 (⌧ 0 , n, ✏) =

BP
where PW (C, ✏) is the average block error probability for
C 2 LDPC[ (x), ⇢(x), n], ↵BP = ↵BP ( (x), ⇢(x)) and BP =
BP ( (x), ⇢(x)), i.e., ↵BP and BP are constants that depend
only on the degree distribution. The analytical expression for
the parameters ↵BP and BP can be found in [11], [6].
It is important for our work to provide further details about
the derivation of the SL in (9). For ✏ = ✏BP , we know by
assumption that there only exists one critical point ⌧ ⇤ . If we
now vary ✏ slightly, the expected fraction of check nodes at
⌧ ⇤ can be estimated by Taylor expansion:

@rBP (⌧ )
BP
r1 (⌧ ⇤ ) = 1
@✏

⌧ =⌧ ⇤
✏=✏BP

✏,

BP
@r1 (⌧ )
@✏

◆

(11)

1
⌧ =⌧ ⇤
✏=✏BP

.

(12)

We now show that the TEP decoder can be modeled by
a similar scaling law and we provide a ﬁrst estimate of the
scaling parameters as a function of the LDPC DD.
The function r1 (⌧, n, ✏BP ) provides the average presence of
degree-one check nodes at the codes’s critical point for ﬁnite
block-lengths. We proceed as in (10)-(12) to estimate the TEP
error probability. The LDPC ensemble has threshold ✏TEP =
✏BP and a critical point at ⌧ 0 . Assume now an slight deviation
of the erasure probability ✏ = ✏TEP + ✏. According to (7), the
average fraction of degree-one check nodes has the following
Taylor expansion:

Consider a transmission over the BEC using the ensemble
LDPC[ (x), ⇢(x), n], which has a single non-zero critical
point. Under these conditions, in [11] it was proposed the
following SL to predict the BP error performance:

1/3

✓

,

B. TEP SL for single critical-point LDPC ensembles

A. BP SL for single critical-point LDPC ensembles

⇥ BP
⇤
ELDPC[ (x),⇢(x),n] PW (C, ✏) =
✓p
◆
2/3
n(✏BP
✏) ⇣
BP n
1 + O(n
Q
↵BP

BP
r1 ,r1 (⌧ )

◆

For moderate block-lengths, we are underestimating the error
probability since we ignore those trajectories for which the
fraction of check nodes of degree one vanishes at ⌧  ⌧ ⇤ .
This effect is included in the scaling function by introducing
the BP parameter in (9).

n = 2 16

0

q

✏)

TEP n

1

+

@r1 (⌧, n, ✏)
@✏

0

✏.

(13)

⌧ =⌧
✏=✏TEP

To estimate the TEP error probability, we consider that the
TEP decoder will succeed with high probability as long as the
fraction of degree-one check nodes at ⌧ 0 is positive. Therefore,
assuming a Gaussian distribution around the mean in (13) with
TEP
a variance denoted by r1 ,r1 (⌧ 0 )/n, we have
⇥ TEP
⇤
ELDPC[ (x),⇢(x),n] PW (C, ✏)
0
1
p
n(✏TEP ✏)
TEP
A,
= Q@
+q
(14)
↵TEP
TEP
n r1 ,r1 (⌧ 0 )
TEP
where PW (C, ✏) is the TEP block error rate for the code
C 2 LDPC[ (x), ⇢(x), n] and
✓
◆ 1
q
@r1 (⌧, n, ✏)
TEP (⌧ )
↵TEP =
.
(15)
r1 ,r1
@✏
⌧ =⌧ 0

(10)

where ✏ = (✏ ✏BP ) [11]. Because of the channel dispersion,
individual decoding trajectories are Gaussian distributed with
a variance of order O(1/n) [6], [11]. Hence, at point ⌧ ⇤ ,
the observed fraction of degree-one check nodes is a normal
random variable with mean given in (10) and variance denoted
BP
by r1 ,r1 (⌧ ⇤ )/n. A coarse estimation of the error probability
is obtained by computing the probability that this random

✏=✏TEP

The analytical computation of the normalized variance
TEP
0
r1 ,r1 (⌧ )/n at the critical point requires to solve, for the TEP
and each particular ensemble, the covariance graph evolution
equations [11]. Because the variance of the trajectories essentially comes from the channel dispersion [12] and from
the LDPC ensemble [11], a ﬁrst approach to estimate this

4

parameter is given by the BP variance at the corresponding
BP
critical point, i.e., r1 ,r1 (⌧ ⇤ ). Besides, for n ! 1, both the
TEP and BP converge to the same performance, so we set
↵TEP = ↵BP . Due to the assumption of these values for the
TEP parameters, our model provides an upper bound to the
TEP performance because, the better the decoder is, the less
variance we expect among different trajectories.

parameter estimation proposed. Due to the assumption of the
TEP
BP values for r1 ,r1 (⌧ 0 )/n and ↵TEP , we slightly overestimate
the TEP error probability. In Fig. 5 (b), we include with similar
conclusions the results for the irregular code deﬁned in (8). In
all cases, the real error curves have been averaged throughout
one hundred code samples chosen to present large enough
minimum distance so that the error ﬂoor is far below 10 4 .
C. Future directions
In this work, we provide a method to analyze the TEP
ﬁnite-length performance for an LDPC code. For ensembles
that exhibit a single critical point, a model to estimate the
error rate as a function of the channel parameter is provided.
We show that the BP equivalent parameters provide a good
ﬁrst approach. However, irregular capacity-achieving LDPC
ensembles typically have several critical points. In [13], the
authors propose a BP scaling law that takes into account the
effect of all the critical points and its extension to the TEP
decoder should be done in the same way as in (14). The
computation of the (multiple) scaling parameters, for both
the TEP and the BP decoders, is the real challenge. On the
other hand, the main open problem is, without any doubt, the
analysis of the TEP decoder performance over general binary
memoryless channels.

0

10

Word error rate

−1

10

−2

10

n = 2 10
n = 2 11
n = 2 12
−3

10

0.38

0.39

0.4

0.41

0.42

0.43

0.44

0.45

0.46

0.47

0.48

Channel erasure probability ✏

R EFERENCES

(a)

[1] T. Minka and Y. Qi, “Tree-structured approximations by expectation
propagation,” in Proceedings of the Neural Information Processing
Systems Conference, (NIPS), 2003.
[2] P. Olmos, J. J. Murillo-Fuentes, and F. P´ rez-Cruz, “Tree-structured
e
expectation propagation for decoding ﬁnite-length LDPC codes,” IEEE
Communications Letters, vol. 15, no. 2, pp. 235 –237, Feb. 2011.
[3] P. M. Olmos, J. J. Murillo-Fuentes, and F. P´ rez-Cruz, “Tree-structure
e
expectation propagation for decoding LDPC codes over binary erasure
channels,” in International Symposium on Information Theory, ISIT,
2010.
[4] P. M. Olmos, J. J. Murillo-Fuentes, and F. P´ rez-Cruz, “Tree-structure
e
expectation propagation for LDPC decoding over the BEC,” Submitted
to IEEE Trans. on Information Theory, 2011. [Online]. Available:
http://arxiv.org/abs/1201.0715
[5] J. Yedidia, W. Freeman, and Y. Weiss, “Constructing free-energy
approximations and generalized belief propagation algorithms,” IEEE
Transactions on Information Theory, vol. 51, no. 7, pp. 2282 – 2312,
July 2005.
[6] T. Richardson and R. Urbanke, Modern Coding Theory. Cambridge
University Press, Mar. 2008.
[7] A. Shokrollahi, “Raptor codes,” Information Theory, IEEE Transactions
on, vol. 52, no. 6, pp. 2551 –2567, june 2006.
[8] M. A. Shokrollahi and M. Luby, “Raptor codes,” Foundations and Trends
in Communications and Information Theory, vol. 6, no. 3-4, pp. 213–
322, 2009.
[9] G. Liva, B. Matuz, E. Paolini, and M. Chiani, “Pivoting algorithms for
maximum likelihood decoding of LDPC codes over erasure channels,”
in IEEE Global Telecommunications Conference, GLOBECOM 2009,
Dec. 2009, pp. 1 –6.
[10] M. Luby, M. Mitzenmacher, A. Shokrollahi, D. Spielman, and V. Stemann, “Efﬁcient erasure correcting codes,” IEEE Trans. on Information
Theory, vol. 47, no. 2, pp. 569–584, Feb. 2001.
[11] A. Amraoui, A. Montanari, T. Richardson, and R. Urbanke, “Finitelength scaling for iteratively decoded LDPC ensembles,” IEEE Trans.
on Information Theory., vol. 55, no. 2, pp. 473–498, 2009.
[12] Y. Polyanskiy, H. Poor, and S. Verdu, “Channel coding rate in the ﬁnite
blocklength regime,” IEEE Transactions on Information Theory, vol. 56,
no. 5, pp. 2307 –2359, may 2010.
[13] A. Amraoui, R. Urbanke, and A. Montanari, “Finite-length scaling of
irregular LDPC code ensembles,” in 2005 IEEE Information Theory
Workshop, Aug. 2005.

0

Word error rate

10

−1

10

n = 2 10
n = 2 11
n = 2 12
−2

10

0.44

0.45

0.46

0.47

0.48

0.49

0.5

Channel erasure probability ✏

(b)
Fig. 5. In (a), we compare the TEP performance for the regular (3, 6)
ensemble (solid lines) with the approximation in (14) (dashed lines), using
TEP
the approximation ↵TEP ⇡ 0.56036, r1 ,r1 (⌧ ⇤ ) ⇡ 0.0526 and TEP ⇡
0.3194. In (b), we reproduce the same ﬁgure for code deﬁned in (8). The SL
TEP
parameters are ↵TEP ⇡ 0.6887, r1 ,r1 (⌧ ⇤ ) ⇡ 0.0593 and TEP ⇡ 0.2925.

Let us include a couple of examples. In Fig. 5 (a), we
compare the SL solution in (14) in dashed lines with real
performance data obtained through simulation in solid lines
for the regular (3, 6) LDPC ensemble for code lengths n = 2i
i = 10, . . . , 12. As shown in [2], for these code lengths
the TEP signiﬁcantly improves the BP solution. The match
between dashed and solid lines is quite good, proving the
accuracy of the model for the TEP performance and the

5

