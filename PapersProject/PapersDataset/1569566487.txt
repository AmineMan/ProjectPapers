Creator:        TeX
Producer:       Appligent StampPDF Batch, version 5.1
CreationDate:   Fri Apr 27 17:31:08 2012
ModDate:        Tue Jun 19 12:54:56 2012
Tagged:         no
Pages:          5
Encrypted:      no
Page size:      612 x 792 pts (letter)
File size:      388508 bytes
Optimized:      no
PDF version:    1.6
ISIT'2012 1569566487

Secure Computation in a Bidirectional Relay
Navin Kashyap and Shashank V

Andrew Thangaraj

Dept. of Electrical Communication Engineering
Indian Institute of Science, Bangalore, India
Email: {nkashyap,shashank}@ece.iisc.ernet.in

Dept. of Electrical Engineering
Indian Institute of Technology, Madras, India
Email: andrew@ee.iitm.ac.in

to decode the eXclusive OR (XOR) X ⊕ Y , and broadcast
the XOR to A and B in the broadcast phase. This strategy,
known as XOR coding, has been suggested and used by several
authors, and has been generalized to the notion of physical
layer network coding in [4], [5].
In this work, we consider the secure XOR-coded bidirectional relay scenario, where A and B intend that R decodes
the XOR X ⊕ Y in the MAC phase, but remains completely
ignorant of both the individual bits X and Y . In fact, we
consider a more general scenario where X, Y take values in a
ﬁnite Abelian group G, for example, a binary linear code. In
the MAC phase, the relay R must be able to decode X ⊕ Y ,
where ⊕ is now the group operation within G, while getting
no information about the individual values of X and Y .
We design explicit randomized modulation strategies at the
nodes A and B for achieving the objectives of perfect security
of the individual messages X, Y , and correct decoding of
their sum X ⊕ Y at the relay R in the Gaussian MAC phase.
Interestingly, we achieve perfect security using the addition
operation of U and V in (1), and this is an important novel
contribution of our work. The tools used for achieving the
objective of perfect security are characteristic functions and
the Poisson summation formula from probability theory and
Fourier analysis. For the noisy case, we provide a coding
scheme based on nested lattice codes for perfectly secure and
reliable group computation.
Security against an eavesdropping two-way or bidirectional
relay was considered in [6] using friendly jammers that create
a wiretap channel. Lattice codes have been proposed for
Gaussian wiretap channels in [7]. Security for a network with
several two-way realys arranged in a line with cooperative
jamming was considered in [8], where a lattice-based scheme
was proposed. In all of the above works, weak informationtheoretic security (mutual information rate to eavesdropper
tends to zero) has been used as a secrecy metric. In contrast, in
this work, we achieve perfect secrecy i.e. the secret message
is independent of the eavesdropper’s received values.
Throughout this paper, + denotes addition over the reals R,
and ⊕ denotes addition within a ﬁnite Abelian group G.

Abstract—Bidirectional relaying, where a relay helps two user
nodes to exchange equal length binary messages, has been an
active area of recent research. A popular strategy involves a
modiﬁed Gaussian MAC, where the relay decodes the XOR of
the two messages using the naturally-occurring sum of symbols
simultaneously transmitted by user nodes. In this work, we
consider the Gaussian MAC in bidirectional relaying with an
additional secrecy constraint for protection against a honest but
curious relay. The constraint is that, while the relay should
decode the XOR, it should be fully ignorant of the individual
messages of the users. We exploit the symbol addition that
occurs in a Gaussian MAC to design explicit strategies that
achieve perfect independence between the received symbols and
individual transmitted messages. Our results actually hold for a
more general scenario where the messages at the two user nodes
come from a ﬁnite Abelian group G, and the relay must decode
the sum within G of the two messages. We provide a lattice coding
strategy and study optimal rate versus average power trade-offs
for asymptotically large dimensions.

I. I NTRODUCTION
A communication device or node, denoted R, is said to act
as a relay between two other nodes, denoted A and B, if R
facilitates communications from A to B by receiving messages
from A and forwarding them to B. The relay R is said to be
bidirectional if it additionally facilitates communications from
B to A in the reverse direction. We will suppose that A, B
and R are wireless communication nodes that are half-duplex
(cannot transmit and receive simultaneously), and that A and
B are not connected directly. Further, we will assume that all
links between nodes are Gaussian channels. In such settings,
bidirectional relaying typically happens in two phases: (1)
(Gaussian) MAC phase, where A and B transmit to R, and
(2) Broadcast phase, where R transmits to A and B. Twophase bidirectional relaying has been extensively studied in
the recent literature [1], [2], [3].
In the MAC phase, suppose that bits X and Y are modulated
by A and B (independently at some common time) into realvalued transmitted symbols denoted by random variables U
and V , respectively. Then, the relay will receive an instance
of a random variable W , which can be modeled as
W = U + V + Z,

(1)

II. T HE N OISELESS S ETTING

where we have assumed that the links A → R and B → R
have unit gain (normalized), and Z denotes additive noise
independent of U and V . An important departure from the
standard Gaussian MAC is that the bidirectional relay R need
not decode both the bits X and Y . Instead, it is sufﬁcient

The general set-up is as follows: nodes A and B possess
messages X, Y , which are independent random variables (rvs),
uniformly distributed over a ﬁnite Abelian group G. The
messages X and Y are randomly modulated, independently at

1

some common time, into Rd -valued rvs U and V , respectively,
which are transmitted to the relay R; here, d is some positive
integer. To explain the randomized modulation scheme for
achieving perfect secrecy, we ﬁrst consider the setting where
Z = 0 in (1), so that the relay receives W = U + V . In this
setting, the requirements of the modulation scheme can be
summarized as follows (⊥ denotes statistical independence):
⊥
(Z1) (U, X) ⊥ (V, Y );
⊥
(Z2) U + V ⊥ X and U + V ⊥ Y ; and
⊥
⊥
(Z3) U + V almost surely determines X ⊕ Y .
We will show that it is, in fact, possible to construct such
rvs U, V . This is somewhat surprising since it can be easily
shown that we cannot have non-degenerate real-valued rvs U
and V such that U + V ⊥ U and U + V ⊥ V . To explain
⊥
⊥
without clutter the ideas behind our construction, we consider
ﬁrst the simplest case of G = Z2 , i.e., the integers modulo 2.

In summary, we have the following lemma.
Lemma 1. Suppose that the conditional pmfs pU |a and pV |a ,
a ∈ {0, 1}, satisfy (3) and (5). Then, the rvs U, V, X, Y with
joint pmf given by (2) have properties (Z1)–(Z3).
The idea now is to construct pmfs that satisfy the hypotheses
of Lemma 1. To do this, we rely upon methods and results
from Fourier analysis. The key tool we need is the Poisson
summation formula, which we brieﬂy recall here. Our description is based largely on Section XIX.5 in [9].
2) Poisson summation formula: Let ψ be the characteristic function of a real-valued random variable X, such that
∞
|ψ(t)|dt < ∞. In particular, ψ is continuous and ψ(0) =
−∞
1. Since ψ is absolutely integrable, the random variable X has
a continuous density f . The Poisson summation formula [9,
Chapter XIX, equation (5.9)] states that for any T > 0 and
s ∈ R, we have for all ζ ∈ R,

A. Secure Computation of XOR at the Relay
In this section, X and Y are independent and identically
distributed (iid) uniform binary rvs, and X ⊕ Y denotes their
modulo-2 sum (XOR). We describe a construction of integervalued rvs U and V satisfying (Z1)–(Z3).
1) Conditions on PMFs and characteristic functions: We
ﬁrst derive conditions under which integer-valued rvs U and V
can satisfy properties (Z1)–(Z3). We introduce some notation:
for k ∈ Z, let pU (k) = Pr[U = k], pV (k) = Pr[V = k],
and for a ∈ {0, 1}, let pU |a (k) = Pr[U = k | X = a],
pV |a (k) = Pr[V = k | Y = a]. Thus, pU = (1/2)(pU |0 +pU |1 )
and pV = (1/2)(pV |0 + pV |1 ).
Property (Z1) is equivalent to requiring that the joint probability mass function (pmf) of (U, V, X, Y ) be expressible as
pU V XY (k, l, a, b) = (1/2)(1/2)pU |a (k)pV |b (l)

∞

n=−∞

(2)

(3)

∞

ψ(ζ + 2nπ/T ) e−is(2nπ/T )

Ψ(ζ) =
n=−∞

is the characteristic function of a discrete rv supported within
the set {kT + s : k ∈ Z}. The probability mass at the point
kT + s is equal to T f (kT + s).

(4)

It helps to view this in the Fourier domain. Let ϕU , ϕV ,
ϕU |a etc. denote the respective characteristic functions of
the pmfs pU , pV , pU |a etc. — for example, ϕU |a (t) =
ikt
. Then, (4) is equivalent to
k∈Z pU |a (k)e
ϕU ϕV = ϕU |a ϕV = ϕU ϕV |a for a ∈ {0, 1}.

k=−∞

Proposition 2. Let ψ be a characteristic function such that
ψ(t) = 0 whenever |t| ≥ π/T for some T > 0, and let f be
the corresponding probability density function. Then, for any
s ∈ R, the function Ψ : R → C deﬁned by

Finally, we turn our attention to (Z2). Let us deﬁne, for
k ∈ Z, pU +V (k) = Pr[U + V = k], and for a ∈ {0, 1},
pU +V |X=a (k) = Pr[U +V = k | X = a] and pU +V |Y =a (k) =
Pr[U + V = k | Y = a]. Assuming (U, X) ⊥ (V, Y ), we have
⊥
pU +V = pU ∗ pV , pU +V |X=a = pU |a ∗ pV , and pU +V |Y =a =
pU ∗ pV |a , where ∗ denotes the convolution operation. Thus,
when (U, X) ⊥ (V, Y ), (Z2) holds iff
⊥
pU ∗ pV = pU |a ∗ pV = pU ∗ pV |a for a ∈ {0, 1}.

f (kT +s) ei(kT +s)ζ ,

(6)
provided that the series on the left converges to a continuous
∞
function Ψ(ζ). Note that Ψ(0) = T k=−∞ f (kT +s), which
is a non-negative quantity. If Ψ(0) = 0, then dividing both
sides of (6) by Ψ(0) yields the important fact that Ψ(ζ)/Ψ(0)
is the characteristic function of a discrete random variable supported within the set {kT +s : k ∈ Z}, the probability mass at
∞
the point kT +s being equal to f (kT +s)/ k=−∞ f (kT +s).
A special case of interest is when ψ is compactly supported.
Let T > 0 be such that ψ(t) = 0 whenever |t| ≥ π/T .
It is straightforward to see that the series on the left-handside of (6) converges to a continuous function Ψ, and that
Ψ(0) = ψ(0) = 1. From this, we infer that Ψ is the
characteristic function of a discrete rv, as explained above. For
future reference, we record this in the form of a proposition.

for k, l ∈ Z and a, b ∈ {0, 1}. Property (Z3) is satisﬁed by
any U, V such that
pU |0 (k) = pV |0 (k) = 0 for all odd k ∈ Z,
pU |1 (k) = pV |1 (k) = 0 for all even k ∈ Z.

∞

ψ(ζ+2nπ/T ) e−is(2nπ/T ) = T

It should be noted that compactly supported characteristic
functions do indeed exist — see e.g., [9, Section XV.2,
Table 1], [10], [11]. We also give an explicit construction after
the proof of Theorem 3 in the next subsection.
3) General construction: Let ψ be a characteristic function
(of a continuous random variable X) with the properties that

(5)

Note that ϕU = (1/2)(ϕU |0 + ϕU |1 ) and ϕV = (1/2)(ϕV |0 +
ϕV |1 ). Hence, (5) should be viewed as a requirement on the
conditional pmfs pU |a and pV |a , a ∈ {0, 1}.
(C1) ψ(t) = 0 for |t| ≥ π/2, and

2

ψ(t)

supported within the even and odd integers, respectively. The
pmf corresponding to ϕ0 is given by

1

p0 (k) =

t

−π

−π/2

0

π/2

π

p1 (k) =

ϕ0 (ζ)

1

−π/2

0

π/2

π

2f (k)
0

if k is an odd integer
otherwise.

3π/2

ϕ2 = ϕϕ0 = ϕϕ1 .
ϕ1 (ζ)

−π/2

0

π/2

π

3π/2

−1

Fig. 2. The periodic functions ϕ0 and ϕ1 derived from ψ.

Based on this theorem, secure computation of XOR at the
relay works as follows: the nodes A and B modulate their bits
independently to an integer k, with probability p0 (k) (from
(8)) if the bit is 0, or with probability p1 (k) (from (9)) if the
bit is 1. The probability distributions can be chosen such that
the modulated symbols have ﬁnite average power. The sum of
the integers from A and B received at the relay R is independent
of the individual bits of A and B. However, the XOR of the
two bits can be recovered at R with probability 1.
Proof of Theorem 3. With pU |0 = pV |0 = p0 and pU |1 =
pV |1 = p1 , we have pU = pV = p, where p is as in (7).
Clearly, (3) holds. To verify (5), note that, by virtue of
(10), we have for a ∈ {0, 1}, ϕU ϕV = ϕ2 = ϕϕa . But,
by construction, ϕU ϕV |a = ϕV ϕU |a = ϕϕa . Therefore, by
Lemma 1, the rvs (U, V, X, Y ) with joint pmf given by (2)
have the properties (Z1)–(Z3).
The assertion about the variance of U and V follows from
Lemma 2 in [9, Section XV.4]. We omit the details.
For completeness, we give an explicit construction of a compactly supported, twice-differentiable characteristic function
ψ. Consider the density (from [9, Section XV.2, Table 1])

(C2) ψ(t) is real and non-negative for all t ∈ R.1
Note that since ψ is real-valued, it must be an even function:
ψ(−t) = ψ(t) for all t ∈ R. Since ψ is integrable over R, by
the Fourier inversion formula, the random variable X has a
continuous density f . Note that Proposition 2 holds for T ≤ 2.
Let ϕ be the periodic function with period 2π that agrees
∞
with ψ on [−π, π]. Note that ϕ(ζ) = n=−∞ ψ(ζ + 2πn).
Thus, applying Proposition 2 with T = 1 and s = 0, we
ﬁnd that ϕ is the characteristic function of an integer-valued
random variable, with pmf given by
p(k) = f (k) for all k ∈ Z.

(7)

Next, for s = 0, 1, deﬁne ϕs as follows: for ζ ∈ R,
∞

ψ(ζ + nπ)e−isnπ .

ϕs (ζ) =

(10)

Theorem 3. Let X, Y be iid Bernoulli(1/2) rvs. Suppose that
we are given a probability density function f : R → R≥0
with a non-negative real characteristic function ψ such that
ψ(t) = 0 for |t| ≥ π/2. Set pU |0 = pV |0 = p0 and pU |1 =
pV |1 = p1 , where p0 and p1 are as in (8) and 9). Then, the
resulting Z-valued rvs U and V satisfy properties (Z1)–(Z3).
Additionally, the rvs U and V have ﬁnite variance iff ψ is twice
differentiable, in which case the variance equals −ψ (0).

ζ

−π

(9)

We can now prove the following theorem.

1

−3π/2

(8)

1
From (7)–(9), we have p(k) = 2 (p0 (k)+p1 (k)) for all k ∈ Z.
Finally, note that since ϕ0 (t) and ϕ1 (t) differ from ϕ(t)
only when ϕ(t) = 0, we have

ζ

−π

if k is an even integer
otherwise.

and that corresponding to ϕ1 is

Fig. 1. A generic characteristic function supported on [−π/2, π/2].

−3π/2

2f (k)
0

n=−∞

It is easily seen that ϕ0 is the periodic extension of ψ with
period π, i.e., ϕ0 is the periodic function with period π that
agrees with ψ on [−π/2, π/2], as depicted at the top of
Figure 2 for a generic ψ shown in Figure 1. On the other hand,
ϕ1 is periodic with period 2π: its graph is obtained from that
of ϕ0 by reﬂecting about the ζ-axis every second copy of ψ,
as depicted at the bottom of Figure 2.
Applying Proposition 2 with T = 2 and s ∈ {0, 1},
we get that ϕ0 and ϕ1 are characteristic functions of rvs

h(x) =

1
2π
1−cos x
πx2

if x = 0
if x = 0

(11)

ˆ
which has characteristic function h(t) = max{0, 1 − |t|}. The
ˆ ∗ h, where ∗ denotes convolution, can be
ˆ
function g = h
explicitly computed to be

1
 2 |t|3 − t2 + 2 if |t| ≤ 1

3
ˆ ˆ
g(t) = (h ∗ h)(t) = 1 (2 − |t|)3
if 1 ≤ |t| ≤ 2 (12)
6

0
otherwise

1 There is no loss of generality in imposing this requirement. Suppose that
a random variable X has characteristic function ψ, which is complex-valued
in general. Let X1 , X2 be iid rvs with the same distribution as X. Then,
X1 − X2 has characteristic function ψψ = |ψ|2 .

3

Proposition 4. The function f (x) = (3π 2 /4) [h(πx/4)]2 , with
h as in (11), is a density function whose characteristic function
is given by
ψ(t) = 3 g( 4t ),
2
π

Theorem 5. Suppose that ψ : Rd → R≥0 is the characteristic
function of a probability density function f : Rd → R≥0 ,
ˆ
ˆ
such that ψ(t) = 0 for t ∈ V(Λ0 ), where Λ0 is the Fourier
/
dual of Λ0 . For j = 0, 1, . . . , N − 1, deﬁne the pmf pj
as follows: pj (k) = (det Λ0 )f (k) if k ∈ Λj ; otherwise,
pj (k) = 0. Finally, deﬁne a random variable U (resp. V )
jointly distributed with X (resp. Y ) as follows: if X = Λj
(resp. Y = Λj ), U (resp. V ) is a random point from Λj
picked according to the distribution pj . Then, the resulting Λvalued rvs U, V satisfy properties (Z1)–(Z3). Additionally, if ψ
2
2
is twice differentiable, then E U = E V
= − 2 ψ(0),
d
2
2
where
= j=1 ∂j is the Laplacian operator.

where g is as in (12). The function ψ is non-negative with
ψ(t) = 0 for |t| ≥ π/2. Furthermore, ψ is twice differentiable,
with ψ (0) = −48/π 2 .
We omit the simple proof of the proposition.
B. Extension to Finite Abelian Groups
A close look at the modulations in the previous section
reveals the following structure: points from the lattice 2Z and
its coset (in Z) 1 + 2Z are chosen for sending bit 0 and
1, respectively, according to a carefully chosen probability
distribution given by Theorem 3. In essence, we have a ﬁne
lattice Λ = Z and a coarse lattice Λ0 = 2Z with the quotient
group Λ/Λ0 consisting of the two cosets 2Z and 1 + 2Z
making up the probabilistically-chosen modulation alphabet.
Note that the quotient group in this case is isomorphic to Z2 ,
and this enables recovery of the XOR of the bits (addition in
Z2 ) from integer addition of transmitted symbols modulo the
coarse lattice. Also, the choice of the probability distribution
(from Theorem 3) ensures that the choice of coset at each
transmitter is independent of the integer sum at the relay.
Now, any ﬁnite Abelian group G can be expressed as
the quotient group Λ/Λ0 for some pair of nested lattices
Λ0 ⊆ Λ. Indeed, any such G is isomorphic to a direct
sum of cyclic groups: G ∼ ZN1 ⊕ ZN2 ⊕ · · · ⊕ ZNk for
=
some positive integers N1 , N2 , . . . , Nk [12, Theorem 2.14.1].
Here, ZNj denotes the group of integers modulo-Nj . Taking
Λ = Zk and Λ0 = A Zk , where A is the diagonal matrix
diag(N1 , N2 , . . . , Nk ), we have G ∼ Λ/Λ0 . So, the ﬁnite
=
Abelian group case is equivalent to considering the quotient
group, i.e., the group of cosets, of a coarse lattice Λ0 within
a ﬁne lattice Λ. These lattices may be taken to be full-rank
lattices in Rd .
For a full-rank lattice Λ in Rd , let

As with Theorem 3 and XOR, the above theorem allows
for secure computation at the relay of the group operation
X ⊕ Y . The theorem is proved in a manner completely
analogous to Theorem 3, the main difference being that the
multi-dimensional Poisson summation formula is used in place
of (6). We skip the proof for lack of space.
ˆ
While any characteristic function ψ supported within V(Λ0 )
sufﬁces for the construction of Theorem 5, it is of interest
to use a ψ for which − 2 ψ(0) is the least among such
ψ’s. This would yield random variables U and V of least
second moment, having the desired properties. It turns out that
the second moment cannot be made arbitrarily small. Indeed,
the following result, adapted from [10], gives a precise and
complete answer to the question of how small − 2 ψ(0) can
be for a characteristic function ψ supported within a ball of
radius R in Rd .
Theorem 6 ([10], Theorem 5.1). If ψ is a characteristic
function such that ψ(t) = 0 for t ≥ ρ, then
−

2

ψ(0) ≥

4 2
j d−2 ,
ρ2 2

(14)

where jk denotes the ﬁrst positive zero of the Bessel function
Jk . Furthermore, equality holds iff ψ(t) = ψ(t/ρ) for a certain non-negative characteristic function ψ supported within
the unit ball.
A precise expression for ψ and the corresponding density
function can be found in [10].

d

V(Λ) = {x ∈ R : x < x − z for all z ∈ Λ, z = 0},
(13)
where · denotes the Euclidean (L2 ) norm, be the interior of
the Voronoi region of Λ around the point 0. In words, V(Λ)
is the set of points of Rd for which 0 is the unique closest
point of the lattice Λ. The dual lattice is deﬁned as Λ∗ =
ˆ
{y ∈ Rd : xT y ∈ Z}, and the Fourier dual is Λ = 2πΛ∗ . The
determinant of Λ, denoted by det Λ, is equal to | det A| for
any (square) matrix A such that Λ = AZd .
Let Λ0 be a sublattice of Λ of index N (i.e., the number
of cosets of Λ0 in Λ is N ). List the cosets of Λ0 in Λ as
Λ0 , Λ1 , . . . , ΛN −1 , which constitute the quotient group G =
Λ/Λ0 . As before, ⊕ denotes addition within G.
Consider rvs X, Y uniformly distributed over G. We wish
to construct rvs U, V taking values in Λ, having the properties
(Z1)–(Z3). The following theorem shows that this is possible.

III. T HE G AUSSIAN N OISE S ETTING
The modulation scheme of Section II-B extends in a very
natural way to a lattice coding scheme that can be used for
secure and reliable computation over a Gaussian MAC channel
as in (1), where Z is now iid Gaussian noise. We describe the
coding scheme below.
(d)
Code: A (Λ(d) , Λ0 ) code consists of a pair of full-rank nested
(d)
lattices Λ0 ⊆ Λ(d) in Rd . The computation is performed
(d)
(d)
in the group G(d) = Λ(d) /Λ0 , whose N (d)
|Λ(d) /Λ0 |
elements are listed as Λ0 , Λ1 , . . . , ΛN (d) −1 .
Encoding: We have messages X, Y at nodes A, B that are
independent rvs, uniformly distributed over G(d) . We ﬁrst
ˆ (d)
pick a characteristic function ψ supported within V(Λ0 ),
as needed in Theorem 5. In fact, we impose the restriction

4

that ψ be supported within a ball centred at 0 with radius
ˆ (d)
equal to the packing radius, rpack (Λ0 ), of the dual lattice
(d)
ˆ
Λ0 . Now, the packing radius is, by deﬁnition, the largest
ˆ (d)
radius of a ball centred at 0 that is contained within V(Λ0 ).
ˆ
So, if ψ(t) = 0 for t ≥ rpack (Λ0 ), then ψ(t) is certainly
ˆ 0 ). If X = Λj , node A transmits a
supported within V(Λ
random vector u ∈ Λj picked according to the distribution
pj of Theorem 5. Similarly, if Y = Λk , node B transmits a
random vector v ∈ Λk picked according to the distribution pk .
1
The rate of transmission from A or B is R(d) = d log2 N (d) .
The average transmit power per dimension at each node is
2
P (d) = − dψ(0) , as in Theorem 5. Thus, from Theorem 6,
we see that an average transmit power per dimension as low
as
4j 2
d−2
(15)
P (d) = 2 2 ,
ρ d

It now remains to characterize the average transmit power
per dimension at which the rates guaranteed by Proposition 7
are achieved. From (16), it is clear that we need to relate
ˆ
rpack (Λ0 ) to rcov (Λ0 ). Extending the arguments in [15], we can
(d)
show that there exists a sequence of nested lattices (Λ(d) , Λ0 )
as guaranteed by Proposition 7 for which
1
1
(d)
ˆ (d)
(17)
lim rpack (Λ0 )rcov (Λ0 ) = .
d→∞ d
2e
also holds (a proof will be given in a forthcoming full
version of this paper). Using this result, we have the following
theorem.
Theorem 8. A rate R = 1 log2 (P/(4e2 σ 2 )) is achievable
2
with perfect secrecy at a transmit power of P.
1
Proof: Take the constant M in Proposition 7 to be ( 2e )2 P
√
(d)
1
for some P > 0, so that rcov (Λ0 ) = 2e dP. We then ﬁnd,
(d)
via (16) and (17), that limd→∞ P
= P.
At present, we do not have any outer bounds to suggest
that the rates achieved in Theorem 8 are good. In particular,
the factor 4e2 does not appear in any standard Gaussian-MAC
capacity regions without the secrecy constraint.

ˆ (d)
with ρ = rpack (Λ0 ), is achievable by a suitable choice of ψ.
It was shown in [14] (see also [13]) that the ﬁrst positive zero
of the Bessel function Jk can be written as jk = k + ak 1/3 +
O(k −1/3 ), where a is a constant independent of k. Therefore,
in the large d regime,
P (d) =

d
ˆ (d)
rpack 2 (Λ0 )

(1 + o(d)),

R EFERENCES
[1] I.-J. Baik and S.-Y. Chung, “Network coding for two-way relay channels
using lattices,” in Proc. 2008 IEEE Int. Conf. Commun. (ICC’08),
pp. 3898–3902.
[2] P. Popovski and H. Yomo, “Physical network coding in two-way wireless
relay channels,” in Proc. 2007 IEEE Int. Conf. Commun. (ICC’07),
pp. 707–712.
[3] M. Wilson, K. Narayanan, H. Pﬁster, and A. Sprintson, “Joint physical
layer coding and network coding for bidirectional relaying,” IEEE Trans.
Inf. Theory, vol. 56, no. 11, pp. 5641–5654, Nov. 2010.
[4] B. Nazer and M. Gastpar, “Compute-and-Forward: Harnessing Interference through Structured Codes,” IEEE Trans. Inf. Theory, vol. 57, no.
10, pp. 6463–6486, October 2011.
[5] B. Nazer and M. Gastpar, “Reliable physical layer network coding,”
Proceedings of the IEEE, vol. 99, no. 3, pp. 438–460, March 2011.
[6] R. Zhang, L. Song, Z. Han, B. Jiao, M. Debbah, “Physical layer security
for two way relay communications with friendly jammers,” Proc. 2010
IEEE Global Telecommunications Conference (GLOBECOM 2010), pp.
1-6, 6-10 Dec. 2010.
[7] F. Oggier, P. Sol´ , J.-C. Belﬁore, “Lattice Codes for the Wiretap
e
Gaussian Channel: Construction and Analysis,” submitted to the IEEE
Trans. on Information Theory, available arXiv:1103.4086v1 [cs.IT].
[8] X. He and A. Yener, “Providing secrecy with lattice codes,” Proc.
46th Annual Allerton Conference on Communication, Control, and
Computing 2008, pp. 1199-1206, 23-26 Sept. 2008.
[9] W. Feller, An Introduction to Probability Theory and its Applications,
Vol. 2, 2nd ed., Wiley, 1971.
[10] W. Ehm, T. Gneiting, and D. Richards, “Convolution Roots of Radial
Positive Deﬁnite Functions with Compact Support,” Trans. AMS, vol.
356, no. 11, pp. 4655–4685, May 2004.
[11] H. Rubin and T.M. Sellke, “Zeroes of inﬁnitely differentiable characteristic functions,” in A Festschrift for Herman Rubin, Anirban DasGupta,
ed., Institute of Mathematical Statistics Lecture Notes – Monograph
Series, vol. 45, pp. 164–170, 2004.
[12] I.N. Herstein, Topics in Algebra, 2nd ed., Wiley, 1975.
[13] A. Elbert and A. Laforgia, “An asymptotic relation for the zeros of
Bessel functions”, Journal of Math. Analysis and Applications, vol. 98,
no. 2, pp. 502–510, 1984.
[14] F.G. Tricomi, “Sulle funzioni di Bessel di ordine e argomento pressoch´
e
uguali,” Atti Accad. Sci. Torino Cl. Sci. Fis. Mat. Natur., vol. 83, pp.
3–20, 1949.
[15] U. Erez and R. Zamir, “Achieving 1/2log(1+SNR) on the AWGN channel
with Lattice Encoding and Decoding,” IEEE Trans. Inf. Theory, vol. 50,
no. 10, pp. 2293–2314, October 2004.

(16)

where o(d) → 0 as d → ∞, is achievable by a suitable choice
of ψ using Theorem 6.
Decoding: The relay R receives w = u + v + z, where
z is a Gaussian noise vector with d independent N (0, σ 2 )
components, which are all independent of u and v. The relay
estimates Λj ⊕ Λk to be the coset represented by the closest
vector to w in the lattice Λ, which we denote by QΛ (w).
Security: Since the noise z is independent of everything else,
Theorem 5 shows that w is independent of the individual
messages X, Y . Hence, even in the noisy setting, perfect
security continues to be guaranteed at the relay for any choice
of the nested lattice code.
Reliability and achievable rate: Let P(d) denote the probability
err
that QΛ (w) is different from the coset to which u+v belongs.
A rate R is said to be achievable with perfect secrecy if, for
(d)
any > 0, there exists a sequence of (Λ(d) , Λ0 ) codes such
(d)
(d)
that Perr < and R > R− for sufﬁciently large d. The rate
is said to be achieved with perfect secrecy at a transmit power
per dimension P if we have in addition that P (d) < P + for
sufﬁciently large d.
The covering radius of a lattice Λ, denoted by rcov (Λ), is
the radius of the smallest ball centred at 0 that contains V(Λ).
The proposition below characterizes achievable rates in terms
(d)
of the covering radius of the coarse lattice Λ0 . We skip the
proof, which follows easily from the results in [15] and [4].
Proposition 7. Let M > 0 be a constant. A rate R =
M
1
2 log2 σ 2 is achievable with perfect secrecy by a sequence of
√
(d)
(d)
nested lattice pairs (Λ(d) , Λ0 ) satisfying rcov (Λ0 ) = dM
for each d.

5

