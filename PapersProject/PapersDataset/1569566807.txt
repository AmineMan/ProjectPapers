Title:          LiuZhao12ISITFinal.dvi
Creator:        dvips(k) 5.94a Copyright 2003 Radical Eye Software
Producer:       Appligent StampPDF Batch, version 5.1
CreationDate:   Wed May 16 11:39:10 2012
ModDate:        Tue Jun 19 12:54:46 2012
Tagged:         no
Pages:          5
Encrypted:      no
Page size:      612 x 792 pts (letter)
File size:      304297 bytes
Optimized:      no
PDF version:    1.6
ISIT'2012 1569566807

Dynamic Intrusion Detection in
Resource-Constrained Cyber Networks
Keqin Liu, Qing Zhao
Electrical and Computer Engineering, University of California, Davis, CA 95616
Email: {kqliu,qzhao}@ucdavis.edu

An abnormal component remains abnormal until the
anomaly is detected and resolved. A healthy component
may be attacked and become abnormal if the attack
is successful. We consider a general attack model: the
behavior of the intruder can be arbitrarily correlated in
time and varies across components, and different attacks
may have different success probabilities. When an abnormal component is probed, it is ﬁxed and returns to the
healthy state. When a healthy component is probed, its
state evolution (i.e., how likely it will become abnormal
in each subsequent time instant) is reset. This reset
process models the scenario where proactive actions are
taken (patches are installed, ﬁrewalls upgraded, etc.)
by the IDS to refresh the component’s immunity to
attacks. Note that this model is signiﬁcantly different
and more complicated than the SIS (susceptible-infectedsusceptible) model and its variants (see, e.g., [4]).
For each component in an abnormal state, a cost
(depending on the criticality of the component) per unit
time is incurred. At each time, the IDS can choose a
subset of K components to probe, where K is often
much smaller than N due to resource constraints. The
question here is how to dynamically probe these N
components to minimize the total long-term cost. The
key is to learn from past observations and decisions and
dynamically adjust the probing actions.

Abstract—We consider a large-scale cyber network with
N components. Each component is either in a healthy state
(0) or an abnormal state (1). Due to intrusions, the state of
each component transits from 0 to 1 over time according
to an arbitrary stochastic process. At each time, a subset
of K (K < N ) components are probed and those observed
in abnormal states are ﬁxed. The objective is to design
a dynamic probing strategy that minimizes the long-term
network cost incurred at all abnormal components. We
formulate the problem as a Restless Multi-Armed Bandit
(RMAB) process. We show that this class of RMAB is
indexable and Whittle index can be obtained in closedform. For homogeneous networks, we show that Whittle
index policy achieves the optimal performance with a
simple structure that does not require any prior knowledge
on the intrusion processes.

I. I NTRODUCTION
The objective of Intrusion Detection Systems (IDS)
is to quickly locate malicious activities (e.g., denial
of service attack, port scans, hackers) so that infected
parts can be ﬁxed to minimize the overall damage to
the network. With the increasing size, diversity, and
interconnectivity of the cyber system, however, intrusion detection faces the challenge of scalability: how
to rapidly locate intrusions and anomalies in a large
dynamic network with limited resources. The two basic
approaches to intrusion detection, namely, active probing
and passive monitoring [1], [2], both face stringent
resource constraints when the network is large and
dynamic. Speciﬁcally, active-probing based approaches
need to choose judiciously which components of the
network to probe to reduce overhead; passive-monitoring
based approaches need to determine how to sample the
network so that real-time processing of the resulting data
is within the computational capacity of the IDS [3]. The
problem is compounded by the fact that the adversarial
behaviors are typically stochastic and evolving.
In this paper, we address resource-constrained intrusion detection in large dynamic cyber networks. We
consider a network with N heterogeneous components
which can be paths, routers, or subnets. At a given time, a
component can be in a healthy state or an abnormal state.

A. Main Results
We formulate the dynamic intrusion detection problem as a special class of Restless Multi-Armed Bandit
(RMAB) process, where each component is considered
as an arm. In 1988, Whittle generalized the classic
Multi-Armed Bandit (MAB) problem to RMAB, a more
powerful stochastic model to take into account arm
dynamics that cannot be directly controlled [5]. While
the classic MAB can be solved in linear time with respect
to the number of arms [6], ﬁnding the optimal solution to
a general RMAB is PSPACE-hard with exponential complexity [7]. Whittle proposed an index policy with linear
complexity that was shown to be asymptotically (when
the number of arms approaches inﬁnity) optimal under
certain conditions [8], [9]. The difﬁculty of Whittle index
policy lies in the complexity of establishing its existence

0 This work was supported by Army Research Lab under Grant
W911NF1120086.

1

2

Each attack process is a general stochastic process
with arbitrary time dependencies. Consequently, the state
evolution of a component is given by an arbitrary
probability sequence {pn (t)}t≥0 , where pn (t) is the
probability that component n is in the abnormal state
at time t with t being the time elapsed since the last
probing of component n. Speciﬁcally, if a component
(say, component n) is probed and observed in state 0, a
simple maintenance action is taken which resets its state
evolution to {pn (t)}t≥0 . If component n is observed in
state 1, a repair action is taken, and the component will
be back to the normal state in the next time instant1 and
then evolve according to {pn (t)}t≥0 . It is easy to see
that {pn (t)}t≥0 is a monotonically increasing sequence.
This general model includes the i.i.d. attack process as
a special case: each component is compromised with a
constant probability qn (n = 1, . . . , N ) at each time.
For this special attack model, the state of component n
transits as a Markov chain and pn (t) = 1 − (1 − qn )t ,
which monotonically converges to 1 at the geometric rate
(1 − qn ) as t increases. In general, we do not require any
speciﬁc form of {pn (t)}t≥0 .
For each abnormal component (say, component n), a
cost cn is incurred per unit time. With limited resource,
only a subset of K (K < N ) components can be probed
at each time. The objective is to minimize the long-term
average network cost by designing the optimal sequential
probing policy.

(the so-called indexability) and computing the index.
There is no general characterization regarding which
class of RMAB is indexable and whether Whittle index
can be efﬁciently computed, and little is known about
the optimality of Whittle index (when it does exist) for
ﬁnite-size systems. In this paper, we show that the class
of RMAB at hand is indexable and Whittle index can be
obtained in closed-form, leading to easy implementations
of the policy. For homogeneous networks, we show that
Whittle index policy is optimal for any network size N
and has a simple robust structure that does not require
any prior knowledge on the attack model.
B. Related Work
Most existing studies on intrusion detection do not
consider the constraint on the system monitoring capacity (see, e.g., [10]–[13]). Our work takes a stochastic
control approach to intrusion detection in large networks
with resource constraints, where the problem of adaptively allocating the limited probing and repair power is
of interest.
In the literature of RMAB, indexability was studied
in [14] for RMAB with ﬁnite state space, where numerical algorithms were proposed to test indexability
and compute Whittle index. Extensive numerical studies in [15]–[17] have demonstrated the near optimal
performance of Whittle index policy. For the RMAB
studied in this paper, the system state space is inﬁnite,
which renders such numerical methods infeasible, even
for a ﬁxed realization of system parameters. Analytical
studies of indexability exist for certain special classes
of RMAB [15]–[24]. In particular, the indexability was
established for a class of RMAB that arises in the
context of dynamic spectrum access [20], [21] and
multi-agent tracking systems [22]. Furthermore, in [21],
Whittle index policy was shown to be optimal when
arms are homogeneous by establishing its equivalence
to the myopic policy and leveraging existing results on
the optimality of the myopic policy given in [25]–[27].
The work in [21] was extended to a more general model
in [24], where the indexability, the closed-form Whittle
index, and the asymptotic optimality of Whittle index
policy were established.

III. P ROBLEM F ORMULATION
In this section, we formulate the intrusion detection
problem as a special class of Restless Multi-Armed
Bandit (RMAB) process. The concepts of indexability
and Whittle index are also introduced.
A. RMAB and Sufﬁcient Statistics
In a general RMAB, a player chooses K out of N
independent arms to activate at each time based on the
current states of all arms. At each time, the state of
each arm transits according to two potentially different
Markovian rules depending on whether it is made active
or passive. Each arm contributes an immediate reward
depending on its current state and the imposed action.
The objective is to maximize the long-term average
reward by optimally selecting arms to activate over time
based on the arm state evolutions.
We need to note that the states of all arms are assumed
to be fully observable and obey Markovian transition
rules in an RMAB. However, for the intrusion detection
problem at hand, the state (0/1) of each component
is not observable unless it is probed, and the state

II. N ETWORK M ODEL
Consider a cyber network with N heterogeneous
components that are subject to attacks over time. At
each discrete time, each component is either in the
healthy state (0) or the abnormal state (1). If an attack
to a healthy component is successful, the component
enters the abnormal state until it is probed and ﬁxed.
We assume that different components experience statistically independent but not necessarily identical attack
processes.

1 Parallel results can be obtained for the model in which a component
is repaired immediately and is guaranteed to be healthy in the current
time instant only.

2

3

N

where A = {an }N with
n=1
n=1 an = K denotes
the current probing actions, G the maximum steadystate average reward over the inﬁnite horizon, F (·) the
transient reward for a given set of initial arm states,
and EA [·] the expectation operator given A. Solving
the optimality equation (1) using dynamic programming
suffers from exponential complexity. In Sec. IV, we show
that for RMAB-IDS, the linear-complexity Whittle index
policy exists and can be obtained in closed-form with a
near-optimal performance.

transition rules are non-Markovian in general. It is thus
not suitable to model the component state as the arm
state. By exploring the reset nature of the problem, we
show in the next lemma that a sufﬁcient statistic for
optimal decision making is given by the two-dimensional
vector set {(in , tn )}N , where in ∈ {0, 1} is the last
n=1
observed state of component n and tn the time elapsed
since the last observation. As a consequence, we can
treat (in , tn ) as the arm state of component n, which is
fully observable but with an inﬁnite dimension. In the
rest of the paper, we refer to (in , tn ) as the arm state
of component n to distinguish it from the component
state Sn ∈ {0, 1}. We let an ∈ {active (1), passive (0)}
denote the probing action on arm n.
Lemma 1: For the intrusion detection problem, the
vector set {(in , tn )}N
n=1 is a sufﬁcient statistics for
optimal decision making. Furthermore, given the current
probing actions and observations, the arm state (in , tn )
of component n transits according to the following
Markovian rules.

C. Deﬁnition of Whittle Index Policy

The key idea of Whittle index policy is to provide
a subsidy for passivity to measure the attractiveness of
activating an arm at its current state. Based on the strong
decomposability of Whittle index, it is sufﬁcient to focus
on each single arm [5].
1) Single-Armed Bandit with Subsidy: Consider the
single-armed bandit for the intrusion detection problem
with only one arm/component. At each time instant, we
decide whether to activate the arm or make it passive.
(0, 1),
if an = 1, Sn = 0
(1, 1),
if an = 1, Sn = 1 , Assume that a subsidy, denoted by λ, is gained whenΓ(in , tn |an , Sn ) =
ever the arm is made passive. We have the following
(in , tn + 1),
if an = 0
optimality equations. For simplicity of the presentation,
where Γ(·) denotes the one-step transition of the arm we drop the component index from the notations.
state given the current arm state and action.
g + f (0, t) = max{λ − p(t)c + f (0, t + 1),
Proof: See [28].
−p(t)c + p(t)f (1, 1) + (1 − p(t))f (0, 1)}
Now we complete the RMAB formulation of the intru= max{λ + f (0, t + 1),
(2)
sion detection problem by observing that the immediate
p(t)f (1, 1) + (1 − p(t))f (0, 1)},
reward Rn (Sn ) offered by component n can be modeled g + f (1, t) = max{λ + f (1, t + 1),
(3)
by −cn if it is currently in the abnormal state and
p(t − 1)f (1, 1) + (1 − p(t − 1))f (0, 1)},
0 otherwise. Consequently, the reward maximization is
equivalent to the cost minimization. The objective is to where g and f (·) denote, respectively, the maximum
maximize the expected average reward over an inﬁnite steady-state average reward and the transient reward. For
horizon:
a given subsidy for passivity λ, the optimal policy for this
single-arm problem is essentially given by an optimal
T
N
1
partition of the arm state space i=0,1 {(i, t)}t≥1 into
max Eπ lim
Rn (Sn )
,
π
T →∞ T
a passive set
t=1 n=1
P(λ)

where π denotes a sequential probing policy and Eπ the
expectation under π. In the rest of the paper, we use
RMAB-IDS to denote this class of RMAB.

≥ p(t − i)f (1, 1) + (1 − p(t − i))f (0, 1)}
and its complement, an active set A(λ) = {(i, t) :
a∗ (i, t, λ) = 1}, where a∗ (i, t, λ) denotes the optimal
action at arm state (i, t) under subsidy λ.
2) Indexability and Whittle Index: To deﬁne Whittle
index policy, it is required that the RMAB is indexable [5].
Deﬁnition 1: An RMAB is indexable if for each arm,
the passive set P(λ) increases monotonically from the
empty set φ to the entire state space i=1,2 {(i, t)}t≥1 as
the subsidy λ increases from −∞ to +∞. An RMAB is
strictly indexable if the states join the passive set one by
one (instead of as groups) as λ continuously increases.

B. The Optimality Equation
We now establish the optimality equation for RMABIDS. We consider the following strong average-reward
criterion under which not only the steady-state average
reward but also the transient reward starting from an
arbitrary initial arm state is maximized, leading to the
maximum reward growth rate.
N

G + F ({(in , tn )}N ) = max EA [
n=1
A

Rn (Sn )

= {(i, t) : a∗ (i, t, λ) = 0}
= {(i, t) : λ + f (i, t + 1)

(1)

n=1

+ F ({Γ(in , tn |an , Sn )}N )],
n=1

3

4

Given the indexability, the Whittle index W (i, t) of
an arm state (i, t) is deﬁned as the inﬁmum subsidy λ
that makes the passive action optimal at (i, t):
W (i, t) =
=

In general, the myopic policy chooses the K components
to solely minimize the expected cost in the next slot. It is
not difﬁcult to show that for homogeneous networks, the
myopic policy is reduced to choosing the K components
with the largest probabilities of being in the abnormal
ˆ
state. The myopic action A(·) as a function of the current
states of all arms is thus given below.

inf{λ : a∗ (i, t, λ) = 0}
inf{λ : λ + f (i, t + 1)

≥ p(t − i)f (1, 1) + (1 − p(t − i))f (0, 1)}. ˆ
A({in , tn }N )
n=1
Whittle index is intuitive: how rewarding it is to
activate the arm under a particular state is measured by
the minimum subsidy λ needed to make it optimal to
not activate the arm at this state.
Whittle index policy is naturally given by playing the
K arms with the largest Whittle indexes.

=

W (1, t) =

p(t + 1)(t + p(t))
−
1 + p(t + 1) − p(t)

p(k))c, (4)

W (0, t − 1), W (0, 0) = 0.

arg max{
A

Pr(Sn = 1|(in , tn ))}

n:an =1

(p(tn )(1 − in )

n:an =1

(6)

VI. N UMERICAL E XAMPLES
We have shown that Whittle index policy is optimal in
homogeneous networks. In this section, we demonstrate
the near-optimal performance of Whittle index policy in
heterogeneous networks.
In Fig. 1, we compare the performance of Whittle
index policy with the optimal policy. As mentioned
in Sec. I, the structure of the optimal policy for a
general RMAB is unknown. The only approach is to
numerically compute the optimal policy through the
standard dynamic programming procedure. Due to the
curse of dimensionality of dynamic programming, we
can only simulate the performance of the optimal policy
over a short time horizon. As shown in Fig. 1, we
observe that Whittle index policy achieves a near-optimal
performance.
In Fig. 2, we compare Whittle index policy with the
myopic policy. While Whittle index policy is equivalent
to the myopic policy in homogeneous networks, it outperforms the myopic policy in heterogeneous networks
as demonstrated in Fig. 2.

t

k=1
∆

A

Lemma 2: For homogeneous networks, Whittle index
policy is equivalent to the myopic policy and has the
following simple structure: initialize a queue in which
components are ordered according to the descending order of their initial probabilities of being in the abnormal
state. Each time we probe the K components at the head
of the queue. In the next slot, these K components will
be moved to the bottom of the queue while keeping those
observed in state 1 a higher position than those observed
in state 0.
Proof: See [28].
From Lemma 2, Whittle index policy can be implemented without knowing the system parameters
{p(t)}t≥0 and c. Furthermore, Whittle index policy is
optimal, as given in the following theorem.
Theorem 3: For homogeneous networks, Whittle index policy minimizes the expected total cost over a ﬁnite
time horizon of an arbitrary length T (T ≥ 1). It is thus
also optimal under the strong average-reward criterion
over the inﬁnite time horizon.
Proof: See [28].

In this section, we establish the indexability of
RMAB-IDS and solve for Whittle index in closed-form.
Theorem 1: RMAB-IDS is indexable.
Proof: See [28].
Given the indexability established in Theorem 1, we
proceed to solve for the closed-form Whittle index of
RMAB-IDS. For simplicity of the presentation, we focus
on the case that the bandit is strictly indexable (see
Deﬁnition 1), i.e., there is no tie among the Whittle
indexes. A simple condition in the following is adopted
to guarantee the strict indexability.
C1: p(t + 1) − p(t) is strictly decreasing with t.
Note that C1 is always satisﬁed under the Markovian
state model (see Sec. II). As shown in the following
theorem, under C1, RMAB-IDS is strictly indexable.
The closed-form Whittle index function is subsequently
obtained.
Theorem 2: Under C1, RMAB-IDS is strictly indexable and the Whittle index W (·) is given below.
(

arg max{

+p(tn − 1)in )}.

IV. I NDEXABILITY AND C LOSED -F ORM W HITTLE
I NDEX

W (0, t) =

=

(5)

Proof: See [28].
The near-optimal performance of Whittle index policy
is observed through numerical examples (see Sec. VI).
In Sec. V, we show that when all components are
homogeneous, Whittle index policy is equivalent to the
myopic policy and achieves the optimal performance.
V. O PTIMALITY IN H OMOGENEOUS N ETWORKS
In this section, we study the performance of Whittle
index policy in homogeneous networks, i.e., all components have the same parameters: the probability sequence
{p(t)}t≥0 and the per-unit cost c for being abnormal.
We ﬁrst establish the equivalence of Whittle index policy with the myopic policy for homogeneous networks.

4

5

R EFERENCES

1.4

[1] S. Jajodia, P. Liu, V. Swarup, and C. Wang, Cyber Situational Awareness,
Springer, 2009.
[2] H. Debar, M. Dacier, and A. Wespi, “Towards A Taxonomy of IntrusionDetection Systems,” Computer Networks, vol. 31, no. 8, pp. 805-822, 2005.
[3] M. Kodialam and T. V. Lakshman, “Detecting Network Intrusions via
Sampling,” Proc. of INFOCOM, 2003.
[4] J. C. Wierman and D. J. Marchette, “Modeling Computer Virus Prevalence
with a Susceptible-Infected-Susceptible Model with Reintroduction,” Computational Statistics and Data Analysis, no. 1, vol. 45, pp. 3-23, 2004.
[5] P. Whittle, “Restless Bandits: Activity Allocation in a Changing World,” J.
Appl. Probab., vol. 25, pp. 287-298, 1988.
[6] J. C. Gittins, “Bandit Processes and Dynamic Allocation Indices,” Journal
of the Royal Statistical Society, vol. 41, no. 2, pp. 148-177, 1979.
[7] C. H. Papadimitriou and J. N. Tsitsiklis, “The Complexity of Optimal
Queueing Network Control,” Math. Oper. Res., vol. 24, no. 2, pp. 293-305,
May 1999.
[8] R. R. Weber and G. Weiss, “On an Index Policy for Restless Bandits,” J.
Appl. Probab., vol.27, no.3, pp. 637-648, September, 1990.
[9] R. R. Weber and G. Weiss, “Addendum to ’On an Index Policy for Restless
Bandits,” Adv. Appl. Prob., vol. 23, no. 2, pp. 429-430, Jun., 1991.
[10] W. Lee and S. J. Stolfo, “Data Mining Approaches for Intrusion Detection,”
Proceedings of the 7th conference on USENIX Security Symposium, 1998.
[11] D.E. Denning, “An Intrusion-Detection Model,” IEEE Transactions on
Software Engineering, no. 2, vol. SE-13, pp. 222-232, 1987.
[12] M. Roesch, “Snort-Light Weight Intrusion Detection for Networks,” Proceedings of the 13th Large Installation System Administration Conference,
1999.
[13] A. K. Ghosh, A. Schwartzbard, and M. Schats, “Learning program behavior
proﬁles for intrusion detection,” Proceedings of the 1st conference on
Workshop on Intrusion Detection and Network Monitoring, 1999.
[14] J. E. Ni˜ o-Mora, “Restless Bandits, Partial Conservation Laws and Indexn
ability,” Adv. Appl. Prob., vol. 33, pp. 76-98, 2001.
[15] K. D. Glazebrook and H. M. Mitchell, “An Index Policy for a Stochastic
Scheduling Model with Improving/Deteriorating Jobs,” Naval Research
Logistics (NRL), vol. 49, pp. 706-721, March, 2002.
[16] P. S. Ansell, K. D. Glazebrook, J.E. Ni˜ o-Mora, and M. O’Keeffe,
n
“Whittle’s Index Policy for a Multi-Class Queueing System with Convex
Holding Costs,” Math. Meth. Operat. Res., vol. 57, pp. 21-39, 2003.
[17] K. D. Glazebrook, D. Ruiz-Hernandez, and C. Kirkbride, “Some Indexable
Families of Restless Bandit Problems,” Advances in Applied Probability,
vol. 38, pp. 643-672, 2006.
[18] N. Ehsan, M. Liu, “On the Optimality of An Index Policy for Bandwidth
Allocation with Delayed State Observation and Differentiated Services,” in
Proc. of INFOCOM, 2004.
[19] V. Raghunathan, V. Borkar, M. Cao and P. R. Kumar, “Index Policies for
Real-Time Multicast Scheduling for Wireless Broadcast Systems,” in Proc.
of INFOCOM, April, 2008.
[20] K. Liu and Q. Zhao “A Restless Bandit Formulation of Opportunistic
Access: Indexablity and Index Policy,” in Proc. of the 5th IEEE Conference
on Sensor, Mesh and Ad Hoc Communications and Networks (SECON)
Workshops, June, 2008.
[21] K. Liu and Q. Zhao, “Indexability of Restless Bandit Problems and
Optimality of Whittle Index for Dynamic Multichannel Access,” IEEE
Trans. Inf. Theory, vol. 56, no. 11, pp. 5547-5567, November, 2010.
[22] J. Le Ny, M. Dahleh, and E. Feron, “Multi-UAV Dynamic Routing
with Partial Observations using Restless Bandit Allocation Indices,” in
Proceedings of the 2008 American Control Conference, June, 2008.
[23] T. He, A. Anandkumar, and D. Agrawal, “Index-Based Sampling Policies
for Tracking Dynamic Networks under Sampling Constraints,” IEEE INFOCOM, April, 2011.
[24] K. Liu, R. Weber, and Q. Zhao, “Indexability and Whittle Index for Restless
Bandit Problems Involving Reset Processes,” in Proc. of the 50th IEEE
Conference on Decision and Control (CDC), December, 2011.
[25] Q. Zhao, B. Krishnamachari, and K. Liu, “On Myopic Sensing for MultiChannel Opportunistic Access: Structure, Optimality, and Performance,”
IEEE Transactions on Wireless Communications, vol. 7, no. 12, pp. 54315440, December 2008.
[26] S. H. Ahmad, M. Liu, T. Javadi, Q. Zhao, and B. Krishnamachari,
“Optimality of Myopic Sensing in Multi-Channel Opportunistic Access,”
IEEE Transactions on Information Theory, vol. 55, No. 9, pp. 4040-4050,
September, 2009.
[27] S. Ahmad and M. Liu, “Multi-channel Opportunistic Access: A Case of
Restless Bandits with Multiple Plays,” in Proc. of Allerton Conference on
Communication, Control, and Computing, October, 2009.
[28] K. Liu and Q. Zhao, “Intrusion Detection in Resource-Constrained
Cyber Networks: A Restless Multi-Armed Bandit Approach,”
submitted to IEEE/ACM Transactions on Networking. Avialable at
http://arxiv.org/abs/1112.0101.

Time−Averaged Cost

1.2
1
0.8

The Optimal Policy
Whittle Index Policy

0.6
0.4
0.2
0

1

2

3

4

5

6

Time

Fig. 1.
The near-optimality of Whittle index policy
(K
=
1, N
=
4, {pn (t)}n=1,2,··· ,4,0≤t≤6
=
[0, .5, .7, .85, .95, .97, .975; 0, .3, .4, .48, .54, .57, .59;
0, .36, .46, .5, .53, .55, .56; 0, .6, .78, .9, .96, .98, .99],
{cn }n=1,2,··· ,4 = [.8, 1, 1.2, .9], all components start from
the healthy state).

Time−Averaged Cost

6
5
4
Myopic Policy
Whittle Index Policy

3
2
1
0

10

20

30

40

50
60
Time

70

80

90

100

Fig. 2.
The performance of Whittle index policy versus the
myopic policy (K = 2, N = 8, Markovian state model,
{qn }n=1,2,··· ,8 = [.2, .3, .3, .5, .6, .7, .7, .8], {cn }n=1,2,··· ,8 =
[2.5, 2, 1.8, 1.5, 1.2, 1, .6, .5], all components start from the healthy
state).

VII. C ONCLUSION
In this paper, we studied the intrusion detection
problem in large cyber networks under arbitrary attack
processes. By adopting a general non-Markovian model
of the network dynamics, we formulated the problem as
a special class of RMAB. We showed that this class of
RMAB is indexable and Whittle index can be solved
in closed-form. This result leads to a low-complexity
implementation of Whittle index policy that achieves a
near-optimal performance. We further showed that for
homogeneous networks, Whittle index policy can be
implemented without knowing the system parameters
and is optimal over both ﬁnite and inﬁnite time horizons.

5

