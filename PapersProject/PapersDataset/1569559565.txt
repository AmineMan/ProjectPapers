Creator:        TeX
Producer:       Appligent StampPDF Batch, version 5.1
CreationDate:   Fri May 18 23:27:14 2012
ModDate:        Tue Jun 19 12:54:13 2012
Tagged:         no
Pages:          5
Encrypted:      no
Page size:      612 x 792 pts (letter)
File size:      346089 bytes
Optimized:      no
PDF version:    1.6
ISIT'2012 1569559565

Sphere Packing Bound for Quantum Channels
Marco Dalai
Department of Information Engineering
University of Brescia, Italy
Email: marco.dalai@ing.unibs.it

non-disjoint supports, for otherwise the problem is trivial. The
decision has to be taken based on the result of a measurement
that can be identiﬁed with a pair of positive operators {1 −
Π, Π}, where 0 < Π < 1, associated respectively to and ς.
The probability of error given that the system is in state or
ς is respectively

Abstract—In this paper, the Sphere-Packing-Bound of Fano,
Shannon, Gallager and Berlekamp is extended to general
classical-quantum channels. The obtained upper bound for the
reliability function, for the case of pure-state channels, coincides
at high rates with a lower bound derived by Burnashev and
Holevo [1]. Thus, for pure state channels, the reliability function
at high rates is now exactly determined. For the general case, the
obtained upper bound expression at high rates was conjectured
to represent also a lower bound to the reliability function, but a
complete proof has not been obtained yet.

Pe| = Tr Π

and

Pe|ς = Tr(1 − Π)ς.

(1)

Remark 1: This choice of notation is motivated by the fact
that our states and ς do not play the role of the states that are
usually indicated with ρ and σ in the literature. For example,
when comparing Theorem 1 below with the results in [6],
we should interpret our quantities with the correspondences
= ρ⊗N and ς = σ ⊗N in mind. Here, however, we will
apply the theorem to more general cases where and ς are
tensor products of N not necessarily identical states and, in
this sense, Theorem 1 is more general than the results in [6].
Following [7, Sec. 3], for any real s in the interval 0 < s <
1, deﬁne the quantity

I. I NTRODUCTION
This paper considers the problem of classical communication over quantum channels, focusing on the study of
error exponents for optimal codes at rates below the channel
capacity. Upper bounds to the probability of error of optimal
codes for pure-state channels were obtained by Burnashev and
Holevo [1] that are the equivalent of the so-called random
coding bound obtained by Fano [2] and Gallager [3] and of
the expurgated bound of Gallager [3] for classical channels.
The expurgated bound was then extended to general quantum
channels by Holevo [4]. The formal extension of the random
coding bound expression to mixed states is conjectured to
represent an upper bound for the general case but no proof
has been obtained yet (see [1], [4]).
In this paper, a sphere packing bound for classical-quantum
channels is derived. The quantum case is related to the
classical one by means of the Nussbaum-Szkoła mapping,
introduced in [5] and central to the proof of the converse part
of the quantum Chernoff bound (see [6] for more details). This
allows us to extend to the quantum case the Shannon-GallagerBerlekamp generalization of the Chernoff bound introduced
in [7] (in its converse part). Then, the proof of the sphere
packing bound used in [7] is adapted to the quantum case. This
demonstrates the power of the method developed in [7]. Due to
space limitation, this paper only includes the main derivation
of the results; technical details and additional comments can
be found in an extended version of this paper [8].

µ(s) = log Tr

1−s s

ς

(2)

and let then by deﬁnition
µ(0) = lim µ(s) and µ(1) = lim µ(s).
s→0

s→1

(3)

Theorem 1 (Quantum Shannon-Gallager-Berlekamp Bound):
Let , ς be density operators with non-disjoint supports, let
Π be a measurement operator for the binary hypothesis test
between and ς, let the probabilities of error Pe| , Pe|ς be
deﬁned as in (1) and µ(s) be deﬁned as in (2)-(3). Then, for
any 0 < s < 1, either
1
Pe| > exp µ(s) − sµ (s) − s 2µ (s)
(4)
8
or
1
Pe|ς > exp µ(s) + (1 − s)µ (s) − (1 − s) 2µ (s) .
8
(5)
Proof: This theorem is essentially the combination of the
main idea introduced in [5] for proving the converse part of
the quantum Chernoff bound and of [7, Th. 5], the classical
version of this same theorem. Since some intermediate steps
of those proofs are needed, we unroll the details here for the
reader’s convenience.
We proceed as in [6]. Let the spectral decomposition of
and ς be respectively

II. B INARY H YPOTHESIS T ESTING
In this section, the converse part of the Shannon-GallagerBerlekamp bound for classical binary hypothesis testing [7,
Th. 5] is extended to the case of quantum state discrimination.
This result will then be used in the next section to derive the
sphere packing bound.
Let and ς be two density operators in a Hilbert space H
and consider the problem of binary hypothesis testing between
and ς. We suppose here that the two density operators have

αi |xi xi | and ς =

=
i

1

βj |yj yj |.
j

(6)

where {|xi } and {|yj } are orthonormal bases. First observe
that, from the Quantum Neyman-Pearson Lemma ([9], [10]),
it sufﬁces to consider orthogonal projectors Π. So, one has
Π = Π2 = Π1Π = j Π|yj yj |Π. Symmetrically, we have
that (1 − Π) = i (1 − Π)|xi xi |(1 − Π). Hence, one has
Pe|

=

Tr Π

−1

−(1 − s) 2µ (s)]

αi | xi |Π|yj |

(8)

1
2

i,j

Pe|ς

Tr(1 − Π)ς

=

βj | xi |1 − Π|yj |2

=

. (20)

Hence, in Ys , Qs (i, j) is bounded by the minimum of the two
expressions on the right hand side of (19) and (20). If we call
η1 the coefﬁcient of P1 (i, j) in (19) and η2 the coefﬁcient of
P2 (i, j) in (20), then we obtain

(7)
2

=

Qs (i, j) ≤ P2 (i, j) exp[µ(s) + (1 − s)µ (s)

(9)
(10)

<

Qs (i, j)
min (η1 P1 (i, j), η2 P2 (i, j))

≤

i,j

(21)
(22)

(i,j)∈Ys

(i,j)∈Ys

Using the fact that |a|2 + |b|2 ≥ |a + b|2 /2 for any two
complex numbers a, b, we ﬁnd that for all (i, j)

≤

min (η1 P1 (i, j), η2 P2 (i, j)) .

(23)

(i,j)

η1 αi | xi |Π|yj |2 + η2 βj | xi |1 − Π|yj |2 ≥
| xi |yj |2
min(η1 αi , η2 βj )
, (11)
2
which implies that

Now note that the last expression, by the deﬁnition of P1
and P2 in (13), exactly equals the sum in (12). So, with the
selected values of η1 and η2 we have η1 Pe| + η2 Pe|ς > 1/4.
But, obviously, η1 Pe| + η2 Pe|ς ≤ 2 max{η1 Pe| , η2 Pe|ς }.
−1
−1
Hence, either Pe| > η1 /8 or Pe|ς > η2 /8, concluding
the proof.

η1 Pe| + η2 Pe|ς ≥
1
min η1 αi | xi |yj |2 , η2 βj | xi |yj |2 . (12)
2 i,j

III. S PHERE PACKING B OUND

where the subscript Qs means that the expected values are
with respect to the probability distribution Qs . Hence, if one
deﬁnes the set
P2 (i, j)
Ys = (i, j) : log
− µ (s) ≤ 2µ (s) (18)
P1 (i, j)

Following [4], consider a classical-quantum channel with
an input alphabet of K symbols {1, . . . , K} with associated
density operators Sk , k = 1, . . . , K in a ﬁnite dimensional
Hilbert space H. The N -fold product channel acts in the
tensor product space H⊗N of N copies of H. To a codeword w = (k1 , k2 , . . . , kN ) is associated the signal state
Sw = Sk1 ⊗ Sk2 · · · ⊗ SkN . A block code with M codewords
is a mapping from a set of M messages {1, . . . , M } into
a set of M codewords w1 , . . . , wM . A quantum decision
scheme for such a code is a collection of M positive operators
{Π1 , Π2 , . . . , ΠM } such that
Πi ≤ 1. The rate of the code
is deﬁned as R = (log M )/N .
The probability that message m is decoded when message
m is transmitted is P (m |m) = Tr Πm Swm and the total
probability of error after sending message m is Pe,m =
1 − Tr (Πm Swm ). We then deﬁne the maximum probability of
error of the code Pe,max = maxm Pe,m and, for any positive
(N )
R and integer N , we deﬁne Pe,max (R) as the minimum
maximum error probability over all codes of block length N
and rate at least R.
For rates R smaller than the capacity of the channel,
(N )
Pe,max (R) goes to zero exponentially fast in N . The reliability
function of the channel is deﬁned as1
1
(N )
(24)
E(R) = lim sup − log Pe,max (R).
N
N →∞

then
Ys Qs (i, j) > 1/2, by Chebyshev’s inequality. It is
easily checked, using the deﬁnitions (15) and (18), that for
each (i, j) ∈ Ys the distribution Qs satisﬁes

The purpose of this section is to adapt the proof of the
sphere packing bound in [7, Sec. IV] to the case of quantum
channels. This results in the following theorem.

Now, following [5], consider two probability distributions
deﬁned by the Nussbaum-Szkoła mapping
P1 (i, j) = αi | xi |yj |2 ,

P2 (i, j) = βj | xi |yj |2 .

(13)

These two probability distributions are both strictly positive
for at least one pair of (i, j) values, since we assumed , ς
to have non-disjoint supports. Furthermore, they have the nice
property of allowing for µ(s), as deﬁned in (2), the expression
P1 (i, j)1−s P2 (i, j)s .

µ(s) = log

(14)

i,j

Following [7, Th. 5], deﬁne the distribution Qs by
Qs (i, j) =

P1 (i, j)1−s P2 (i, j)s
1−s P (i , j )s
2
i ,j P1 (i , j )

(15)

and observe that
µ (s)

=

EQs [log(P2 /P1 )]

(16)

µ (s)

=

VarQs [log(P2 /P1 )] ,

(17)

−1

1 It is known that the same function E(R) results if in (24) one substitutes Pe,max with the average probability of error over codewords Pe =
P
/M , see for example [7], [3].
m e,m

Qs (i, j) ≤ P1 (i, j) exp [µ(s) − sµ (s) − s 2µ (s)]
(19)

2

Applying Theorem 1 with = Swm , ς = f and Π = 1 − Πm ,
we ﬁnd that for each s in 0 < s < 1, either
1
Tr [(1 − Πm ) Swm ] > exp µ(s) − sµ (s) − s 2µ (s)
8
(30)
or
1
Tr [Πm f ] > exp µ(s) + (1 − s)µ (s) − (1 − s) 2µ (s) .
8
(31)
Note now that Tr [(1 − Πm ) Swm ] = Pe,m ≤ Pe,max for all
M
m. Furthermore, since m=1 Πm ≤ 1, for at least one value
of m we have Tr [Πm f ] ≤ 1/M = e−N R . Choosing this
particular m, we thus obtain from the above two equations
that either
1
(32)
Pe,max > exp µ(s) − sµ (s) − s 2µ (s)
8
or
1
µ(s) + (1 − s)µ (s) − (1 − s) 2µ (s) − log 8
R<−
N
(33)

Theorem 2 (Sphere Packing Bound): For all positive rates
R and all positive ε,
E(R) ≤ Esp (R − ε),

(25)

where Esp (R) is deﬁned by the relations
Esp (R)

=

sup [E0 (ρ) − ρR]

(26)

ρ≥0

E0 (ρ)

=

max E0 (ρ, q)

(27)

q

1+ρ

K

E0 (ρ, q)

1/(1+ρ)
qk Sk

= − log Tr

(28)

k=1

Remark 2: For some channels, the function Esp (R) can be
inﬁnite for R small enough. The role of the arbitrarily small
constant ε is only important for one single value of the rate
R = R∞ , which is the inﬁmum of the rates R such that
Esp (R) is ﬁnite.
Proof: We follow closely the proof given in [7, Sec. IV]
for the classical case. Some steps are clearly to be adapted to
the quantum case and, since that proof is quite complicated, it
would not be easy to explain how to do that without at least
repeating the main steps of the proof. Hence, for the reader’s
convenience, we prefer to go through the whole proof used in
[7] directly speaking in terms quantum channels and trying to
simplify it as much as possible in view of the weaker results
that we are pursuing with respect to [7, Th. 5] (we are here
only interested in the asymptotic ﬁrst order exponent, while
in [7], bounds for ﬁxed M and N are obtained).
The key point is using Fano’s idea [2, Sec. 9.2] of bounding
the probability of error for at least one codeword wm by
studying a binary hypothesis testing problem between Swm
and a dummy state f , which is only used as a measure for the
decision operator Πm .
Here, we simplify the problem using the fact that for the
study of E(R) we can only consider the case of constant
composition codes (see [2] [7]). This observation clearly holds
also for classical-quantum channels, since it stems from the
fact that the number of different compositions only grows
polynomially in N , while the number of codewords grows
exponentially. Hence, let ck be the number of occurrences of
symbol k in each word and deﬁne then qk as the ratio ck /N , so
that the vector q = (q1 , q2 , . . . , qK ) is obviously a probability
distribution over the K input symbols.
Let now f be a state in H⊗N . We will ﬁrst apply Theorem
1 using one of the codewords as state and f as state ς. This
will result in a trade-off between the rate of the code R and
the probability of error Pe,max , where both quantities will be
parameterized in the parameter s, a higher rate being allowed
if a larger Pe,max is tolerated and vice-versa. This trade-off
depends of course on q and f . We will later pick f properly
so as to obtain the best possible bound for a given R valid for
all compositions q.
For any m = 1 . . . , M , consider the binary hypothesis
testing between Swm and f . We assume that Swm and f have
non-disjoint supports and deﬁne the quantity
µ(s) = log Tr S1−s f s .
wm

In these equations we begin to see the aimed trade-off
between the rate and the probability of error. It is implicit
here in the deﬁnition of µ(s) that both equations depend on
Swm and f . Since m has been ﬁxed, we can drop its explicit
indication and use simply w in place of wm from this point
on. We will now call R(s, Sw , f ) the right hand side of (33).
This allows us to write µ (s) in (32) in terms of R(s, Sw , f )
so that, taking the logarithm in equation (32), our conditions
can be rewritten as either
R < R(s, Sw , f )
(34)
or
1
µ(s)
sN
log
<−
−
R(s, Sw , f )
Pe,max
1−s 1−s
log 8
+ 2s 2µ (s) +
. (35)
1−s
At this point, we exploit the fact that we are considering a
ﬁxed composition code. Since we want our result to depend
only on the composition q and not on the particular sequence
w, we choose f so that the function µ(s) also only depends on
the composition q. We thus choose f to be the N -fold tensor
power of a state f in H, that is f = f ⊗N . With this choice,
in fact, we easily check that, if w has composition q,
µ(s)

=

log Tr S1−s f s
w

(36)

K
1−s
qk log Tr Sk f s .

= N

(37)

k=1

Thus, µ(s) actually only depends on the composition q and
on f , and not on the particular w. It is useful to remember
that since we assumed the supports of f and Sw to be nondisjoint, the supports of Sk and f are not disjoint if qk > 0,
so that all terms in the sum are well deﬁned. Setting
1−s
µk,f (s) := log Tr Sk f s

(38)

we thus have
µ(s) = N

(29)

qk µk,f (s)
k

3

(39)

and hence, obviously,
µ (s) = N

qk µk,f (s).

(in that notation) is deﬁned, which is not supposed to depend
on k. Fortunately, it is instead possible to exactly replicate the
steps used in [7] by correctly reinterpreting the construction
of f and q in the quantum setting.
For a ﬁxed s in the interval 0 < s < 1, consider the quantity

(40)

With the same procedure used to obtain (17) using the
Nussbaum-Szkoła mapping (13), we see that for ﬁxed s and
f , µk,f (s) is a variance of a ﬁnite random variable and it is
thus a ﬁnite non-negative real number. Taking the largest of
these numbers over k, say C(s, f ), we ﬁnd that
µ (s) ≤ N C(s, f ).

E0

(41)

qk µk,f (s) −
k

= − log Tr

(44)

k

1−s s/(1−s)
1/(1−s)
;
Tr Sk αs
≥ Tr αs

k = 1, . . . , K
(45)

where
K
1−s
qk,s Sk .

αs =

(46)

k=1

Furthermore, equation (45) is satisﬁed with equality for those
k with qk,s > 0, as can be veriﬁed by multiplying it by qk,s
and summing over k.
Deﬁne now
1/(1−s)
αs
.
(47)
fs =
1/(1−s)
Tr αs
Since we can choose s and f freely, we will now tie the
operator f to the choice of s, using fs for f . We only have to
keep in mind that µ (s) and µ (s) are computed by holding f
ﬁxed. Note further that we fullﬁll the requirement that f and
Sk have non-disjoint supports, since the left hand side in (45)
must be positive for all k.
As in [7, eqs (4.21)-(4.22)], we see that, using fs in place
of f in the deﬁnition of µk,f (s), we get

(42)

or
1
1
1
log
<−
N
Pe,max
1−s

1/(1−s)
1−s
qk Sk

and call qs = (q1,s , . . . , qK,s ) the choice of q that maximizes
this expression. As observed by Holevo2 [4, eq. (38)], qs
satisﬁes the conditions

We also observe that since µk,f (s) ≥ 0 for all k, µk,f (s) is
convex in s for all choices of f , a fact that will be useful later.
The essential point here is that the contribution of µ(s)
and µ (s) in our bounds will grow linearly √ N , while the
in
contribution of µ (s) will only grow with N . Hence, the
terms involving µ (s) become unimportant for large N . A
formalization of this fact, however, is tricky. In [7] the effect of
µ (s) in the classical case is dealt with by bounding s2 µk,f (s)
by a constant uniformly over s and f , which allows the authors
to proceed in deriving a bound on Pe,max for all ﬁxed M and
N.
In our case, this procedure cannot be applied in a simple
way (see [8] for details on the reasons) and we have to take
at this point a slightly different approach, which will allow us
to ﬁnd a bound on E(R) using the asymptotic regime N →
∞. Simplifying again the notation in light of the previous
observations, let us write R(s, q, f ) for R(s, Sw , f ). Using
the obtained expression for µ(s), our conditions are either
R < R(s, q, f )

s
,q
1−s

s
R(s, q, f )
1−s

1
log 8
+
2s 2µ (s) +
. (43)
N
1−s
Now we come to the most critical step. Given a rate R,
we want to bound Pe,max for all codes. Here, we should
choose s and f optimally depending on q and R, but we
should then optimize the composition q in order to have a
bound valid for all codes. This direct approach, even in the
classical case, turns out to be very complicated (see [2, Sec. 9.3
and 9.4, pag. 188-303] for a detailed and however instructive
analysis). The authors in [7] thus proceed in a more synthetic
way by stating the resulting optimal f and q as a function
of s and then proving that this choice leads to the desired
bound. Here, we will follow this approach showing that the
same reasoning can be applied also to the case of quantum
channels. It is important to point out that it is not possible to
simply convert the quantum problem to the classical one using
the Nussbaum-Szkoła mapping (13) directly on the states Sk
and f and then using the construction of [7, eqs. (4.18)-(4.20)]
on the obtained classical distributions. In fact, in (13), even
if one of the two states is kept ﬁxed and only the other one
varies, both distributions vary. Thus, even if f is kept ﬁxed,
the effect of varying Sk for the different values of k would not
be compatible with the fact that in [7, eq. (4.20)] a ﬁxed fs

1−s s/(1−s)
1/(1−s)
µk,fs (s) = log Tr Sk αs
− s log Tr αs
. (48)

Using (45) we then see that
1/(1−s)
µk,fs (s) ≥ (1 − s) log Tr αs
(49)
s
= −(1 − s)E0
, qs
(50)
1−s
s
(51)
= −(1 − s)E0
1−s
with equality if qk,s > 0. Here, we have used the deﬁnitions
(46), (28) and (27), and the the fact that qs maximizes (44).
Thus, with the choice of f = fs , equations (42) and (43) can
be rewritten as (for each s) either

R < R(s, q, fs )

(52)

or
1
1
s
s
log
< E0
−
R(s, q, fs )
N
Pe,max
1−s
1−s
√
log 8
2s 2
+ √
qk µk,fs (s) +
(1 − s)N
N
k

(53)

2 The variable s in [4] corresponds to our s/(1 − s), that we call ρ here in
accordance with the consolidated classical notation.

4

s ∈ [ε1 , 1) we must have R(s, qn , fs ) ≤ Rn inﬁnitely often.
Since condition (52) is not satisﬁed, (53) must be satisﬁed
inﬁnitely often for any ﬁxed s ∈ [ε1 , 1). Making n → ∞ we
can get rid again of the last two terms in (53) and have
s
s
¯
E(R) ≤ E0
−
R(s, q, f )
(59)
1−s
1−s
Letting then ε1 → 0, we can let s → 0 as well and ﬁnd that
E(R) ≤ 0. Thus, surely E(R) ≤ Esp (R) proving the theorem
in this case (see [8] for more details here).
Suppose ﬁnally that either case (3) above is veriﬁed inﬁnitely often, or that case (1) is with the only accumulating
point s = 1 for the values sn . Given any ε1 > 0, for all
¯
s ∈ (0, 1 − ε1 ], the inequality Rn < R(s, qn , fs ) is veriﬁed
inﬁnitely often, so that we can take this time the limit n → ∞
in (52) and (54). Proceeding exactly as in [7], we can then
use the convexity of µk,f (s) and (51) to prove that
s
1−s
E0
(60)
R≤
s
1−s
for all s ∈ (0, 1 − ε1 ]. Setting ρ = s/(1 − s) and ρ1 =
(1 − ε1 )/ε1 , this implies that for any ε2 > 0,

where
R(s, q, fs ) = −

qk µk,fs (s) − (1 − s)
k

qk µk,fs (s)
k

1
+ √ (1 − s) 2
N

qk µk,fs (s) +
k

1
log 8. (54)
N

Using the same procedure used in [7, pag. 100-102], invoking the strict convexity of Tr(α1/(1−s) ) in α for 0 < s < 1, it
can be proved that R(s, q, fs ) is a continuous function of s.
Thus, for ﬁxed R, we can only have three possibilities:
1) R = R(s, q, fs ) for some s in (0, 1);
2) R > R(s, q, fs ) ∀s ∈ (0, 1);
3) R < R(s, q, fs ) ∀s ∈ (0, 1).
Our conditions are slightly different from those in [7] due
to the fact that we have not been able to bound uniformly
the second derivatives µk,fs (s) for s ∈ (0, 1). For this same
reason, dealing with these possibilities for a ﬁxed code is
more complicated in our case than in [7]. Thus, we have to
depart slightly from [7]. Due to space limitation, we can give
here only a concise explanation that should be sufﬁcient when
integrated with [7], the interested reader can ﬁnd more precise
technical details in [8].
Instead of considering a ﬁxed code of block length N , consider sequences of codes. From the deﬁnition of E(R) in (24),
it is obvious that there exists a sequence of codes of blocklengths N1 , N2 , . . . , Nn , . . . , and rates R1 , R2 , . . . , Rn , . . .
such that R = limn Rn and
1
(Nn )
log Pe,max (R).
(55)
E(R) = lim −
n→∞
Nn
Each code of the sequence will in general have a different
composition qn but must anyway fall in one of the above
three cases. Thus, one of those cases is veriﬁed inﬁnitely often.
Since the compositions qn are in a bounded set, there exists a
¯
subsequence of codes such that qn converge to, say, q. Thus,
we can directly assume this subsequence is our own sequence
¯
and safely assume that qn → q.
Suppose now that case (1) is veriﬁed inﬁnitely often. Thus,
for inﬁnitely many n, there is an s = sn in the interval 0 < s <
1 such that Rn = R(s, qn , fsn ). Hence, since the values sn are
in the interval (0, 1), there must exists an accumulation point
for the sn in the closed interval [0, 1]. We will ﬁrst assume
that an accumulation point s exists satisfying 0 < s < 1. A
¯
¯
subsequence of codes then exists with the sn tending to s. Let
¯
this subsequence be our new sequence. We can ﬁrst substitute
R(sn , qn , fsn ) with Rn in (53). Letting then n → ∞, we ﬁnd
that Rn → R and the last two terms on the right hand side of
(53) vanish. Hence, we obtain
s
¯
s
¯
−
R
(56)
E(R) ≤ E0
1−s
¯
1−s
¯
≤ sup (E0 (ρ) − ρR)
(57)

Esp (R − ε2 )

Esp (R).

sup (E0 (ρ) − ρ (R − ε2 ))
ρ≥0

≥

sup

(E0 (ρ) − ρ (R − ε2 ))

0≤ρ≤(1−ε1 )/ε1

≥

sup

ρε2

0≤ρ≤(1−ε1 )/ε1

(1 − ε1 )ε2
.
ε1
which is arbitrarily large for any ε2 if ε1 is small enough. This
proves that Esp (R − ε2 ) is unbounded for arbitrarily small ε2
and thus surely E(R) ≤ Esp (R − ε2 ), concluding the proof.
=

R EFERENCES
[1] M. V. Burnashev and A. S. Holevo, “On reliability function of quantum
communication channel,” Probl. Peredachi Inform., vol. 34, no. 2, pp.
1–13, 1998.
[2] R. Fano, Transmission of Information: A Statistical Theory of Communication. Wiley, New York, 1961.
[3] R. G. Gallager, “A simple derivation of the coding theorem and some
applications,” IEEE Trans. Inform. Theory, vol. IT-11, no. 1, pp. 3–18,
January 1965.
[4] A. S. Holevo, “Reliability function of general classical-quantum channel,” IEEE Trans. Inform. Theory, vol. IT-46, no. 6, pp. 2256 –2261,
2000.
[5] M. Nussbaum and A. Szkoła, “The chernoff lower bound for symmetric
quantum hypothesis testing,” Ann. Statist., vol. 37, no. 2, pp. 1040–1057,
2009.
[6] K. M. R. Audenaert, M. Nussbaum, A. Szkoła, and F. Verstraete,
“Asymptotic error rates in quantum hypothesis testing,” Comm. in Math.
Phys., vol. 279, pp. 251–283, 2008.
[7] C. E. Shannon, R. G. Gallager, and E. R. Berlekamp, “Lower bounds
to error probability for coding in discrete memoryless channels. I,”
Information and Control, vol. 10, pp. 65–103, 1967.
[8] M. Dalai, “Sphere packing and zero-rate bounds to the reliability of
classical-quantum channels,” arXiv:1201.5411v1.
[9] C. W. Helstrom, Quantum detection and estimation theory. Academic
Press, New York, 1976.
[10] A. S. Holevo, “An analog of the theory of statistical decisions in
noncommutative theory of probability,,” Tr. Mosk. Matemat. Obshchest,
vol. 26, pp. 133–149, 1972.

ρ≥0

=

=

(58)

Suppose now that either case (2) above is veriﬁed inﬁnitely
often, or that case (1) is with the only accumulating point
s = 0 for the values sn . Given any ε1 > 0, for any ﬁxed
¯

5

