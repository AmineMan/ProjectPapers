Title:          Paper Title (use style: paper title)
Subject:        
Keywords:       
Author:         IEEE
Creator:        Acrobat PDFMaker 10.1 for Word
Producer:       Appligent StampPDF Batch, version 5.1
CreationDate:   Fri May 18 20:27:13 2012
ModDate:        Tue Jun 19 12:54:23 2012
Tagged:         yes
Pages:          5
Encrypted:      no
Page size:      595.44 x 841.68 pts
File size:      461894 bytes
Optimized:      no
PDF version:    1.6
ISIT'2012 1569565265

Three-Receiver Broadcast Channels with Side
Information
Saeed Hajizadeh
(Undergraduate Student)
Department of Electrical Engineering
Ferdowsi University of Mashhad
Mashhad, Iran
Saeed.hajizadeh1367@gmail.com

Ghosheh Abed Hodtani
Department of Electrical Engineering
Ferdowsi University of Mashhad
Mashhad, Iran
ghodtani@gmail.com

In this paper, we find the achievable rate region of
Multilevel BC and 3-receiver less noisy BC both with SI noncausally available at the encoder. Our achievable rate regions
reduce to that of [3] and [4] when there is no side information.
We also find the capacity region of the latter when side
information is also available at the receivers. The rest of the
paper is organized as follows. In section II, basic definitions
and notations are presented. In sections III and IV, new
achievable rate regions are given for the Multilevel BC and 3receiver less noisy BC, respectively. In section V, conclusion
is given.

Abstractâ€”Three-receiver broadcast channel (BC) is of
interest due to its information theoretical differences with two
receiver one. In this paper, we derive achievable rate regions for
two classes of 3-receiver BC with side information available at
the transmitter, Multilevel BC and 3-receiver less noisy BC, by
using superposition coding, Gelâ€™fand-Pinsker binning scheme
and Nair-El Gamal indirect decoding. Our rate region for
multilevel BC subsumes the Steinberg rate region for 2-receiver
degraded BC with side information as its special case. We also
find the capacity region of 3-receiver less noisy BC when side
information is available both at the transmitter and at the
receivers.
Keywords: 3-receiver broadcast channel, less noisy, Multilevel
broadcast channel

II.

The k-receiver, ğ‘˜ğ‘˜ â‰¥ 3, broadcast channel (BC) was first
studied by Borade et al. in [1] where they simply surmised
that straightforward extension of KÃ¶rner-Martonâ€™s capacity
region for two-receiver BCs with degraded message sets [2] to
k-receiver multilevel broadcast networks is optimal. Nair-El
Gamal [3] showed that the capacity region of a special class of
3-receiver BCs with two degraded message sets when one of
the receivers is a degraded version of the other, is a superset of
[1], thus proving that direct extension of [2] is not in general
optimal. Nair and Wang later in [4] established the capacity
region of the 3-receiver less noisy BC. Channels with Side
information (SI), were first studied by Shannon [5], where he
found the capacity region of the Single-Input-Single-Output
channel when SI is causally available at the encoder. Gelfâ€™and
and Pinsker [6] found the capacity region of a single-user
channel when SI is non-causally available at the transmitter
while the receiver is kept ignorant of it. Cover and Chiang [7]
extended the results of [6] to the case where SI is available at
both the encoder and the decoder. Multiple user channels with
side information were studied in [8] where inner and outer
bounds for degraded BC with non-causal SI and capacity
region of degraded BC with causal SI were found. Moreover,
in [9] inner and outer bounds were given to general two-user
BCs with SI available at the transmitter and other special cases
both for BCs and MACs were also found.
I.

DEFINITIONS

Random variables and their realizations are denoted by
uppercase and lowercase letters, respectively, e.g. x is a
realization of X. Let ğ’³ğ’³, ğ’´ğ’´1 , ğ’´ğ’´2 , ğ’´ğ’´3 , ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ ğ’®ğ’® be finite sets
showing alphabets of random variables. The n-sequence of a
random variable is given by ğ‘‹ğ‘‹ ğ‘›ğ‘› where the superscript is
omitted when the choice of n is clear, thus we only use
boldface letters for the random variable itself, i.e. ğ’™ğ’™ = ğ‘¥ğ‘¥ ğ‘›ğ‘› .
is
the
Throughout,
we
assume
that
ğ‘‹ğ‘‹ğ‘–ğ‘–ğ‘›ğ‘›
sequence (ğ‘‹ğ‘‹ğ‘–ğ‘– , ğ‘‹ğ‘‹ğ‘–ğ‘–+1 , â€¦ , ğ‘‹ğ‘‹ ğ‘›ğ‘› ).

INTRODUCTION

Definition 1: A channel ğ‘‹ğ‘‹ â†’ ğ‘ğ‘ is said to be a degraded
version of the channel ğ‘‹ğ‘‹ â†’ ğ‘Œğ‘Œ with SI if ğ‘‹ğ‘‹ â†’ ğ‘Œğ‘Œ â†’ ğ‘ğ‘ be a
Markov chain conditioned on every ğ‘ ğ‘  âˆˆ ğ’®ğ’® for all ğ‘ğ‘(ğ‘¢ğ‘¢, ğ‘¥ğ‘¥|ğ‘ ğ‘ ).
Multilevel BC with side information, denoted by
ï¿½ğ’³ğ’³, ğ’®ğ’®, ğ’´ğ’´1 , ğ’´ğ’´2 , ğ’´ğ’´3 , ğ‘ğ‘(ğ‘¦ğ‘¦1 , ğ‘¦ğ‘¦3 |ğ‘¥ğ‘¥, ğ‘ ğ‘ ), ğ‘ğ‘(ğ‘¦ğ‘¦2 |ğ‘¦ğ‘¦1 )ï¿½ , is a 3-receiver BC
with 2-degraded message sets with input alphabet ğ’³ğ’³ and
output alphabets ğ’´ğ’´1 , ğ’´ğ’´2 , and ğ’´ğ’´3 . The side information is the
random variable S distributed over the set ğ’®ğ’® according to ğ‘ğ‘(ğ‘ ğ‘ ).
The transition probability function ğ‘ğ‘(ğ‘¦ğ‘¦1 , ğ‘¦ğ‘¦3 |ğ‘¥ğ‘¥, ğ‘ ğ‘ ) describes the
relationship between channel input X, side information S, and
channel outputs ğ‘Œğ‘Œ1 and ğ‘Œğ‘Œ3 while the probability function
ğ‘ğ‘(ğ‘¦ğ‘¦2 |ğ‘¦ğ‘¦1 ) shows the virtual channel modeling the output ğ‘Œğ‘Œ2 as
the degraded version of ğ‘Œğ‘Œ1 . Independent message sets
ğ‘šğ‘š0 âˆˆ â„³0 and ğ‘šğ‘š1 âˆˆ â„³1 are to be reliably sent, m0 being the
common message for all the receivers and m1 the private
message only for Y1 . Channel model is depicted in Fig. 1.

1

Figure 1. Multilevel broadcast channel with side information.

Definition 2: A (ğ‘›ğ‘›, 2 ğ‘›ğ‘›ğ‘…ğ‘…0 , 2 ğ‘›ğ‘›ğ‘…ğ‘…1 , ğœ–ğœ–) two-degraded message set
code
for
the
Multilevel
BC
with
side
information ï¿½ğ‘ğ‘(ğ‘¦ğ‘¦1 , ğ‘¦ğ‘¦3 |ğ‘¥ğ‘¥, ğ‘ ğ‘ ), ğ‘ğ‘(ğ‘¦ğ‘¦2 |ğ‘¦ğ‘¦1 )ï¿½ consists of an encoder
map

Figure.2. Three-receiver less noisy broadcast channel with side
information.

Achievable rate tuples and the achievable rate region and
the capacity region ğ’ğ’ ğ¿ğ¿ are defined in just the same way as
Multilevel BC.

ğ‘“ğ‘“ âˆ¶ {1,2, â€¦ , ğ‘€ğ‘€0 } Ã— {1,2, â€¦ , ğ‘€ğ‘€1 } Ã— ğ’®ğ’® ğ‘›ğ‘› âŸ¶ ğ’³ğ’³ ğ‘›ğ‘›
ğ‘”ğ‘” ğ‘¦ğ‘¦1 âˆ¶ ğ’´ğ’´1ğ‘›ğ‘› âŸ¶ {1,2, â€¦ , ğ‘€ğ‘€0 } Ã— {1,2, â€¦ , ğ‘€ğ‘€1 }
ğ‘”ğ‘” ğ‘¦ğ‘¦2 âˆ¶ ğ’´ğ’´2ğ‘›ğ‘› âŸ¶ {1,2, â€¦ , ğ‘€ğ‘€0 }
ğ‘”ğ‘” ğ‘¦ğ‘¦3 âˆ¶ ğ’´ğ’´3ğ‘›ğ‘› âŸ¶ {1,2, â€¦ , ğ‘€ğ‘€0 }

and a tuple of decoding maps

Such that ğ‘ƒğ‘ƒğ‘’ğ‘’

(ğ‘›ğ‘›)

III.

Define ğ’«ğ’« as the collection of all random variables
(ğ‘ˆğ‘ˆ, ğ‘‰ğ‘‰, ğ‘†ğ‘†, ğ‘‹ğ‘‹, ğ‘Œğ‘Œ1 , ğ‘Œğ‘Œ2 , ğ‘Œğ‘Œ3 ) with finite alphabets such that
INFORMATION

ğ‘ğ‘(ğ‘¢ğ‘¢, ğ‘£ğ‘£, ğ‘ ğ‘ , ğ‘¥ğ‘¥, ğ‘¦ğ‘¦1 , ğ‘¦ğ‘¦2 , ğ‘¦ğ‘¦3 ) =
ğ‘ğ‘(ğ‘ ğ‘ )ğ‘ğ‘(ğ‘¢ğ‘¢|ğ‘ ğ‘ )ğ‘ğ‘(ğ‘£ğ‘£|ğ‘¢ğ‘¢, ğ‘ ğ‘ )ğ‘ğ‘(ğ‘¥ğ‘¥|ğ‘£ğ‘£, ğ‘ ğ‘ )ğ‘ğ‘(ğ‘¦ğ‘¦1 , ğ‘¦ğ‘¦3 |ğ‘¥ğ‘¥, ğ‘ ğ‘ )ğ‘ğ‘(ğ‘¦ğ‘¦2 |ğ‘¦ğ‘¦1 )

â‰¤ ğœ–ğœ–, i.e.

1
ï¿½ ï¿½ ï¿½ ğ‘ğ‘(ğ’”ğ’”)ğ‘ğ‘{ğ‘”ğ‘” ğ‘¦ğ‘¦1 (ğ’šğ’š1 ) â‰  (ğ‘šğ‘š0 , ğ‘šğ‘š1 ) ğ‘œğ‘œğ‘œğ‘œ
ğ‘€ğ‘€0 ğ‘€ğ‘€1
ğ‘›ğ‘›
ğ‘›ğ‘›
ğ‘€ğ‘€0

ğ‘€ğ‘€1

(ğ‘ˆğ‘ˆ, ğ‘‰ğ‘‰) â†’ (ğ‘‹ğ‘‹, ğ‘†ğ‘†) â†’ (ğ‘Œğ‘Œ1 , ğ‘Œğ‘Œ3 )
(ğ‘†ğ‘†, ğ‘‹ğ‘‹, ğ‘Œğ‘Œ3 ) â†’ ğ‘Œğ‘Œ1 â†’ ğ‘Œğ‘Œ2

ğ‘šğ‘š 0=1 ğ‘šğ‘š 1 =1 ğ‘ ğ‘  âˆˆğ’®ğ’®

ğ‘”ğ‘” ğ‘¦ğ‘¦2 (ğ’šğ’š2 ) â‰  ğ‘šğ‘š0 ğ‘œğ‘œğ‘œğ‘œ ğ‘”ğ‘” ğ‘¦ğ‘¦3 (ğ’šğ’š3 ) â‰  ğ‘šğ‘š0 |ğ’”ğ’”, ğ’™ğ’™(ğ‘šğ‘š0 , ğ‘šğ‘š1 , ğ’”ğ’”)} â‰¤ ğğ

(1)

By (1), the following Markov chains hold:

(2)
(3)

Theorem 1: A pair of nonnegative numbers (ğ‘…ğ‘…0 , ğ‘…ğ‘…1 ) is
achievable for Multilevel BC with side information noncausally available at the transmitter provided that

1
(ğ‘…ğ‘…0 , ğ‘…ğ‘…1 ) = (log ğ‘€ğ‘€0 , ğ‘™ğ‘™ ğ‘™ğ‘™ğ‘™ğ‘™ ğ‘€ğ‘€1 )
ğ‘›ğ‘›

The rate pair of the code is defined as

A rate pair (ğ‘…ğ‘…0 , ğ‘…ğ‘…1 ) is said to be ğœ–ğœ–-achievable if for any
ğœ‚ğœ‚ > 0 there is an integer ğ‘›ğ‘›0 such that for all ğ‘›ğ‘› â‰¥ ğ‘›ğ‘›0 we have a
code
for
(ğ‘›ğ‘›, 2 ğ‘›ğ‘›(ğ‘…ğ‘…0 âˆ’ğœ‚ğœ‚ ) , 2 ğ‘›ğ‘›(ğ‘…ğ‘…1 âˆ’ğœ‚ğœ‚ ) , ğœ–ğœ–)
ï¿½ğ‘ğ‘(ğ‘¦ğ‘¦1 , ğ‘¦ğ‘¦3 |ğ‘¥ğ‘¥, ğ‘ ğ‘ ), ğ‘ğ‘(ğ‘¦ğ‘¦2 |ğ‘¦ğ‘¦1 )ï¿½. The union of the closure of all ğœ–ğœ–achievable rate pairs is called the capacity region ğ’ğ’ ğ‘€ğ‘€ğ‘€ğ‘€ğ‘€ğ‘€ .

ğ‘…ğ‘…0 â‰¤ min{ğ¼ğ¼(ğ‘ˆğ‘ˆ; ğ‘Œğ‘Œ2 ) âˆ’ ğ¼ğ¼(ğ‘ˆğ‘ˆ; ğ‘†ğ‘†), ğ¼ğ¼(ğ‘‰ğ‘‰; ğ‘Œğ‘Œ3 ) âˆ’ ğ¼ğ¼(ğ‘ˆğ‘ˆğ‘ˆğ‘ˆ; ğ‘†ğ‘†)}
ğ‘…ğ‘…1 â‰¤ ğ¼ğ¼(ğ‘‹ğ‘‹; ğ‘Œğ‘Œ1 |ğ‘ˆğ‘ˆ) âˆ’ ğ¼ğ¼(ğ‘‰ğ‘‰; ğ‘†ğ‘†|ğ‘ˆğ‘ˆ) âˆ’ ğ¼ğ¼(ğ‘‹ğ‘‹; ğ‘†ğ‘†|ğ‘‰ğ‘‰)
(4)
ğ‘…ğ‘…0 + ğ‘…ğ‘…1 â‰¤ ğ¼ğ¼(ğ‘‰ğ‘‰; ğ‘Œğ‘Œ3 ) + ğ¼ğ¼(ğ‘‹ğ‘‹; ğ‘Œğ‘Œ1 |ğ‘‰ğ‘‰) âˆ’ ğ¼ğ¼(ğ‘‹ğ‘‹; ğ‘†ğ‘†|ğ‘‰ğ‘‰) âˆ’ ğ¼ğ¼(ğ‘ˆğ‘ˆğ‘ˆğ‘ˆ; ğ‘†ğ‘†)
for some (ğ‘ˆğ‘ˆ, ğ‘‰ğ‘‰, ğ‘†ğ‘†, ğ‘‹ğ‘‹, ğ‘Œğ‘Œ1 , ğ‘Œğ‘Œ2 , ğ‘Œğ‘Œ3 ) âˆˆ ğ’«ğ’«.

Corollary 1.1: By setting ğ‘†ğ‘† â‰¡ âˆ… in (4), our achievable rate
region in Theorem 1 is reduced to the capacity region of
Multilevel BC given in [3].

Definition 3: A channel ğ‘‹ğ‘‹ â†’ ğ‘Œğ‘Œ is said to be less noisy than
the channel ğ‘‹ğ‘‹ â†’ ğ‘ğ‘ in the presence of side information if
ğ¼ğ¼(ğ‘ˆğ‘ˆ; ğ‘Œğ‘Œ|ğ‘†ğ‘† = ğ‘ ğ‘ ) â‰¥ ğ¼ğ¼(ğ‘ˆğ‘ˆ; ğ‘ğ‘|ğ‘†ğ‘† = ğ‘ ğ‘ )
âˆ€ğ‘ğ‘(ğ‘¢ğ‘¢, ğ‘¥ğ‘¥, ğ‘¦ğ‘¦, ğ‘§ğ‘§|ğ‘ ğ‘ ) = ğ‘ğ‘(ğ‘¢ğ‘¢|ğ‘ ğ‘ )ğ‘ğ‘(ğ‘¥ğ‘¥|ğ‘¢ğ‘¢, ğ‘ ğ‘ )ğ‘ğ‘(ğ‘¦ğ‘¦, ğ‘§ğ‘§|ğ‘¥ğ‘¥, ğ‘ ğ‘ ) ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ âˆ€ğ‘ ğ‘  âˆˆ ğ’®ğ’®.

Corollary 1.2: By setting ğ‘Œğ‘Œ3 = ğ‘Œğ‘Œ1 and ğ‘‰ğ‘‰ = ğ‘ˆğ‘ˆ in (4), our
achievable rate region reduces to that of [8] for the two-user
degraded BC with side information.

The 3-receiver less noisy BC with side information is
depicted in Fig. 2, where ğ‘Œğ‘Œ1 is less noisy than ğ‘Œğ‘Œ2 and ğ‘Œğ‘Œ2 is less
noisy than ğ‘Œğ‘Œ3 , i.e. according to [4], ğ‘Œğ‘Œ1 â‰½ ğ‘Œğ‘Œ2 â‰½ ğ‘Œğ‘Œ3 .

Proof: Fix n and a joint distribution on ğ’«ğ’«. Note that side
information is distributed i.i.d according to

The messages ğ‘šğ‘š1 âˆˆ â„³1 , ğ‘šğ‘š2 âˆˆ â„³2 , ğ‘šğ‘š3 âˆˆ â„³3 are to be
reliably sent to receivers ğ‘Œğ‘Œ1 , ğ‘Œğ‘Œ2 , ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ ğ‘Œğ‘Œ3 , respectively. The code
and rate tuple definitions are as follows

ğ‘›ğ‘›

ğ‘ğ‘(ğ’”ğ’”) = ï¿½ ğ‘ğ‘(ğ‘ ğ‘ ğ‘–ğ‘– )
ğ‘–ğ‘–=1

Split the â„³1 message into two independent submessage
sets â„³11 , ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ â„³12 so that ğ‘…ğ‘…1 = ğ‘…ğ‘…11 + ğ‘…ğ‘…12 .

(ğ‘›ğ‘›, 2 ğ‘›ğ‘›ğ‘…ğ‘…1 , 2 ğ‘›ğ‘›ğ‘…ğ‘…2 , 2 ğ‘›ğ‘›ğ‘…ğ‘…3 , ğœ–ğœ–)

(ğ‘…ğ‘…1 , ğ‘…ğ‘…2 , ğ‘…ğ‘…3 ) =

MULTILEVEL BROADCAST CHANNEL WITH SIDE

1
(ğ‘™ğ‘™ ğ‘™ğ‘™ğ‘™ğ‘™ ğ‘€ğ‘€1 , ğ‘™ğ‘™ ğ‘™ğ‘™ğ‘™ğ‘™ ğ‘€ğ‘€2 , ğ‘™ğ‘™ ğ‘™ğ‘™ğ‘™ğ‘™ ğ‘€ğ‘€3 )
ğ‘›ğ‘›

Codebook Generation: First randomly and independently
â€²
â€²
â€²
â€²
generate 2 ğ‘›ğ‘›ï¿½ğ‘…ğ‘…0 +ğ‘…ğ‘…0 ï¿½ sequences ğ’–ğ’–(ğ‘šğ‘š0 , ğ‘šğ‘š0 ), ğ‘šğ‘š0 âˆˆ ï¿½1,2, â€¦ , 2 ğ‘›ğ‘›ğ‘…ğ‘…0 ï¿½,

2

ğ‘›ğ‘›
ğ‘šğ‘š0 âˆˆ {1,2, â€¦ , 2 ğ‘›ğ‘›ğ‘…ğ‘…0 }, each one i.i.d according to âˆ ğ‘–ğ‘–=1 ğ‘ğ‘(ğ‘¢ğ‘¢ ğ‘–ğ‘– )
ğ‘›ğ‘›ğ‘…ğ‘…0
bins. It is clear that
and then randomly throw them into 2
â€²
ğ‘›ğ‘›ğ‘…ğ‘…0
sequences in each bin.
we have 2
â€²
Now for each ğ’–ğ’–(ğ‘šğ‘š0 , ğ‘šğ‘š0 ), randomly and independently
â€² +ğ‘…ğ‘… )
â€²
â€²
â€²
generate 2 ğ‘›ğ‘›(ğ‘…ğ‘…11 11 sequences ğ’—ğ’—(ğ‘šğ‘š0 , ğ‘šğ‘š0 , ğ‘šğ‘š11 , ğ‘šğ‘š11 ), ğ‘šğ‘š11 âˆˆ
â€²
ğ‘›ğ‘›ğ‘…ğ‘…11
ğ‘›ğ‘›ğ‘…ğ‘…11 }
each one i.i.d according to
ï¿½, ğ‘šğ‘š11 âˆˆ {1, â€¦ , 2
ï¿½1, â€¦ , 2
ğ‘›ğ‘›
â€²
âˆ ğ‘–ğ‘–=1 ğ‘ğ‘ ğ‘‰ğ‘‰|ğ‘ˆğ‘ˆ ï¿½ğ‘£ğ‘£ ğ‘–ğ‘– ï¿½ğ‘¢ğ‘¢ ğ‘–ğ‘– (ğ‘šğ‘š0 , ğ‘šğ‘š0 )ï¿½, and randomly throw them into
2 ğ‘›ğ‘›ğ‘…ğ‘…11 bins.
â€²
â€²
Now for each sequence ğ’—ğ’—(ğ‘šğ‘š0 , ğ‘šğ‘š0 , ğ‘šğ‘š11 , ğ‘šğ‘š11 ), randomly and
â€²
independently
generate
2 ğ‘›ğ‘›(ğ‘…ğ‘…12 +ğ‘…ğ‘…12 )
â€²
â€²
â€²
sequences ğ’™ğ’™(ğ‘šğ‘š0 , ğ‘šğ‘š0 , ğ‘šğ‘š11 , ğ‘šğ‘š11 , ğ‘šğ‘š12 , ğ‘šğ‘š12 ) each one i.i.d
ğ‘›ğ‘›
ğ‘›ğ‘›
according to âˆ ğ‘–ğ‘–=1 ğ‘ğ‘ ğ‘‹ğ‘‹|ğ‘ˆğ‘ˆ,ğ‘‰ğ‘‰ (ğ‘¥ğ‘¥ ğ‘–ğ‘– |ğ‘£ğ‘£ ğ‘–ğ‘– , ğ‘¢ğ‘¢ ğ‘–ğ‘– ) = âˆ ğ‘–ğ‘–=1 ğ‘ğ‘ ğ‘‹ğ‘‹|ğ‘‰ğ‘‰ (ğ‘¥ğ‘¥ ğ‘–ğ‘– |ğ‘£ğ‘£ ğ‘–ğ‘– ). Then
ğ‘›ğ‘›ğ‘…ğ‘…12
randomly throw them into 2
bins. Then provide the
transmitter and all the receivers with bins and their codewords.
Encoding: We are given the side information ğ’”ğ’” and the
message pair (ğ‘šğ‘š0 , ğ‘šğ‘š1 ). Indeed, our messages are bin indices.
We find ğ‘šğ‘š11 , ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ ğ‘šğ‘š12 . Now in the bin ğ‘šğ‘š0 of ğ’–ğ’– sequences
(ğ’ğ’)
â€²
â€²
look for a ğ‘šğ‘š0 such that (ğ’–ğ’–(ğ‘šğ‘š0 , ğ‘šğ‘š0 ), ğ’”ğ’”) âˆˆ ğ´ğ´ ğğ , i.e. the
sequence ğ’–ğ’– that is jointly typical with the ğ’”ğ’” given where
definitions of typical sequences are given in [12]. Then in the
â€²
bin ğ‘šğ‘š11 of ğ’—ğ’— sequences look for some ğ‘šğ‘š11 such that

We see that âˆ€ğœ–ğœ– > 0, ğ‘ğ‘(ğ¸ğ¸22 ) â‰¤ ğœ–ğœ– as ğ‘›ğ‘› â†’ âˆ provided that

â€²
â€²
â€²
(ğ’–ğ’–(ğ‘šğ‘š0 , ğ‘šğ‘š0 ), ğ’—ğ’—(ğ‘šğ‘š0 , ğ‘šğ‘š0 , ğ‘šğ‘š11 , ğ‘šğ‘š11 ),
(ğ’ğ’)
â€²
â€²
â€²
ğ’™ğ’™(ğ‘šğ‘š0 , ğ‘šğ‘š0 , ğ‘šğ‘š11 , ğ‘šğ‘š11 , ğ‘šğ‘š12 , ğ‘šğ‘š12 ), ğ’”ğ’”) âˆˆ ğ‘¨ğ‘¨ ğğ

The third receiver ğ‘Œğ‘Œ3 receives ğ’šğ’š3 and needs to decode only
the common message indirectly by decoding the message
ğ‘šğ‘š11 . The error events are

â€²
ğ‘…ğ‘…0 + ğ‘…ğ‘…0 â‰¤ ğ¼ğ¼(ğ‘ˆğ‘ˆ; ğ‘Œğ‘Œ2 ) âˆ’ 3ğœ–ğœ–

The first receiver ğ‘Œğ‘Œ1 receives ğ’šğ’š1 and needs to decode both
ğ‘šğ‘š0 and ğ‘šğ‘š1 . Therefore, the error events are
(5)

â€²
â€²
â€²
ğ¸ğ¸11 = {( ğ’–ğ’–(ğ‘€ğ‘€0 , 1), ğ’—ğ’—(ğ‘€ğ‘€0 , 1, ğ‘€ğ‘€11 , 1),
(ğ‘›ğ‘›)
â€²
â€²
â€²
ğ’™ğ’™(ğ‘€ğ‘€0 , 1, ğ‘€ğ‘€11 , 1, ğ‘€ğ‘€12 , 1), ğ’šğ’š1 ) âˆ‰ ğ´ğ´âˆˆ }
â€²
â€²
â€²
ğ¸ğ¸12 = {( ğ’–ğ’–(ğ‘€ğ‘€0 , 1), ğ’—ğ’—(ğ‘€ğ‘€0 , 1, ğ‘€ğ‘€11 , 1),
(ğ‘›ğ‘›)
â€²
â€²
â€²
ğ’™ğ’™(ğ‘€ğ‘€0 , 1, ğ‘€ğ‘€11 , 1, ğ‘šğ‘š12 , ğ‘šğ‘š12 ), ğ’šğ’š1 ) âˆˆ ğ´ğ´âˆˆ
â€²
â€²
ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘  ğ‘šğ‘š12 â‰  1 ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ ğ‘šğ‘š12 â‰  ğ‘€ğ‘€12 }
â€²
â€²
â€²
ğ¸ğ¸13 = {( ğ’–ğ’–(ğ‘€ğ‘€0 , 1), ğ’—ğ’—(ğ‘€ğ‘€0 , 1, ğ‘šğ‘š11 , ğ‘šğ‘š11 ),
(ğ‘›ğ‘›)
â€²
â€²
â€²
ğ’™ğ’™(ğ‘€ğ‘€0 , 1, ğ‘šğ‘š11 , ğ‘šğ‘š11 , ğ‘šğ‘š12 , ğ‘šğ‘š12 ), ğ’šğ’š1 ) âˆˆ ğ´ğ´âˆˆ
â€²
â€²
ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘  ğ‘šğ‘š1ğ‘–ğ‘– â‰  1 ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ ğ‘šğ‘š1ğ‘–ğ‘– â‰  ğ‘€ğ‘€1ğ‘–ğ‘– , ğ‘–ğ‘– = 1,2}
â€²
â€²
â€²
ğ¸ğ¸14 = {( ğ’–ğ’–(ğ‘šğ‘š0 , ğ‘šğ‘š0 ), ğ’—ğ’—(ğ‘šğ‘š0 , ğ‘šğ‘š0 , ğ‘šğ‘š11 , ğ‘šğ‘š11 ),
(ğ‘›ğ‘›)
â€²
â€²
â€²
ğ’™ğ’™(ğ‘šğ‘š0 , ğ‘šğ‘š0 , ğ‘šğ‘š11 , ğ‘šğ‘š11 , ğ‘šğ‘š12 , ğ‘šğ‘š12 ), ğ’šğ’š1 ) âˆˆ ğ´ğ´âˆˆ
â€²
â€²
ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘  ğ‘šğ‘š0 â‰  1 ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ ğ‘šğ‘š0 â‰  ğ‘€ğ‘€0 ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ 
â€²
â€²
ğ‘šğ‘š1ğ‘–ğ‘– â‰  1 ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ ğ‘šğ‘š1ğ‘–ğ‘– â‰  ğ‘€ğ‘€1ğ‘–ğ‘– , ğ‘–ğ‘– = 1,2}

The first receiverâ€™s probability of error can be arbitrarily
made small provided that
â€²
ğ‘…ğ‘…12 + ğ‘…ğ‘…12 â‰¤ ğ¼ğ¼(ğ‘‹ğ‘‹; ğ‘Œğ‘Œ1 |ğ‘‰ğ‘‰) âˆ’ 6ğœ–ğœ–
â€²
â€²
ğ‘…ğ‘…11 + ğ‘…ğ‘…11 + ğ‘…ğ‘…12 + ğ‘…ğ‘…12 â‰¤ ğ¼ğ¼(ğ‘‹ğ‘‹; ğ‘Œğ‘Œ1 |ğ‘ˆğ‘ˆ) âˆ’ 6ğœ–ğœ–
â€²
â€²
â€²
ğ‘…ğ‘…0 + ğ‘…ğ‘…0 + ğ‘…ğ‘…11 + ğ‘…ğ‘…11 + ğ‘…ğ‘…12 + ğ‘…ğ‘…12 â‰¤ ğ¼ğ¼(ğ‘‹ğ‘‹; ğ‘Œğ‘Œ1 ) âˆ’ 5ğœ–ğœ–

â€²
â€²
â€²
(ğ’–ğ’–(ğ‘šğ‘š0 , ğ‘šğ‘š0 ), ğ’—ğ’—(ğ‘šğ‘š0 , ğ‘šğ‘š0 , ğ‘šğ‘š11 , ğ‘šğ‘š11 ), ğ’”ğ’”) âˆˆ ğ‘¨ğ‘¨(ğ’ğ’)
ğğ

â€²
Now in the bin ğ‘šğ‘š12 of ğ’™ğ’™ sequences look for some ğ‘šğ‘š12 such
that

We send the found ğ’™ğ’™ sequence. Before bumping into
decoding, assume that the correct indices are found through
â€²
â€²
â€²
â€²
the encoding procedure, i.e. ğ‘šğ‘š0 = ğ‘€ğ‘€0 , ğ‘šğ‘š11 = ğ‘€ğ‘€11
â€²
â€²
and ğ‘šğ‘š12 = ğ‘€ğ‘€12 .

(6)
(7)
(8)

â€²
â€²
â€²
ğ¸ğ¸31 = {( ğ’–ğ’–(ğ‘€ğ‘€0 , 1), ğ’—ğ’—(ğ‘€ğ‘€0 , 1, ğ‘€ğ‘€11 , 1), ğ’šğ’š3 ) âˆ‰ ğ´ğ´âˆˆ }
(ğ‘›ğ‘›)
â€²
â€²
â€²
ğ¸ğ¸32 = {( ğ’–ğ’–(ğ‘€ğ‘€0 , 1), ğ’—ğ’—(ğ‘€ğ‘€0 , 1, ğ‘šğ‘š11 , ğ‘šğ‘š11 ), ğ’šğ’š3 ) âˆˆ ğ´ğ´âˆˆ ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“
â€²
â€²
â€²
ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘  ğ‘šğ‘š11 â‰  1 ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ ğ‘šğ‘š11 â‰  ğ‘€ğ‘€11 }
(ğ‘›ğ‘›)
â€²
â€²
â€²
ğ¸ğ¸33 = {( ğ’–ğ’–(ğ‘šğ‘š0 , ğ‘šğ‘š0 ), ğ’—ğ’—(ğ‘šğ‘š0 , ğ‘šğ‘š0 , ğ‘šğ‘š11 , ğ‘šğ‘š11 ), ğ’šğ’š3 ) âˆˆ ğ´ğ´âˆˆ ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“
â€²
â€²
â€²
â€²
ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘  ğ‘šğ‘š0 â‰  1, ğ‘šğ‘š11 â‰  1, ğ‘šğ‘š0 â‰  ğ‘€ğ‘€0 , ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ ğ‘šğ‘š11 â‰  ğ‘€ğ‘€11 }
(ğ‘›ğ‘›)

Decoding: Since the messages are uniformly distributed
over their respective ranges, we can assume, without loss of
generality, that the tuple (ğ‘šğ‘š0 , ğ‘šğ‘š11 , ğ‘šğ‘š12 ) = (1,1,1) is sent.
The second receiver ğ‘Œğ‘Œ2 receives ğ’šğ’š2 thus having the
following error events
â€²
ğ¸ğ¸21 = {(ğ’–ğ’–(ğ‘€ğ‘€0 , 1), ğ’šğ’š2 ) âˆ‰ ğ´ğ´ ğœ–ğœ– }
(ğ‘›ğ‘›)
â€²
ğ¸ğ¸22 = {(ğ’–ğ’–(ğ‘šğ‘š0 , ğ‘šğ‘š0 ), ğ’šğ’š2 ) âˆˆ ğ´ğ´ ğœ–ğœ– ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘  ğ‘šğ‘š0 â‰  1
â€²
â€²
ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ ğ‘šğ‘š0 â‰  ğ‘€ğ‘€0 }

Again by using WLLN and AEP, we see that the third
receiverâ€™s error probabilities can be arbitrarily made small
as ğ‘›ğ‘› â†’ âˆ provided that

leads us to a redundant inequality.

â€²
ğ‘…ğ‘…0 â‰¥ ğ¼ğ¼(ğ‘ˆğ‘ˆ; ğ‘†ğ‘†) + 2ğœ–ğœ–
â€²
ğ‘…ğ‘…11 â‰¥ ğ¼ğ¼(ğ‘‰ğ‘‰; ğ‘†ğ‘†|ğ‘ˆğ‘ˆ) + 2ğœ–ğœ–
â€²
ğ‘…ğ‘…12 â‰¥ ğ¼ğ¼(ğ‘‹ğ‘‹; ğ‘†ğ‘†|ğ‘‰ğ‘‰) + 2ğœ–ğœ–

(ğ‘›ğ‘›)

â€²
ğ¸ğ¸23 = {(ğ’–ğ’–(ğ‘€ğ‘€0 , ğ‘šğ‘š0 ), ğ’šğ’š1 ) âˆˆ

(ğ‘›ğ‘›)
ğ´ğ´ ğœ–ğœ–

â€²
â€²
ğ‘…ğ‘…0 + ğ‘…ğ‘…0 + ğ‘…ğ‘…11 + ğ‘…ğ‘…11 â‰¤ ğ¼ğ¼(ğ‘‰ğ‘‰; ğ‘Œğ‘Œ3 ) âˆ’ 3ğœ–ğœ–

Using Gelâ€™fand-Pinsker coding we see that the encoders can
â€²
â€²
â€²
choose the proper ğ‘šğ‘š0 , ğ‘šğ‘š11 , ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ ğ‘šğ‘š12 indices with vanishing
probability of error provided that for every ğœ–ğœ– > 0 and
sufficiently large n

ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘  ğ‘šğ‘š0 â‰  1}

Remark 1: The following error event

Now by the weak law of large numbers (WLLN)
[14], ğ‘ğ‘(ğ¸ğ¸21 ) â‰¤ ğœ–ğœ–, âˆ€ğœ–ğœ– > 0 as ğ‘›ğ‘› â†’ âˆ. For the second error
event we have
ğ‘ğ‘(ğ¸ğ¸22 ) = ï¿½ ï¿½ ğ‘ğ‘(ğ’–ğ’–)ğ‘ğ‘(ğ’šğ’š2 ) â‰¤ 2 ğ‘›ğ‘›ï¿½ğ‘…ğ‘…0 +ğ‘…ğ‘…0 ï¿½ 2 ğ‘›ğ‘›(ğ»ğ»(ğ‘ˆğ‘ˆ,ğ‘Œğ‘Œ2 )+ğœ–ğœ–)

2

â€²
ğ‘šğ‘š 0 ,ğ‘šğ‘š 0 ğ´ğ´(ğ‘›ğ‘› )
ğœ–ğœ–
âˆ’ğ‘›ğ‘›(ğ»ğ»(ğ‘ˆğ‘ˆ)âˆ’ğœ–ğœ–) âˆ’ğ‘›ğ‘›(ğ»ğ»(ğ‘Œğ‘Œ2 )âˆ’ğœ–ğœ–)

2

=2

(9)

â€²

ğ¼ğ¼(ğ‘‰ğ‘‰; ğ‘†ğ‘†|ğ‘ˆğ‘ˆ) + ğ¼ğ¼(ğ‘ˆğ‘ˆ; ğ‘†ğ‘†) = ğ¼ğ¼(ğ‘‰ğ‘‰ğ‘‰ğ‘‰; ğ‘†ğ‘†)

(10)
(11)
(12)

Now combining (5) - (9) and (10) - (12) and noting that

â€²
âˆ’ğ‘›ğ‘›ï¿½ğ¼ğ¼(ğ‘ˆğ‘ˆ;ğ‘Œğ‘Œ2 )âˆ’3ğœ–ğœ–âˆ’ğ‘…ğ‘…0 âˆ’ğ‘…ğ‘…0 ï¿½

3

(13)

â€²
ğ‘…ğ‘…3 + ğ‘…ğ‘…3 â‰¤ ğ¼ğ¼(ğ‘ˆğ‘ˆ; ğ‘Œğ‘Œ3 )
â€²
ğ‘…ğ‘…2 + ğ‘…ğ‘…2 â‰¤ ğ¼ğ¼(ğ‘‰ğ‘‰; ğ‘Œğ‘Œ2 |ğ‘ˆğ‘ˆ)
â€²
ğ‘…ğ‘…1 + ğ‘…ğ‘…1 â‰¤ ğ¼ğ¼(ğ‘‹ğ‘‹; ğ‘Œğ‘Œ1 |ğ‘‰ğ‘‰)

and using Fourier-Motzkin procedure afterwards to eliminate
ğ‘…ğ‘…11 ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ ğ‘…ğ‘…12 , we obtain (4) as an achievable rate region for
Multilevel BC with side information.
âˆ
IV.

Now combining (16), (17) and (18) with (19), (20) and (21)
gives us (15).
âˆ

THREE-RECEIVER LESS NOISY BROADCAST
CHANNEL WITH SIDE INFORMATION

Define ğ’«ğ’« âˆ— as the collection of all random variables
(ğ‘ˆğ‘ˆ, ğ‘‰ğ‘‰, ğ‘†ğ‘†, ğ‘‹ğ‘‹, ğ‘Œğ‘Œ1 , ğ‘Œğ‘Œ2 , ğ‘Œğ‘Œ3 ) with finite alphabets such that
ğ‘ğ‘(ğ‘¢ğ‘¢, ğ‘£ğ‘£, ğ‘ ğ‘ , ğ‘¥ğ‘¥, ğ‘¦ğ‘¦1 , ğ‘¦ğ‘¦2 , ğ‘¦ğ‘¦3 ) =
ğ‘ğ‘(ğ‘ ğ‘ )ğ‘ğ‘(ğ‘¢ğ‘¢|ğ‘ ğ‘ )ğ‘ğ‘(ğ‘£ğ‘£|ğ‘¢ğ‘¢, ğ‘ ğ‘ )ğ‘ğ‘(ğ‘¥ğ‘¥|ğ‘£ğ‘£, ğ‘ ğ‘ )ğ‘ğ‘(ğ‘¦ğ‘¦1 , ğ‘¦ğ‘¦2 , ğ‘¦ğ‘¦3 |ğ‘¥ğ‘¥, ğ‘ ğ‘ )

Theorem 3: The capacity region of the 3-receiver less
noisy BC with side information, non-causally available at the
transmitter and the receivers is the set of all rate
triples(ğ‘…ğ‘…1 , ğ‘…ğ‘…2 , ğ‘…ğ‘…3 ) such that
ğ‘…ğ‘…1 â‰¤ ğ¼ğ¼(ğ‘‹ğ‘‹; ğ‘Œğ‘Œ1 |ğ‘‰ğ‘‰ğ‘‰ğ‘‰)
ğ‘…ğ‘…2 â‰¤ ğ¼ğ¼(ğ‘‰ğ‘‰; ğ‘Œğ‘Œ2 |ğ‘ˆğ‘ˆğ‘ˆğ‘ˆ)
ğ‘…ğ‘…3 â‰¤ ğ¼ğ¼(ğ‘ˆğ‘ˆ; ğ‘Œğ‘Œ3 |ğ‘†ğ‘†)

Theorem 2: A rate triple(ğ‘…ğ‘…1 , ğ‘…ğ‘…2 , ğ‘…ğ‘…3 ) is achievable for 3receiver less noisy BC with side information non-causally
available at the transmitter provided that
ğ‘…ğ‘…1 â‰¤ ğ¼ğ¼(ğ‘‹ğ‘‹; ğ‘Œğ‘Œ1 |ğ‘‰ğ‘‰) âˆ’ ğ¼ğ¼(ğ‘‹ğ‘‹; ğ‘†ğ‘†|ğ‘‰ğ‘‰)
ğ‘…ğ‘…2 â‰¤ ğ¼ğ¼(ğ‘‰ğ‘‰; ğ‘Œğ‘Œ2 |ğ‘ˆğ‘ˆ) âˆ’ ğ¼ğ¼(ğ‘‰ğ‘‰; ğ‘†ğ‘†|ğ‘ˆğ‘ˆ)
ğ‘…ğ‘…3 â‰¤ ğ¼ğ¼(ğ‘ˆğ‘ˆ; ğ‘Œğ‘Œ3 ) âˆ’ ğ¼ğ¼(ğ‘ˆğ‘ˆ; ğ‘†ğ‘†)

for some joint distribution on ğ’«ğ’«âˆ— .

(14)

(22)

Proof:

Achievability: The direct part of the proof is achieved if
ï¿½
you set ğ‘Œğ‘Œğ‘˜ğ‘˜ = (ğ‘Œğ‘Œğ‘˜ğ‘˜ , ğ‘†ğ‘†), ğ‘˜ğ‘˜ = 1,2,3 in (15).

(15)

Converse: The converse part uses an extension of lemma 1
in [4].

Lemma 1: [4] Let the channel ğ‘‹ğ‘‹ â†’ ğ‘Œğ‘Œ be less noisy than the
channel ğ‘‹ğ‘‹ â†’ ğ‘ğ‘. Consider (ğ‘€ğ‘€, ğ‘†ğ‘† ğ‘›ğ‘› ) to be any random vector
such that

Corollary 2.1: By setting ğ‘†ğ‘† â‰¡ âˆ… in the above rate region, it
reduces to the capacity region of 3-receiver less noisy BC
given in [4].

(ğ‘€ğ‘€, ğ‘†ğ‘† ğ‘›ğ‘› ) â†’ ğ‘‹ğ‘‹ ğ‘›ğ‘› â†’ (ğ‘Œğ‘Œ ğ‘›ğ‘› , ğ‘ğ‘ ğ‘›ğ‘› )

Proof: The proof uses Coverâ€™s superposition [15] and
Gelâ€™fand-Pinsker random binning coding [6] procedures along
with Nairâ€™s indirect decoding and is similar to the last proof
provided and thus only an outline is provided.

ğ¼ğ¼(ğ‘Œğ‘Œ ğ‘–ğ‘–âˆ’1 ; ğ‘ğ‘ğ‘–ğ‘– ï¿½ğ‘€ğ‘€, ğ‘†ğ‘† ğ‘›ğ‘› ) â‰¥ ğ¼ğ¼(ğ‘ğ‘ ğ‘–ğ‘–âˆ’1 ; ğ‘ğ‘ğ‘–ğ‘– ï¿½ğ‘€ğ‘€, ğ‘†ğ‘† ğ‘›ğ‘› )

forms a Markov chain. Then
1.

Fix n and a distribution on ğ’«ğ’« .
Again note that side information is distributed i.i.d
according to
âˆ—

2.

ğ¼ğ¼(ğ‘Œğ‘Œ ğ‘–ğ‘–âˆ’1 ; ğ‘Œğ‘Œğ‘–ğ‘– ï¿½ğ‘€ğ‘€, ğ‘†ğ‘† ğ‘›ğ‘› ) â‰¥ ğ¼ğ¼(ğ‘ğ‘ ğ‘–ğ‘–âˆ’1 ; ğ‘Œğ‘Œğ‘–ğ‘– ï¿½ğ‘€ğ‘€, ğ‘†ğ‘† ğ‘›ğ‘› )

Proof: First of all note that since the channel is
memoryless we have

ğ‘›ğ‘›
(ğ‘€ğ‘€1 , ğ‘€ğ‘€2 , ğ‘€ğ‘€3 , ğ‘Œğ‘Œ1ğ‘–ğ‘–âˆ’1 , ğ‘Œğ‘Œ2ğ‘–ğ‘–âˆ’1 , ğ‘Œğ‘Œ3ğ‘–ğ‘–âˆ’1 , ğ‘†ğ‘† ğ‘–ğ‘–âˆ’1 , ğ‘†ğ‘†ğ‘–ğ‘–+1 ) â†’ (ğ‘‹ğ‘‹ğ‘–ğ‘– , ğ‘†ğ‘†ğ‘–ğ‘– ) â†’ (ğ‘Œğ‘Œ1ğ‘–ğ‘– , ğ‘Œğ‘Œ2ğ‘–ğ‘– , ğ‘Œğ‘Œ3ğ‘–ğ‘– )

ğ‘›ğ‘›

ğ‘ğ‘(ğ’”ğ’”) = ï¿½ ğ‘ğ‘(ğ‘ ğ‘ ğ‘–ğ‘– )

Just like [4], for any 1 â‰¤ ğ‘Ÿğ‘Ÿ â‰¤ ğ‘–ğ‘– âˆ’ 1

ğ‘–ğ‘–=1

ğ¼ğ¼(ğ‘ğ‘ ğ‘Ÿğ‘Ÿâˆ’1 , ğ‘Œğ‘Œğ‘Ÿğ‘Ÿğ‘–ğ‘–âˆ’1 ; ğ‘Œğ‘Œğ‘–ğ‘– ï¿½ğ‘€ğ‘€, ğ‘†ğ‘† ğ‘›ğ‘› )
ğ‘–ğ‘–âˆ’1
= ğ¼ğ¼ï¿½ğ‘ğ‘ ğ‘Ÿğ‘Ÿ âˆ’1 , ğ‘Œğ‘Œğ‘Ÿğ‘Ÿ+1 ; ğ‘Œğ‘Œğ‘–ğ‘– ï¿½ğ‘€ğ‘€, ğ‘†ğ‘† ğ‘›ğ‘› ï¿½
ğ‘–ğ‘–âˆ’1
+ğ¼ğ¼ï¿½ğ‘Œğ‘Œğ‘Ÿğ‘Ÿ ; ğ‘Œğ‘Œğ‘–ğ‘– ï¿½ğ‘€ğ‘€, ğ‘†ğ‘† ğ‘›ğ‘› , ğ‘ğ‘ ğ‘Ÿğ‘Ÿ âˆ’1 , ğ‘Œğ‘Œğ‘Ÿğ‘Ÿ+1 ï¿½
ğ‘–ğ‘–âˆ’1
ğ‘Ÿğ‘Ÿ âˆ’1
ğ‘›ğ‘›
â‰¥ ğ¼ğ¼ï¿½ğ‘ğ‘ , ğ‘Œğ‘Œğ‘Ÿğ‘Ÿ +1 ; ğ‘Œğ‘Œğ‘–ğ‘– ï¿½ğ‘€ğ‘€, ğ‘†ğ‘† ï¿½
ğ‘–ğ‘–âˆ’1
+ğ¼ğ¼ï¿½ğ‘ğ‘ ğ‘Ÿğ‘Ÿ ; ğ‘Œğ‘Œğ‘–ğ‘– ï¿½ğ‘€ğ‘€, ğ‘†ğ‘† ğ‘›ğ‘› , ğ‘ğ‘ ğ‘Ÿğ‘Ÿâˆ’1 , ğ‘Œğ‘Œğ‘Ÿğ‘Ÿ+1 ï¿½
ğ‘–ğ‘–âˆ’1
ğ‘Ÿğ‘Ÿ
ğ‘›ğ‘›
= ğ¼ğ¼ï¿½ğ‘ğ‘ , ğ‘Œğ‘Œğ‘Ÿğ‘Ÿ+1 ; ğ‘Œğ‘Œğ‘–ğ‘– ï¿½ğ‘€ğ‘€, ğ‘†ğ‘† ï¿½

Randomly
and
independently
generate
â€²
â€²
2 ğ‘›ğ‘›(ğ‘…ğ‘…3 +ğ‘…ğ‘…3 ) sequences ğ’–ğ’–(ğ‘šğ‘š3 , ğ‘šğ‘š3 ) , each distributed i.i.d
ğ‘›ğ‘›
according to âˆ ğ‘–ğ‘–=1 ğ‘ğ‘(ğ‘¢ğ‘¢ ğ‘–ğ‘– ) and randomly throw them into 2 ğ‘›ğ‘›ğ‘…ğ‘…3
bins.
â€²
For each ğ’–ğ’–(ğ‘šğ‘š3 , ğ‘šğ‘š3 ), randomly and independently generate
â€² +ğ‘…ğ‘… )
â€²
â€²
2 ğ‘›ğ‘›(ğ‘…ğ‘…2 2 sequences ğ’—ğ’—(ğ‘šğ‘š3 , ğ‘šğ‘š3 , ğ‘šğ‘š2 , ğ‘šğ‘š2 ) each distributed i.i.d
ğ‘›ğ‘›
according to âˆ ğ‘–ğ‘–=1 ğ‘ğ‘ ğ‘‰ğ‘‰|ğ‘ˆğ‘ˆ (ğ‘£ğ‘£ ğ‘–ğ‘– |ğ‘¢ğ‘¢ ğ‘–ğ‘– ) and randomly throw them into
2 ğ‘›ğ‘›ğ‘…ğ‘…2 bins.
â€²
â€²
Now for each generated ğ’—ğ’—(ğ‘šğ‘š3 , ğ‘šğ‘š3 , ğ‘šğ‘š2 , ğ‘šğ‘š2 ), randomly and
independently
generate
â€²
â€²
â€²
â€²
ğ‘›ğ‘›(ğ‘…ğ‘…1 +ğ‘…ğ‘…1 )
) , each one
sequences ğ’™ğ’™(ğ‘šğ‘š3 , ğ‘šğ‘š3 , ğ‘šğ‘š2 , ğ‘šğ‘š2 , ğ‘šğ‘š1 , ğ‘šğ‘š1
2
ğ‘›ğ‘›
distributed i.i.d according to âˆ ğ‘–ğ‘–=1 ğ‘ğ‘ ğ‘‹ğ‘‹|ğ‘‰ğ‘‰ (ğ‘¥ğ‘¥ ğ‘–ğ‘– |ğ‘£ğ‘£ ğ‘–ğ‘– ) and randomly
ğ‘›ğ‘›ğ‘…ğ‘…1
throw them into 2
bins.
Encoding is succeeded with small probability of error
provided that
â€²
ğ‘…ğ‘…3 â‰¥ ğ¼ğ¼(ğ‘ˆğ‘ˆ; ğ‘†ğ‘†)
â€²
ğ‘…ğ‘…2 â‰¥ ğ¼ğ¼(ğ‘‰ğ‘‰; ğ‘†ğ‘†|ğ‘ˆğ‘ˆ)
â€²
ğ‘…ğ‘…1 â‰¥ ğ¼ğ¼(ğ‘‹ğ‘‹; ğ‘†ğ‘†|ğ‘‰ğ‘‰)

(19)
(20)
(21)

where the inequality follows from the memorylessness of the
channel and the fact that ğ‘Œğ‘Œ is less noisy than ğ‘ğ‘, i.e.
ğ‘–ğ‘–âˆ’1
ğ‘–ğ‘–âˆ’1
ğ¼ğ¼ï¿½ğ‘Œğ‘Œğ‘Ÿğ‘Ÿ ; ğ‘Œğ‘Œğ‘–ğ‘– ï¿½ğ‘€ğ‘€, ğ‘†ğ‘† ğ‘›ğ‘› , ğ‘ğ‘ ğ‘Ÿğ‘Ÿâˆ’1 , ğ‘Œğ‘Œğ‘Ÿğ‘Ÿ+1 ï¿½ â‰¥ ğ¼ğ¼ï¿½ğ‘ğ‘ ğ‘Ÿğ‘Ÿ ; ğ‘Œğ‘Œğ‘–ğ‘– ï¿½ğ‘€ğ‘€, ğ‘†ğ‘† ğ‘›ğ‘› , ğ‘ğ‘ ğ‘Ÿğ‘Ÿâˆ’1 , ğ‘Œğ‘Œğ‘Ÿğ‘Ÿ+1 ï¿½.
Proof of the second part follows the same as the first part
âˆ
with negligible variations.
ğ‘›ğ‘›ğ‘…ğ‘…3 = ğ»ğ»(ğ‘€ğ‘€3 ) = ğ»ğ»(ğ‘€ğ‘€3 |ğ‘†ğ‘† ğ‘›ğ‘› ) = ğ»ğ»(ğ‘€ğ‘€3 |ğ‘†ğ‘† ğ‘›ğ‘› , ğ‘Œğ‘Œ3ğ‘›ğ‘› )
Now we stick to the proof of the converse

+ğ¼ğ¼(ğ‘€ğ‘€3 ; ğ‘Œğ‘Œ3ğ‘›ğ‘› |ğ‘†ğ‘† ğ‘›ğ‘› ) â‰¤ ğ»ğ»(ğ‘€ğ‘€3 |ğ‘Œğ‘Œ3ğ‘›ğ‘› ) + ğ¼ğ¼(ğ‘€ğ‘€3 ; ğ‘Œğ‘Œ3ğ‘›ğ‘› |ğ‘†ğ‘† ğ‘›ğ‘› )

(16)
(17)
(18)

ğ‘›ğ‘›

â‰¤ ğ‘›ğ‘›ğœ–ğœ–3ğ‘›ğ‘› + ï¿½ ğ¼ğ¼(ğ‘€ğ‘€3 ; ğ‘Œğ‘Œ3ğ‘–ğ‘– |ğ‘†ğ‘† ğ‘›ğ‘› , ğ‘Œğ‘Œ3ğ‘–ğ‘–âˆ’1 ) â‰¤ ğ‘›ğ‘›ğœ–ğœ–3ğ‘›ğ‘›
ğ‘–ğ‘–=1

and decoding is succeeded if

4

ğ‘›ğ‘›

+ ï¿½ ğ¼ğ¼(ğ‘€ğ‘€3 ; ğ‘Œğ‘Œ3ğ‘–ğ‘– |ğ‘†ğ‘†
ğ‘–ğ‘–=1
ğ‘›ğ‘›

ğ‘–ğ‘–âˆ’1

,

ğ‘›ğ‘›
ğ‘†ğ‘†ğ‘–ğ‘– , ğ‘†ğ‘†ğ‘–ğ‘–+1 , ğ‘Œğ‘Œ3ğ‘–ğ‘–âˆ’1 )

ğ‘›ğ‘›

+ ï¿½ ğ¼ğ¼(ğ‘‹ğ‘‹ğ‘–ğ‘– ; ğ‘Œğ‘Œ1ğ‘–ğ‘– |ğ‘ˆğ‘ˆğ‘–ğ‘– , ğ‘†ğ‘†ğ‘–ğ‘– ),

â‰¤ ğ‘›ğ‘›ğœ–ğœ–3ğ‘›ğ‘›

ğ‘–ğ‘–=1

ğ‘›ğ‘›
+ ï¿½ ğ¼ğ¼ï¿½ğ‘€ğ‘€3 , ğ‘†ğ‘† ğ‘–ğ‘–âˆ’1 , ğ‘†ğ‘†ğ‘–ğ‘–+1 , ğ‘Œğ‘Œ3ğ‘–ğ‘–âˆ’1 ; ğ‘Œğ‘Œ3ğ‘–ğ‘– ï¿½ğ‘†ğ‘†ğ‘–ğ‘– ï¿½ â‰¤ ğ‘›ğ‘›ğœ–ğœ–3ğ‘›ğ‘›
ğ‘–ğ‘–=1
ğ‘›ğ‘›

where (a) follows from the memorylessness of the channel and
(b) follows from Lemma 1.

ğ‘›ğ‘›

ğ‘›ğ‘›
+ ï¿½ ğ¼ğ¼ï¿½ğ‘€ğ‘€3 , ğ‘†ğ‘† ğ‘–ğ‘–âˆ’1 , ğ‘†ğ‘†ğ‘–ğ‘–+1 , ğ‘Œğ‘Œ2ğ‘–ğ‘–âˆ’1 ; ğ‘Œğ‘Œ3ğ‘–ğ‘– ï¿½ğ‘†ğ‘†ğ‘–ğ‘– ï¿½ = ğ‘›ğ‘›ğœ–ğœ–3ğ‘›ğ‘› + ï¿½ ğ¼ğ¼(ğ‘ˆğ‘ˆğ‘–ğ‘– ; ğ‘Œğ‘Œ3ğ‘–ğ‘– |ğ‘†ğ‘†ğ‘–ğ‘– )
ğ‘–ğ‘–=1

ğ‘–ğ‘–=1

Now using the standard time sharing scheme, we can easily
conclude that any achievable rate triple for the three-receiver
less noisy broadcast channel with side information nancausally available at the transmitter and at the receivers, must
satisfy (22) and the proof is complete.
âˆ

ğ‘›ğ‘›
where ğ‘ˆğ‘ˆğ‘–ğ‘– â‰œ ï¿½ğ‘€ğ‘€3 , ğ‘†ğ‘† ğ‘–ğ‘–âˆ’1 , ğ‘†ğ‘†ğ‘–ğ‘–+1 , ğ‘Œğ‘Œ2ğ‘–ğ‘–âˆ’1 ï¿½ and the last inequality
follows from Lemma 1.

ğ‘›ğ‘›ğ‘…ğ‘…2 = ğ»ğ»(ğ‘€ğ‘€2 ) = ğ»ğ»(ğ‘€ğ‘€2 |ğ‘€ğ‘€3 , ğ‘†ğ‘†

ğ‘›ğ‘› )

= ğ»ğ»(ğ‘€ğ‘€2 |ğ‘€ğ‘€3 , ğ‘†ğ‘† ,
ğ‘›ğ‘›

ğ‘Œğ‘Œ2ğ‘›ğ‘› )

V.

+ğ¼ğ¼(ğ‘€ğ‘€2 ; ğ‘Œğ‘Œ2ğ‘›ğ‘› |ğ‘€ğ‘€3 , ğ‘†ğ‘† ğ‘›ğ‘› ) â‰¤ ğ»ğ»(ğ‘€ğ‘€2 |ğ‘Œğ‘Œ2ğ‘›ğ‘› ) + ğ¼ğ¼(ğ‘€ğ‘€2 ; ğ‘Œğ‘Œ2ğ‘›ğ‘› |ğ‘€ğ‘€3 , ğ‘†ğ‘† ğ‘›ğ‘› )
ğ‘›ğ‘›

We established two achievable rate regions for two special
classes of 3-receiver BCs with side information. We also found
the capacity region of 3-receiver less noisy BC when side
information is available both at the transmitter and at the
receivers.

ğ‘›ğ‘›
â‰¤ ğ‘›ğ‘›ğœ–ğœ–2ğ‘›ğ‘› + ï¿½ ğ¼ğ¼ï¿½ğ‘€ğ‘€2 ; ğ‘Œğ‘Œ2ğ‘–ğ‘– ï¿½ğ‘€ğ‘€3 , ğ‘†ğ‘† ğ‘–ğ‘–âˆ’1 , ğ‘†ğ‘†ğ‘–ğ‘– , ğ‘†ğ‘†ğ‘–ğ‘–+1 , ğ‘Œğ‘Œ2ğ‘–ğ‘–âˆ’1 ï¿½ = ğ‘›ğ‘›ğœ–ğœ–2ğ‘›ğ‘›
ğ‘›ğ‘›

ğ‘–ğ‘–=1

REFERENCES

ğ‘›ğ‘›
ğ‘›ğ‘›
+ ï¿½ ğ¼ğ¼ï¿½ğ‘€ğ‘€2 , ğ‘€ğ‘€3 , ğ‘†ğ‘† ğ‘–ğ‘–âˆ’1 , ğ‘†ğ‘†ğ‘–ğ‘–+1 , ğ‘Œğ‘Œ2ğ‘–ğ‘–âˆ’1 ; ğ‘Œğ‘Œ2ğ‘–ğ‘– ï¿½ğ‘€ğ‘€3 , ğ‘†ğ‘† ğ‘–ğ‘–âˆ’1 , ğ‘†ğ‘†ğ‘–ğ‘–+1 , ğ‘Œğ‘Œ2ğ‘–ğ‘–âˆ’1 , ğ‘†ğ‘†ğ‘–ğ‘– ï¿½
ğ‘–ğ‘–=1

[1]

ğ‘›ğ‘›

[2]

= ğ‘›ğ‘›ğœ–ğœ–2ğ‘›ğ‘› + ï¿½ ğ¼ğ¼(ğ‘‰ğ‘‰ğ‘–ğ‘– ; ğ‘Œğ‘Œ2ğ‘–ğ‘– |ğ‘ˆğ‘ˆğ‘–ğ‘– , ğ‘†ğ‘†ğ‘–ğ‘– ),

[3]

ğ‘–ğ‘–=1

ğ‘›ğ‘›
where ğ‘‰ğ‘‰ğ‘–ğ‘– â‰œ ï¿½ğ‘€ğ‘€2 , ğ‘€ğ‘€3 , ğ‘†ğ‘† ğ‘–ğ‘–âˆ’1 , ğ‘†ğ‘†ğ‘–ğ‘–+1 , ğ‘Œğ‘Œ2ğ‘–ğ‘–âˆ’1 ï¿½. It is clear that for the
given choice of ğ‘ˆğ‘ˆğ‘–ğ‘– and ğ‘‰ğ‘‰ğ‘–ğ‘– , we have the Markov chain (2)
satisfied for the channel is assumed to be memoryless.

ğ‘›ğ‘›ğ‘…ğ‘…1 = ğ»ğ»(ğ‘€ğ‘€1 |ğ‘†ğ‘† ğ‘›ğ‘› , ğ‘€ğ‘€2 , ğ‘€ğ‘€3 ) = ğ»ğ»(ğ‘€ğ‘€1 |ğ‘€ğ‘€2 , ğ‘€ğ‘€3 , ğ‘†ğ‘† ğ‘›ğ‘› , ğ‘Œğ‘Œ1ğ‘›ğ‘› )

[4]
[5]

+ğ¼ğ¼(ğ‘€ğ‘€1 ; ğ‘Œğ‘Œ1ğ‘›ğ‘› |ğ‘€ğ‘€2 , ğ‘€ğ‘€3 , ğ‘†ğ‘† ğ‘›ğ‘› ) â‰¤ ğ»ğ»(ğ‘€ğ‘€1 |ğ‘Œğ‘Œ1ğ‘›ğ‘› ) + ğ¼ğ¼(ğ‘€ğ‘€1 ; ğ‘Œğ‘Œ1ğ‘›ğ‘› |ğ‘€ğ‘€2 , ğ‘€ğ‘€3 , ğ‘†ğ‘† ğ‘›ğ‘› )
ğ‘›ğ‘›

ğ‘›ğ‘›
â‰¤ ğ‘›ğ‘›ğœ–ğœ–1ğ‘›ğ‘› + ï¿½ ğ¼ğ¼ï¿½ğ‘€ğ‘€1 ; ğ‘Œğ‘Œ1ğ‘–ğ‘– ï¿½ğ‘€ğ‘€2 , ğ‘€ğ‘€3 , ğ‘†ğ‘† ğ‘–ğ‘–âˆ’1 , ğ‘†ğ‘†ğ‘–ğ‘– , ğ‘†ğ‘†ğ‘–ğ‘–+1 , ğ‘Œğ‘Œ1ğ‘–ğ‘–âˆ’1 ï¿½
ğ‘›ğ‘›

ğ‘–ğ‘–=1

+ ï¿½ ğ¼ğ¼ï¿½ğ‘‹ğ‘‹ğ‘–ğ‘– ; ğ‘Œğ‘Œ1ğ‘–ğ‘– ï¿½ğ‘€ğ‘€2 , ğ‘€ğ‘€3 , ğ‘†ğ‘†
ğ‘–ğ‘–=1
ğ‘›ğ‘›

ğ‘–ğ‘–âˆ’1

,

ğ‘›ğ‘›
ğ‘†ğ‘†ğ‘–ğ‘– , ğ‘†ğ‘†ğ‘–ğ‘–+1 , ğ‘Œğ‘Œ1ğ‘–ğ‘–âˆ’1 ï¿½

ğ‘›ğ‘›
+ ï¿½ ğ¼ğ¼(ğ‘‹ğ‘‹ğ‘–ğ‘– ; ğ‘Œğ‘Œ1ğ‘–ğ‘– ï¿½ğ‘€ğ‘€2 , ğ‘€ğ‘€3 , ğ‘†ğ‘† ğ‘–ğ‘–âˆ’1 , ğ‘†ğ‘†ğ‘–ğ‘– , ğ‘†ğ‘†ğ‘–ğ‘–+1 )
ğ‘–ğ‘–=1
ğ‘›ğ‘›

ğ‘›ğ‘›
âˆ’ ï¿½ ğ¼ğ¼ï¿½ğ‘Œğ‘Œ1ğ‘–ğ‘–âˆ’1 ; ğ‘Œğ‘Œ1ğ‘–ğ‘– ï¿½ğ‘€ğ‘€2 , ğ‘€ğ‘€3 , ğ‘†ğ‘† ğ‘–ğ‘–âˆ’1 , ğ‘†ğ‘†ğ‘–ğ‘– , ğ‘†ğ‘†ğ‘–ğ‘–+1 ï¿½
ğ‘–ğ‘–=1
ğ‘›ğ‘›

ğ‘›ğ‘›
+ ï¿½ ğ¼ğ¼(ğ‘‹ğ‘‹ğ‘–ğ‘– ; ğ‘Œğ‘Œ1ğ‘–ğ‘– ï¿½ğ‘€ğ‘€2 , ğ‘€ğ‘€3 , ğ‘†ğ‘† ğ‘–ğ‘–âˆ’1 , ğ‘†ğ‘†ğ‘–ğ‘– , ğ‘†ğ‘†ğ‘–ğ‘–+1 )
ğ‘–ğ‘–=1

CONCLUSION

[6]

(ğ‘ğ‘)
ğ‘›ğ‘›ğœ–ğœ–
â‰¤ 1ğ‘›ğ‘›

[7]

= ğ‘›ğ‘›ğœ–ğœ–1ğ‘›ğ‘› +

[8]

[9]

(ğ‘ğ‘)
ğ‘›ğ‘›ğœ–ğœ–
â‰¤ 1ğ‘›ğ‘›

[10]
[11]
[12]

ğ‘›ğ‘›

ğ‘›ğ‘›
âˆ’ ï¿½ ğ¼ğ¼ï¿½ğ‘Œğ‘Œ2ğ‘–ğ‘–âˆ’1 ; ğ‘Œğ‘Œ1ğ‘–ğ‘– ï¿½ğ‘€ğ‘€2 , ğ‘€ğ‘€3 , ğ‘†ğ‘† ğ‘–ğ‘–âˆ’1 , ğ‘†ğ‘†ğ‘–ğ‘– , ğ‘†ğ‘†ğ‘–ğ‘–+1 ï¿½ = ğ‘›ğ‘›ğœ–ğœ–1ğ‘›ğ‘›

[13]
[14]

ğ‘–ğ‘–=1
ğ‘›ğ‘›

ğ‘›ğ‘›
+ ï¿½ ğ¼ğ¼ï¿½ğ‘‹ğ‘‹ğ‘–ğ‘– ; ğ‘Œğ‘Œ1ğ‘–ğ‘– ï¿½ğ‘€ğ‘€2 , ğ‘€ğ‘€3 , ğ‘†ğ‘† ğ‘–ğ‘–âˆ’1 , ğ‘†ğ‘†ğ‘–ğ‘–+1 , ğ‘Œğ‘Œ2ğ‘–ğ‘–âˆ’1 , ğ‘†ğ‘†ğ‘–ğ‘– ï¿½ = ğ‘›ğ‘›ğœ–ğœ–1ğ‘›ğ‘›

[15]

ğ‘–ğ‘–=1

[16]

5

S. Borade, L. Zheng, and M. Trott., â€œMultilevel Broadcast Networks,â€
Int. Symp. on Inf. Theory, pp. 1151-1155, June 2007.
J. KÃ¶rner and K. Marton, â€œGeneral broadcast channels with degraded
message sets,â€ IEEE Trans. On Inf. Theory IT-23, Jan. 1977, pp. 60-64.
C. Nair and A. El Gamal, â€The capacity region of a class of 3-receiver
broadcast channels with degraded message sets,â€ IEEE Trans. On Inf.
Theory, vol. 55, no. 10, pp. 4479-4493, Oct. 2009.
C. Nair and Z. V. Wang, â€œThe Capacity Region of the Three-receiver
Less Noisy Broadcast Channel,â€ IEEE Trans. On Inf. Theory, Vol. 57,
pp. 4058-4062, July 2011.
C. E. Shannon, â€œChannels with Side Information at the Transmitter,â€
IBM Journal of Research and Development, Vol. 2, pp. 289-293, Oct.
1958.
S. I. Gelâ€™fand and M. S. Pinsker, â€œCoding for Channel with random
parameters,â€ Probl. Contr. And Inform. Theory, Vol. 9, no. 1, pp. 19-31,
1980.
T. M. Cover; M. Chiang, â€œDuality Between Channel Capacity and Rate
Distortion with two-sided State Information,â€ IEEE Trans. On Inf.
Theory, Vol. 48, pp. 1629-1638, June 2002.
Y. Steinberg, â€œCoding for the Degraded Broadcast Channel with
Random Parameters, with Causal and Noncausal Side Information,â€
IEEE Trans. On Inform. Theory, Vol. 51, no. 8, pp. 2867-2877, Aug.
2005.
Reza Khosravi-Farsani; Farokh Marvasti, â€œCapacity Bounds for
Multiuser Channels with Non-Causal Channel State Information at the
Transmitters,â€ Inf. Theory. Workshop (ITW), pp. 195-199, Oct. 2011.
J. KÃ¶rner and K. Marton, â€œComparison of two noisy Channelsâ€, Topics
on Information Theory (ed. by I. Csiszar and P.Elias), Keszthely,
Hungry, August 1975, 411-423.
C. Nair, â€œCapacity Regions of two new classes of two-receiver broadcast
channelsâ€, IEEE Trans. On Inf. Theory, Vol. 56, pp. 4207-4214, Sept.
2010.
T. M. Cover and J. A. Thomas, â€œElements of Information Theory,â€ John
Wiley & Sons, 1991.
A. El Gamal and Y. H. Kim, â€œNetwork Information Theory,â€ Cambridge
University Press, 2011.
S. M. Ross, â€œA First Course in Probability Theory,â€ Prentice Hall,
printed in the United States of America, 5th edition, 1997.
T. M. Cover, â€œAn Achievable Rate Region for the Broadcast Channel,â€
IEEE Trans. On Inf. Theory, Vol. IT-21, pp. 399-404, July 1975.
Y. Stein berg and S. Shamai, â€œAchievable rates for the broadcast
channel with states known at the transmitter,â€ Int. Symp. on Inf. Theory,
2005, Adelaide, SA, pp. 2184-2188.

